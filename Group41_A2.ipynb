{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5046_a2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMK60u7d85s2",
        "colab_type": "text"
      },
      "source": [
        "# **Read Me**\n",
        "\n",
        "This ipynb has two main section:\n",
        "\n",
        "1. for submission\n",
        "2. below is testing logs\n",
        "\n",
        "Please run the code in first section (for submission) sequently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PoWHvnz9YPU",
        "colab_type": "text"
      },
      "source": [
        "# **1. for submission**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0b8DziI0BHx",
        "colab_type": "code",
        "outputId": "a5f44183-5dbe-4a55-85d1-f4c074b0cb25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# environment set up\n",
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import time\n",
        "import math\n",
        "import csv\n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy.tokens import Doc\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import gensim.downloader as api\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fbf90d09490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G90rAe870g57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download data set\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate\n",
        "drive = None\n",
        "def authenticate():\n",
        "    global drive\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "\n",
        "#Download files\n",
        "def downloadFiles(fileIds):\n",
        "    authenticate()\n",
        "    for fileId in fileIds:    \n",
        "        downloaded = drive.CreateFile({\"id\": fileId[1]})\n",
        "        downloaded.GetContentFile(fileId[0])\n",
        "\n",
        "#Download file if not existing\n",
        "try:\n",
        "    train_data = pd.read_csv('train_upper.csv')\n",
        "except:\n",
        "    downloadFiles([['train_upper.csv', '1rFyBQzZK2CSwt0Sm11J2aEsxKh0qB4T6']])\n",
        "    train_data = pd.read_csv('train_upper.csv')\n",
        "\n",
        "try:\n",
        "    val_data = pd.read_csv('val_upper.csv')\n",
        "except:\n",
        "    downloadFiles([['val_upper.csv', '1f0OP_gI5jwqDgeFyawZZ1tTJzqCTgo6X']])\n",
        "    val_data = pd.read_csv('val_upper.csv')\n",
        "\n",
        "try:\n",
        "    test_data = pd.read_csv('test_upper.csv')\n",
        "except:\n",
        "    downloadFiles([['test_upper.csv', '1CQ3W5q4JhAB3s4j2XC17gVYWsQcAxvb4']])\n",
        "    test_data = pd.read_csv('test_upper.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBxBOoyo6TKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read data into list\n",
        "sentence_train = train_data['Sentence'].tolist()\n",
        "ner_train = train_data['NER'].tolist()\n",
        "\n",
        "sentence_val = val_data['Sentence'].tolist()\n",
        "ner_val = val_data['NER'].tolist()\n",
        "\n",
        "sentence_test = test_data['Sentence'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4PNBcQfzTaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining nlp model\n",
        "word_model = api.load(\"glove-wiki-gigaword-300\")\n",
        "\n",
        "# https://spacy.io/usage/linguistic-features#tokenization define our own spacy tokenizar by split()\n",
        "class WhitespaceTokenizer(object):\n",
        "    def __init__(self, vocab):\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __call__(self, text):\n",
        "        words = text.split(' ')\n",
        "        # All tokens 'own' a subsequent space character in this tokenizer\n",
        "        spaces = [True] * len(words)\n",
        "        return Doc(self.vocab, words=words, spaces=spaces)\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.tokenizer = WhitespaceTokenizer(nlp.vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcD0BTXsFJw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find all possible POS tagging, dependence path tagging, tagging\n",
        "word_to_ix, pos_table, dep_table, tag_table = {}, {}, {}, {}\n",
        "for sentence in sentence_train:\n",
        "    parse = nlp(sentence)\n",
        "    for token in parse:\n",
        "        if str(token) not in word_to_ix:\n",
        "            word_to_ix[str(token)] = len(word_to_ix)\n",
        "        if token.pos_ not in pos_table:\n",
        "            pos_table[token.pos_] = len(pos_table)\n",
        "        if token.dep_ not in dep_table:\n",
        "            dep_table[token.dep_] = len(dep_table)\n",
        "        if token.tag_ not in tag_table:\n",
        "            tag_table[token.tag_] = len(tag_table)\n",
        "\n",
        "for sentence in sentence_val:\n",
        "    parse = nlp(sentence)\n",
        "    for token in parse:\n",
        "        if str(token) not in word_to_ix:\n",
        "            word_to_ix[str(token)] = len(word_to_ix)\n",
        "        if token.pos_ not in pos_table:\n",
        "            pos_table[token.pos_] = len(pos_table)\n",
        "        if token.dep_ not in dep_table:\n",
        "            dep_table[token.dep_] = len(dep_table)\n",
        "        if token.tag_ not in tag_table:\n",
        "            tag_table[token.tag_] = len(tag_table)\n",
        "\n",
        "for sentence in sentence_test:\n",
        "    parse = nlp(sentence)\n",
        "    for token in parse:\n",
        "        if str(token) not in word_to_ix:\n",
        "            word_to_ix[str(token)] = len(word_to_ix)\n",
        "        if token.pos_ not in pos_table:\n",
        "            pos_table[token.pos_] = len(pos_table)\n",
        "        if token.dep_ not in dep_table:\n",
        "            dep_table[token.dep_] = len(dep_table)\n",
        "        if token.tag_ not in tag_table:\n",
        "            tag_table[token.tag_] = len(tag_table)\n",
        "\n",
        "pos_onehot = np.eye(len(pos_table))\n",
        "dep_onehot = np.eye(len(dep_table))\n",
        "tag_onehot_emb = np.eye(len(tag_table))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7N06NQ419m1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate tf-idf by code in lab 1\n",
        "DF = {}\n",
        "def get_df(documents):\n",
        "    for sentence in documents:\n",
        "        # sentence = [sentence.split()]\n",
        "        for term in np.unique(sentence.split()):\n",
        "            try:\n",
        "                DF[term] += 1\n",
        "            except:\n",
        "                DF[term] = 1\n",
        "\n",
        "get_df(sentence_train)\n",
        "get_df(sentence_val)\n",
        "get_df(sentence_test)\n",
        "\n",
        "def get_tf_idf(documents):\n",
        "    tf_idf = {}\n",
        "    # total number of documents\n",
        "    N = 3000 + 700 + 3684\n",
        "    doc_id = 0\n",
        "    # get each tokenised doc\n",
        "    for sentence in documents:\n",
        "        # sentence = [sentence.split()]\n",
        "        \n",
        "        # initialise counter for the doc\n",
        "        counter = Counter(sentence.split())\n",
        "        # calculate total number of words in the doc\n",
        "        total_num_words = len(sentence.split())    \n",
        "        # get each unique word in the doc\n",
        "        for term in np.unique(sentence.split()):\n",
        "            #calculate Term Frequency \n",
        "            tf = counter[term] / total_num_words\n",
        "            #calculate Document Frequency\n",
        "            df = DF[term]\n",
        "            # calculate Inverse Document Frequency\n",
        "            idf = math.log(N / (df + 1)) + 1\n",
        "            # calculate TF-IDF\n",
        "            tf_idf[doc_id, term] = tf * idf\n",
        "        doc_id += 1\n",
        "    return tf_idf\n",
        "\n",
        "\n",
        "tf_idf_train = get_tf_idf(sentence_train)\n",
        "tf_idf_val = get_tf_idf(sentence_val)\n",
        "tf_idf_test = get_tf_idf(sentence_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GBgOer2th3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "\n",
        "tag_to_ix = {'I-LOC': 0,\n",
        "             'I-MISC': 1,\n",
        "             'I-ORG': 2,\n",
        "             'I-PER': 3,\n",
        "             'O': 4,\n",
        "             START_TAG: 5,\n",
        "             STOP_TAG: 6}\n",
        "tag_onehot = np.eye(len(tag_to_ix))\n",
        "tag_lookup_table = {0: 'I-LOC',\n",
        "                    1: 'I-MISC',\n",
        "                    2: 'I-ORG',\n",
        "                    3: 'I-PER',\n",
        "                    4: 'O',\n",
        "                    5: START_TAG,\n",
        "                    6: STOP_TAG}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ey0kZ_JXzmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare a smaller one-hot vector for shape feature\n",
        "target_set, per_set, loc_set, org_set, misc_set = set(), set(), set(), set(), set()\n",
        "for sentence, tag in zip(sentence_train, ner_train):\n",
        "    parse = nlp(sentence)\n",
        "    tags = [e for e in tag.split()]\n",
        "    for i, token in enumerate(parse):\n",
        "        if tags[i] == 'I-PER':\n",
        "            per_set.add(token.shape_)\n",
        "            target_set.add(token.shape_)\n",
        "        elif tags[i] == 'I-LOC':\n",
        "            loc_set.add(token.shape_)\n",
        "            target_set.add(token.shape_)\n",
        "        elif tags[i] == 'I-ORG':\n",
        "            org_set.add(token.shape_)\n",
        "            target_set.add(token.shape_)\n",
        "        elif tags[i] == 'I-MISC':\n",
        "            misc_set.add(token.shape_)\n",
        "            target_set.add(token.shape_)\n",
        "\n",
        "per_set = per_set - loc_set - org_set - misc_set\n",
        "loc_set = loc_set - per_set - org_set - misc_set\n",
        "org_set = org_set - per_set - loc_set - misc_set\n",
        "misc_set = misc_set - per_set - loc_set - org_set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHh5EmC00L1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define get input embedding function\n",
        "def gensim_emb(word):\n",
        "    try:\n",
        "        emb = word_model.wv[word.lower()]\n",
        "    except:\n",
        "        emb = np.array([0.] * 300, dtype=float)\n",
        "    return torch.FloatTensor(emb)\n",
        "\n",
        "def get_pos(token, parse):\n",
        "    return torch.FloatTensor(pos_onehot[pos_table[token.pos_]])\n",
        "\n",
        "def get_dep(token, parse):\n",
        "    return torch.FloatTensor(dep_onehot[dep_table[token.dep_]])\n",
        "\n",
        "def get_tag(token, parse):\n",
        "    return torch.FloatTensor(tag_onehot_emb[tag_table[token.tag_]])\n",
        "\n",
        "def get_shape(token, parse):\n",
        "    shape = token.shape_\n",
        "    if shape in target_set:\n",
        "        if shape in per_set:\n",
        "            return torch.FloatTensor([1, 0, 0, 0, 0, 0])\n",
        "        elif shape in loc_set:\n",
        "            return torch.FloatTensor([0, 1, 0, 0, 0, 0])\n",
        "        elif shape in org_set:\n",
        "            return torch.FloatTensor([0, 0, 1, 0, 0, 0])\n",
        "        elif shape in misc_set:\n",
        "            return torch.FloatTensor([0, 0, 0, 1, 0, 0])\n",
        "        return torch.FloatTensor([0, 0, 0, 0, 1, 0])\n",
        "    else:\n",
        "        return torch.FloatTensor([0, 0, 0, 0, 0, 1])\n",
        "\n",
        "def get_tf_idf(token, parse, index, flag):\n",
        "    if flag == 'train':\n",
        "        tf_idf_emb = torch.FloatTensor([tf_idf_train[index, str(token)]])\n",
        "    elif flag == 'val':\n",
        "        tf_idf_emb = torch.FloatTensor([tf_idf_val[index, str(token)]])\n",
        "    elif flag == 'test':\n",
        "        tf_idf_emb = torch.FloatTensor([tf_idf_test[index, str(token)]])\n",
        "    return tf_idf_emb\n",
        "\n",
        "def get_embeddings(sentence, index, flag, emb_dim):\n",
        "    N = len(sentence.split())\n",
        "    sentence_emb = torch.empty((0, emb_dim), dtype=torch.float32)\n",
        "    parse = nlp(sentence)\n",
        "    for token in parse:\n",
        "        word_emb = gensim_emb(str(token))\n",
        "        pos_emb = get_pos(token, parse)\n",
        "        dep_emb = get_dep(token, parse)\n",
        "        tag_emb = get_tag(token, parse)\n",
        "        shape_emb = get_shape(token, parse)\n",
        "        tf_idf_emb = get_tf_idf(token, parse, index, flag)\n",
        "        pad_emb = torch.FloatTensor([0., 0., 0.])\n",
        "        embeddings = torch.cat((word_emb, pos_emb, dep_emb, tag_emb, shape_emb, tf_idf_emb, pad_emb), axis=-1).view(1, -1)\n",
        "        sentence_emb = torch.cat((sentence_emb, embeddings), axis=0)\n",
        "    return sentence_emb.view(N, 1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67cCfeJcag4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, tag_to_ix, embedding_dim, hidden_dim, layers=1):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        self.layers = layers\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=self.layers, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "        \n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def argmax(self, vec):\n",
        "        # return the argmax as a python int\n",
        "        _, idx = torch.max(vec, 1)\n",
        "        return idx.item()\n",
        "    \n",
        "    # Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "    def log_sum_exp(self, vec):\n",
        "        max_score = vec[0, self.argmax(vec)]\n",
        "        max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "        return max_score + \\\n",
        "            torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2 * self.layers, 1, self.hidden_dim // 2),\n",
        "                torch.randn(2 * self.layers, 1, self.hidden_dim // 2))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(self.log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = self.log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        lstm_out, self.hidden = self.lstm(sentence, self.hidden)\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = self.argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = self.argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(feats)\n",
        "        return forward_score - gold_score, tag_seq\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jCRhTvFQPl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training functions\n",
        "def calculate_acuracy(labels, model_pred):\n",
        "    precision = precision_score(labels, model_pred, average='micro')\n",
        "    recall = recall_score(labels, model_pred, average='micro')\n",
        "    f1 = f1_score(labels, model_pred, average='micro')\n",
        "    return precision, recall, f1\n",
        "\n",
        "\n",
        "def train_iter(model, optimizer, sentence, tags, index, emb_dim):\n",
        "    '''\n",
        "    Train the model for a single iteration.\n",
        "    An iteration is when a single batch of data is passed forward and backward through the neural network.\n",
        "    '''\n",
        "    # move input and output to gpu\n",
        "    # sentence, tags = sentence.to(device), tags.to(device)\n",
        "    # gradient\n",
        "    model.zero_grad()\n",
        "    # forward propagation\n",
        "    sentence_in = get_embeddings(sentence, index, flag='train', emb_dim=emb_dim)\n",
        "    targets = torch.tensor([tag_to_ix[t] for t in tags.split()], dtype=torch.long)\n",
        "\n",
        "    loss, outputs = model.neg_log_likelihood(sentence_in, targets)\n",
        "    # with torch.no_grad():\n",
        "    #     _, outputs = model(sentence_in)\n",
        "    # calculate precision and recall\n",
        "    # precision, recall, f1 = calculate_acuracy(targets.tolist(), outputs)\n",
        "    # backward propagation\n",
        "    loss.backward()\n",
        "    # Update the parameters. \n",
        "    optimizer.step()\n",
        "    return loss, outputs, targets.tolist()\n",
        "\n",
        "\n",
        "def train_epoch(model, optimizer, emb_dim):\n",
        "    '''\n",
        "    in one epoch, loop through the whole data, keep track and record the precision and recall of each batch\n",
        "    '''\n",
        "    # set model to train mode\n",
        "    time_since = time.time()\n",
        "    model.train()\n",
        "    running_loss = []\n",
        "    truth = []\n",
        "    prediction = []\n",
        "    for i, (sentence, tags) in enumerate(zip(sentence_train, ner_train)):\n",
        "        loss, outputs, targets = train_iter(model, optimizer, sentence, tags, i, emb_dim)\n",
        "        running_loss.append(loss.item())\n",
        "        truth += targets\n",
        "        prediction += outputs\n",
        "        # display performance every 500 data records\n",
        "        if i % 500 == 499:\n",
        "            precision, recall, f1 = calculate_acuracy(truth, prediction)\n",
        "            print('[{:4}/{:4}]'.format(i + 1, len(sentence_train)), end=': ')\n",
        "            print('Training Loss: {:>7.4f}'.format(np.mean(running_loss)), end=', ')\n",
        "            print('Training Precision: {:.4f}'.format(precision), end=', ')\n",
        "            print('Training Recall: {:.4f}'.format(recall), end=', ')\n",
        "            print('Training F_1: {:.4f}'.format(f1))\n",
        "            running_loss = []\n",
        "            prediction = []\n",
        "            truth = []\n",
        "    \n",
        "    print('Epoch training time: {:.2f} s.'.format(time.time() - time_since))\n",
        "    return \n",
        "\n",
        "\n",
        "def val_epoch(model, emb_dim):\n",
        "    '''\n",
        "    valid current model on validation set\n",
        "    '''\n",
        "    # set the model to validating mode, without gradient\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        loss_list = []\n",
        "        predictions = []\n",
        "        true_tags = []\n",
        "        for i, (sentence, tags) in enumerate(zip(sentence_val, ner_val)):\n",
        "            sentence_in = get_embeddings(sentence, i, flag='val', emb_dim=emb_dim)\n",
        "            targets = torch.tensor([tag_to_ix[t] for t in tags.split()], dtype=torch.long)\n",
        "            for t in targets:\n",
        "                true_tags.append(t.item())\n",
        "            loss, outputs = model.neg_log_likelihood(sentence_in, targets)\n",
        "            loss_list.append(loss.item())\n",
        "            \n",
        "            for p in outputs:\n",
        "                predictions.append(p)\n",
        "        precision, recall, f1 = calculate_acuracy(true_tags, predictions)\n",
        "        print('############ Val Loss: {:>7.4f}'.format(np.mean(loss_list)), end=', ')\n",
        "        print('Val Precision: {:.4f}'.format(precision), end=', ')\n",
        "        print('Val Recall: {:.4f}'.format(recall), end=', ')\n",
        "        print('Val F_1: {:.4f}'.format(f1))\n",
        "    return\n",
        "\n",
        "\n",
        "def train_model(model, optimizer, emb_dim, num_epochs=25):\n",
        "    # record starting time and initialize summary writer\n",
        "    since = time.time()\n",
        "    # train the model num_epoch times\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
        "        # for every epoch, run training and validating\n",
        "        for phase in ['train', 'val']:\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_epoch(model, optimizer, emb_dim)\n",
        "            elif phase == 'val':\n",
        "                val_epoch(model, emb_dim)\n",
        "        torch.save(model, 'The_'+ str(epoch + 1) + '_epoch_model.pt')\n",
        "        print('-' * 109)\n",
        "    \n",
        "    time_cost = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_cost // 60, time_cost % 60))\n",
        "\n",
        "\n",
        "def predict(model):\n",
        "    outputs = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for index, sentence in enumerate(sentence_test):\n",
        "            sentence_in = get_embeddings(sentence, index, flag='test', emb_dim=EMBEDDING_DIM)\n",
        "            _, predictions = model(sentence_in)\n",
        "            for p in predictions:\n",
        "                outputs.append(p)\n",
        "    with open('Predicted labels.csv', 'w') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(['ID','Predicted'])\n",
        "        for index, label in enumerate(outputs):\n",
        "            writer.writerow([str(index), str(tag_lookup_table[label])])\n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfxBRt244Wjs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "87aca5f9-13ed-4146-d584-69c0510a6d03"
      },
      "source": [
        "HIDDEN_DIM = 512\n",
        "EMBEDDING_DIM = 420\n",
        "\n",
        "model = BiLSTM_CRF(tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, layers=2)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "train_model(model, optimizer, num_epochs=10, emb_dim=EMBEDDING_DIM)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "[ 500/3000]: Training Loss:  8.2771, Training Precision: 0.8341, Training Recall: 0.8341, Training F_1: 0.8341\n",
            "[1000/3000]: Training Loss:  3.3540, Training Precision: 0.8858, Training Recall: 0.8858, Training F_1: 0.8858\n",
            "[1500/3000]: Training Loss:  2.8885, Training Precision: 0.9404, Training Recall: 0.9404, Training F_1: 0.9404\n",
            "[2000/3000]: Training Loss:  2.6661, Training Precision: 0.9436, Training Recall: 0.9436, Training F_1: 0.9436\n",
            "[2500/3000]: Training Loss:  1.6430, Training Precision: 0.9465, Training Recall: 0.9465, Training F_1: 0.9465\n",
            "[3000/3000]: Training Loss:  1.7699, Training Precision: 0.9473, Training Recall: 0.9473, Training F_1: 0.9473\n",
            "Epoch training time: 271.26 s.\n",
            "############ Val Loss:  1.7004, Val Precision: 0.9403, Val Recall: 0.9403, Val F_1: 0.9403\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 2/10\n",
            "[ 500/3000]: Training Loss:  2.1276, Training Precision: 0.9452, Training Recall: 0.9452, Training F_1: 0.9452\n",
            "[1000/3000]: Training Loss:  1.2113, Training Precision: 0.9623, Training Recall: 0.9623, Training F_1: 0.9623\n",
            "[1500/3000]: Training Loss:  1.4534, Training Precision: 0.9689, Training Recall: 0.9689, Training F_1: 0.9689\n",
            "[2000/3000]: Training Loss:  1.7174, Training Precision: 0.9661, Training Recall: 0.9661, Training F_1: 0.9661\n",
            "[2500/3000]: Training Loss:  1.0242, Training Precision: 0.9672, Training Recall: 0.9672, Training F_1: 0.9672\n",
            "[3000/3000]: Training Loss:  1.2373, Training Precision: 0.9615, Training Recall: 0.9615, Training F_1: 0.9615\n",
            "Epoch training time: 267.78 s.\n",
            "############ Val Loss:  1.4284, Val Precision: 0.9502, Val Recall: 0.9502, Val F_1: 0.9502\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 3/10\n",
            "[ 500/3000]: Training Loss:  1.4750, Training Precision: 0.9630, Training Recall: 0.9630, Training F_1: 0.9630\n",
            "[1000/3000]: Training Loss:  0.8663, Training Precision: 0.9713, Training Recall: 0.9713, Training F_1: 0.9713\n",
            "[1500/3000]: Training Loss:  1.0517, Training Precision: 0.9786, Training Recall: 0.9786, Training F_1: 0.9786\n",
            "[2000/3000]: Training Loss:  1.3768, Training Precision: 0.9718, Training Recall: 0.9718, Training F_1: 0.9718\n",
            "[2500/3000]: Training Loss:  0.7055, Training Precision: 0.9788, Training Recall: 0.9788, Training F_1: 0.9788\n",
            "[3000/3000]: Training Loss:  0.9253, Training Precision: 0.9717, Training Recall: 0.9717, Training F_1: 0.9717\n",
            "Epoch training time: 266.45 s.\n",
            "############ Val Loss:  1.2566, Val Precision: 0.9584, Val Recall: 0.9584, Val F_1: 0.9584\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 4/10\n",
            "[ 500/3000]: Training Loss:  1.1840, Training Precision: 0.9710, Training Recall: 0.9710, Training F_1: 0.9710\n",
            "[1000/3000]: Training Loss:  0.6827, Training Precision: 0.9764, Training Recall: 0.9764, Training F_1: 0.9764\n",
            "[1500/3000]: Training Loss:  0.8473, Training Precision: 0.9815, Training Recall: 0.9815, Training F_1: 0.9815\n",
            "[2000/3000]: Training Loss:  1.1749, Training Precision: 0.9746, Training Recall: 0.9746, Training F_1: 0.9746\n",
            "[2500/3000]: Training Loss:  0.5932, Training Precision: 0.9841, Training Recall: 0.9841, Training F_1: 0.9841\n",
            "[3000/3000]: Training Loss:  0.7091, Training Precision: 0.9769, Training Recall: 0.9769, Training F_1: 0.9769\n",
            "Epoch training time: 267.45 s.\n",
            "############ Val Loss:  1.2789, Val Precision: 0.9571, Val Recall: 0.9571, Val F_1: 0.9571\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 5/10\n",
            "[ 500/3000]: Training Loss:  0.9388, Training Precision: 0.9785, Training Recall: 0.9785, Training F_1: 0.9785\n",
            "[1000/3000]: Training Loss:  0.5342, Training Precision: 0.9812, Training Recall: 0.9812, Training F_1: 0.9812\n",
            "[1500/3000]: Training Loss:  0.6875, Training Precision: 0.9860, Training Recall: 0.9860, Training F_1: 0.9860\n",
            "[2000/3000]: Training Loss:  0.8765, Training Precision: 0.9815, Training Recall: 0.9815, Training F_1: 0.9815\n",
            "[2500/3000]: Training Loss:  0.4558, Training Precision: 0.9872, Training Recall: 0.9872, Training F_1: 0.9872\n",
            "[3000/3000]: Training Loss:  0.5254, Training Precision: 0.9828, Training Recall: 0.9828, Training F_1: 0.9828\n",
            "Epoch training time: 269.19 s.\n",
            "############ Val Loss:  1.2660, Val Precision: 0.9607, Val Recall: 0.9607, Val F_1: 0.9607\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 6/10\n",
            "[ 500/3000]: Training Loss:  0.8387, Training Precision: 0.9814, Training Recall: 0.9814, Training F_1: 0.9814\n",
            "[1000/3000]: Training Loss:  0.4735, Training Precision: 0.9835, Training Recall: 0.9835, Training F_1: 0.9835\n",
            "[1500/3000]: Training Loss:  0.5501, Training Precision: 0.9882, Training Recall: 0.9882, Training F_1: 0.9882\n",
            "[2000/3000]: Training Loss:  0.7639, Training Precision: 0.9836, Training Recall: 0.9836, Training F_1: 0.9836\n",
            "[2500/3000]: Training Loss:  0.3737, Training Precision: 0.9905, Training Recall: 0.9905, Training F_1: 0.9905\n",
            "[3000/3000]: Training Loss:  0.4366, Training Precision: 0.9864, Training Recall: 0.9864, Training F_1: 0.9864\n",
            "Epoch training time: 270.65 s.\n",
            "############ Val Loss:  1.2320, Val Precision: 0.9633, Val Recall: 0.9633, Val F_1: 0.9633\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 7/10\n",
            "[ 500/3000]: Training Loss:  0.6430, Training Precision: 0.9855, Training Recall: 0.9855, Training F_1: 0.9855\n",
            "[1000/3000]: Training Loss:  0.3401, Training Precision: 0.9883, Training Recall: 0.9883, Training F_1: 0.9883\n",
            "[1500/3000]: Training Loss:  0.4539, Training Precision: 0.9903, Training Recall: 0.9903, Training F_1: 0.9903\n",
            "[2000/3000]: Training Loss:  0.6122, Training Precision: 0.9873, Training Recall: 0.9873, Training F_1: 0.9873\n",
            "[2500/3000]: Training Loss:  0.2889, Training Precision: 0.9914, Training Recall: 0.9914, Training F_1: 0.9914\n",
            "[3000/3000]: Training Loss:  0.3757, Training Precision: 0.9879, Training Recall: 0.9879, Training F_1: 0.9879\n",
            "Epoch training time: 274.75 s.\n",
            "############ Val Loss:  1.2206, Val Precision: 0.9661, Val Recall: 0.9661, Val F_1: 0.9661\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 8/10\n",
            "[ 500/3000]: Training Loss:  0.4776, Training Precision: 0.9902, Training Recall: 0.9902, Training F_1: 0.9902\n",
            "[1000/3000]: Training Loss:  0.2992, Training Precision: 0.9889, Training Recall: 0.9889, Training F_1: 0.9889\n",
            "[1500/3000]: Training Loss:  0.3439, Training Precision: 0.9933, Training Recall: 0.9933, Training F_1: 0.9933\n",
            "[2000/3000]: Training Loss:  0.4742, Training Precision: 0.9878, Training Recall: 0.9878, Training F_1: 0.9878\n",
            "[2500/3000]: Training Loss:  0.2698, Training Precision: 0.9927, Training Recall: 0.9927, Training F_1: 0.9927\n",
            "[3000/3000]: Training Loss:  0.2544, Training Precision: 0.9930, Training Recall: 0.9930, Training F_1: 0.9930\n",
            "Epoch training time: 272.19 s.\n",
            "############ Val Loss:  1.1507, Val Precision: 0.9700, Val Recall: 0.9700, Val F_1: 0.9700\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 9/10\n",
            "[ 500/3000]: Training Loss:  0.4054, Training Precision: 0.9890, Training Recall: 0.9890, Training F_1: 0.9890\n",
            "[1000/3000]: Training Loss:  0.2349, Training Precision: 0.9899, Training Recall: 0.9899, Training F_1: 0.9899\n",
            "[1500/3000]: Training Loss:  0.2491, Training Precision: 0.9953, Training Recall: 0.9953, Training F_1: 0.9953\n",
            "[2000/3000]: Training Loss:  0.3738, Training Precision: 0.9915, Training Recall: 0.9915, Training F_1: 0.9915\n",
            "[2500/3000]: Training Loss:  0.1861, Training Precision: 0.9955, Training Recall: 0.9955, Training F_1: 0.9955\n",
            "[3000/3000]: Training Loss:  0.2612, Training Precision: 0.9898, Training Recall: 0.9898, Training F_1: 0.9898\n",
            "Epoch training time: 274.07 s.\n",
            "############ Val Loss:  1.5844, Val Precision: 0.9607, Val Recall: 0.9607, Val F_1: 0.9607\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 10/10\n",
            "[ 500/3000]: Training Loss:  0.3265, Training Precision: 0.9917, Training Recall: 0.9917, Training F_1: 0.9917\n",
            "[1000/3000]: Training Loss:  0.2152, Training Precision: 0.9893, Training Recall: 0.9893, Training F_1: 0.9893\n",
            "[1500/3000]: Training Loss:  0.1960, Training Precision: 0.9957, Training Recall: 0.9957, Training F_1: 0.9957\n",
            "[2000/3000]: Training Loss:  0.3054, Training Precision: 0.9924, Training Recall: 0.9924, Training F_1: 0.9924\n",
            "[2500/3000]: Training Loss:  0.1539, Training Precision: 0.9955, Training Recall: 0.9955, Training F_1: 0.9955\n",
            "[3000/3000]: Training Loss:  0.1884, Training Precision: 0.9950, Training Recall: 0.9950, Training F_1: 0.9950\n",
            "Epoch training time: 273.21 s.\n",
            "############ Val Loss:  1.2419, Val Precision: 0.9681, Val Recall: 0.9681, Val F_1: 0.9681\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Training complete in 47m 52s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBx58E8_-whQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load trained model from current runtime, or download from Google Drive\n",
        "# please define the model first, then load\n",
        "try:\n",
        "    model = torch.load('The_10_epoch_model.pt')\n",
        "except:\n",
        "    id = '1zJx5WHfvz46X9jKbiSvYUOEzqgs4LY87'\n",
        "    downloaded = drive.CreateFile({'id': id})\n",
        "    downloaded.GetContentFile('The_10_epoch_model.pt')\n",
        "    model = torch.load('The_10_epoch_model.pt')\n",
        "\n",
        "# predict on test set, result files should in the file list\n",
        "predict(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4jaKpvd6iV0",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK_aldRO4YA7",
        "colab_type": "text"
      },
      "source": [
        "# **2. below is testing logs**\n",
        "\n",
        "some logs may be covered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3ILlf-han6r",
        "colab_type": "text"
      },
      "source": [
        "### **word_emb+pos+dep+tag+shape+tf_idf**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwoFM9VxazC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embeddings(sentence, index, flag, emb_dim):\n",
        "    N = len(sentence.split())\n",
        "    sentence_emb = torch.empty((0, emb_dim), dtype=torch.float32)\n",
        "    parse = nlp(sentence)\n",
        "    for token in parse:\n",
        "        word_emb = gensim_emb(str(token))\n",
        "        pos_emb = get_pos(token, parse)\n",
        "        dep_emb = get_dep(token, parse)\n",
        "        tag_emb = get_tag(token, parse)\n",
        "        shape_emb = get_shape(token, parse)\n",
        "        tf_idf_emb = get_tf_idf(token, parse, index, flag)\n",
        "        embeddings = torch.cat((word_emb, pos_emb, dep_emb, tag_emb, shape_emb, tf_idf_emb), axis=-1).view(1, -1)\n",
        "        sentence_emb = torch.cat((sentence_emb, embeddings), axis=0)\n",
        "    return sentence_emb.view(N, 1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XgjP0yianpD",
        "colab_type": "code",
        "outputId": "d626990d-f710-43c9-aba5-171a28110f2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "HIDDEN_DIM = 512\n",
        "EMBEDDING_DIM = 417\n",
        "\n",
        "model = BiLSTM_CRF(tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, layers=1)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "train_model(model, device, optimizer, num_epochs=10, emb_dim=EMBEDDING_DIM)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "[ 500/3000]: Training Loss:  5.9122, Training Precision: 0.8501, Training Recall: 0.8501, Training F_1: 0.8501\n",
            "[1000/3000]: Training Loss:  1.9064, Training Precision: 0.9223, Training Recall: 0.9223, Training F_1: 0.9223\n",
            "[1500/3000]: Training Loss:  2.1637, Training Precision: 0.9447, Training Recall: 0.9447, Training F_1: 0.9447\n",
            "[2000/3000]: Training Loss:  2.1571, Training Precision: 0.9477, Training Recall: 0.9477, Training F_1: 0.9477\n",
            "[2500/3000]: Training Loss:  1.2708, Training Precision: 0.9414, Training Recall: 0.9414, Training F_1: 0.9414\n",
            "[3000/3000]: Training Loss:  1.4996, Training Precision: 0.9599, Training Recall: 0.9599, Training F_1: 0.9599\n",
            "Epoch training time: 218.36 s.\n",
            "############ Val Loss:  1.3861, Val Precision: 0.9571, Val Recall: 0.9571, Val F_1: 0.9571\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 2/10\n",
            "[ 500/3000]: Training Loss:  1.6917, Training Precision: 0.9392, Training Recall: 0.9392, Training F_1: 0.9392\n",
            "[1000/3000]: Training Loss:  0.9303, Training Precision: 0.9584, Training Recall: 0.9584, Training F_1: 0.9584\n",
            "[1500/3000]: Training Loss:  1.2244, Training Precision: 0.9691, Training Recall: 0.9691, Training F_1: 0.9691\n",
            "[2000/3000]: Training Loss:  1.5264, Training Precision: 0.9641, Training Recall: 0.9641, Training F_1: 0.9641\n",
            "[2500/3000]: Training Loss:  0.8552, Training Precision: 0.9596, Training Recall: 0.9596, Training F_1: 0.9596\n",
            "[3000/3000]: Training Loss:  1.1370, Training Precision: 0.9681, Training Recall: 0.9681, Training F_1: 0.9681\n",
            "Epoch training time: 219.38 s.\n",
            "############ Val Loss:  1.2452, Val Precision: 0.9603, Val Recall: 0.9603, Val F_1: 0.9603\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 3/10\n",
            "[ 500/3000]: Training Loss:  1.3234, Training Precision: 0.9510, Training Recall: 0.9510, Training F_1: 0.9510\n",
            "[1000/3000]: Training Loss:  0.6900, Training Precision: 0.9717, Training Recall: 0.9717, Training F_1: 0.9717\n",
            "[1500/3000]: Training Loss:  0.9377, Training Precision: 0.9817, Training Recall: 0.9817, Training F_1: 0.9817\n",
            "[2000/3000]: Training Loss:  1.2719, Training Precision: 0.9690, Training Recall: 0.9690, Training F_1: 0.9690\n",
            "[2500/3000]: Training Loss:  0.6380, Training Precision: 0.9735, Training Recall: 0.9735, Training F_1: 0.9735\n",
            "[3000/3000]: Training Loss:  0.8904, Training Precision: 0.9761, Training Recall: 0.9761, Training F_1: 0.9761\n",
            "Epoch training time: 219.12 s.\n",
            "############ Val Loss:  1.1932, Val Precision: 0.9607, Val Recall: 0.9607, Val F_1: 0.9607\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 4/10\n",
            "[ 500/3000]: Training Loss:  1.0661, Training Precision: 0.9637, Training Recall: 0.9637, Training F_1: 0.9637\n",
            "[1000/3000]: Training Loss:  0.5736, Training Precision: 0.9792, Training Recall: 0.9792, Training F_1: 0.9792\n",
            "[1500/3000]: Training Loss:  0.7626, Training Precision: 0.9819, Training Recall: 0.9819, Training F_1: 0.9819\n",
            "[2000/3000]: Training Loss:  1.0235, Training Precision: 0.9762, Training Recall: 0.9762, Training F_1: 0.9762\n",
            "[2500/3000]: Training Loss:  0.5182, Training Precision: 0.9804, Training Recall: 0.9804, Training F_1: 0.9804\n",
            "[3000/3000]: Training Loss:  0.6816, Training Precision: 0.9800, Training Recall: 0.9800, Training F_1: 0.9800\n",
            "Epoch training time: 215.19 s.\n",
            "############ Val Loss:  1.1778, Val Precision: 0.9625, Val Recall: 0.9625, Val F_1: 0.9625\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 5/10\n",
            "[ 500/3000]: Training Loss:  0.8605, Training Precision: 0.9670, Training Recall: 0.9670, Training F_1: 0.9670\n",
            "[1000/3000]: Training Loss:  0.4642, Training Precision: 0.9771, Training Recall: 0.9771, Training F_1: 0.9771\n",
            "[1500/3000]: Training Loss:  0.6346, Training Precision: 0.9855, Training Recall: 0.9855, Training F_1: 0.9855\n",
            "[2000/3000]: Training Loss:  0.8201, Training Precision: 0.9798, Training Recall: 0.9798, Training F_1: 0.9798\n",
            "[2500/3000]: Training Loss:  0.4178, Training Precision: 0.9861, Training Recall: 0.9861, Training F_1: 0.9861\n",
            "[3000/3000]: Training Loss:  0.5397, Training Precision: 0.9859, Training Recall: 0.9859, Training F_1: 0.9859\n",
            "Epoch training time: 212.28 s.\n",
            "############ Val Loss:  1.1129, Val Precision: 0.9655, Val Recall: 0.9655, Val F_1: 0.9655\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 6/10\n",
            "[ 500/3000]: Training Loss:  0.7018, Training Precision: 0.9709, Training Recall: 0.9709, Training F_1: 0.9709\n",
            "[1000/3000]: Training Loss:  0.3634, Training Precision: 0.9840, Training Recall: 0.9840, Training F_1: 0.9840\n",
            "[1500/3000]: Training Loss:  0.4924, Training Precision: 0.9866, Training Recall: 0.9866, Training F_1: 0.9866\n",
            "[2000/3000]: Training Loss:  0.6978, Training Precision: 0.9820, Training Recall: 0.9820, Training F_1: 0.9820\n",
            "[2500/3000]: Training Loss:  0.3425, Training Precision: 0.9891, Training Recall: 0.9891, Training F_1: 0.9891\n",
            "[3000/3000]: Training Loss:  0.4253, Training Precision: 0.9874, Training Recall: 0.9874, Training F_1: 0.9874\n",
            "Epoch training time: 214.93 s.\n",
            "############ Val Loss:  1.0997, Val Precision: 0.9660, Val Recall: 0.9660, Val F_1: 0.9660\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 7/10\n",
            "[ 500/3000]: Training Loss:  0.5199, Training Precision: 0.9802, Training Recall: 0.9802, Training F_1: 0.9802\n",
            "[1000/3000]: Training Loss:  0.3179, Training Precision: 0.9852, Training Recall: 0.9852, Training F_1: 0.9852\n",
            "[1500/3000]: Training Loss:  0.4017, Training Precision: 0.9900, Training Recall: 0.9900, Training F_1: 0.9900\n",
            "[2000/3000]: Training Loss:  0.5608, Training Precision: 0.9863, Training Recall: 0.9863, Training F_1: 0.9863\n",
            "[2500/3000]: Training Loss:  0.2683, Training Precision: 0.9900, Training Recall: 0.9900, Training F_1: 0.9900\n",
            "[3000/3000]: Training Loss:  0.3268, Training Precision: 0.9914, Training Recall: 0.9914, Training F_1: 0.9914\n",
            "Epoch training time: 216.36 s.\n",
            "############ Val Loss:  1.0532, Val Precision: 0.9706, Val Recall: 0.9706, Val F_1: 0.9706\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 8/10\n",
            "[ 500/3000]: Training Loss:  0.4212, Training Precision: 0.9793, Training Recall: 0.9793, Training F_1: 0.9793\n",
            "[1000/3000]: Training Loss:  0.2649, Training Precision: 0.9849, Training Recall: 0.9849, Training F_1: 0.9849\n",
            "[1500/3000]: Training Loss:  0.2934, Training Precision: 0.9931, Training Recall: 0.9931, Training F_1: 0.9931\n",
            "[2000/3000]: Training Loss:  0.4340, Training Precision: 0.9908, Training Recall: 0.9908, Training F_1: 0.9908\n",
            "[2500/3000]: Training Loss:  0.2122, Training Precision: 0.9929, Training Recall: 0.9929, Training F_1: 0.9929\n",
            "[3000/3000]: Training Loss:  0.3049, Training Precision: 0.9925, Training Recall: 0.9925, Training F_1: 0.9925\n",
            "Epoch training time: 220.75 s.\n",
            "############ Val Loss:  1.0671, Val Precision: 0.9685, Val Recall: 0.9685, Val F_1: 0.9685\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 9/10\n",
            "[ 500/3000]: Training Loss:  0.3404, Training Precision: 0.9767, Training Recall: 0.9767, Training F_1: 0.9767\n",
            "[1000/3000]: Training Loss:  0.2220, Training Precision: 0.9898, Training Recall: 0.9898, Training F_1: 0.9898\n",
            "[1500/3000]: Training Loss:  0.2450, Training Precision: 0.9944, Training Recall: 0.9944, Training F_1: 0.9944\n",
            "[2000/3000]: Training Loss:  0.3432, Training Precision: 0.9925, Training Recall: 0.9925, Training F_1: 0.9925\n",
            "[2500/3000]: Training Loss:  0.1778, Training Precision: 0.9884, Training Recall: 0.9884, Training F_1: 0.9884\n",
            "[3000/3000]: Training Loss:  0.2122, Training Precision: 0.9941, Training Recall: 0.9941, Training F_1: 0.9941\n",
            "Epoch training time: 218.14 s.\n",
            "############ Val Loss:  1.0377, Val Precision: 0.9715, Val Recall: 0.9715, Val F_1: 0.9715\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 10/10\n",
            "[ 500/3000]: Training Loss:  0.2388, Training Precision: 0.9841, Training Recall: 0.9841, Training F_1: 0.9841\n",
            "[1000/3000]: Training Loss:  0.1790, Training Precision: 0.9904, Training Recall: 0.9904, Training F_1: 0.9904\n",
            "[1500/3000]: Training Loss:  0.1739, Training Precision: 0.9961, Training Recall: 0.9961, Training F_1: 0.9961\n",
            "[2000/3000]: Training Loss:  0.2796, Training Precision: 0.9898, Training Recall: 0.9898, Training F_1: 0.9898\n",
            "[2500/3000]: Training Loss:  0.1237, Training Precision: 0.9947, Training Recall: 0.9947, Training F_1: 0.9947\n",
            "[3000/3000]: Training Loss:  0.1756, Training Precision: 0.9958, Training Recall: 0.9958, Training F_1: 0.9958\n",
            "Epoch training time: 219.73 s.\n",
            "############ Val Loss:  1.1001, Val Precision: 0.9714, Val Recall: 0.9714, Val F_1: 0.9714\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Training complete in 38m 52s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdXUHHBqmqxy",
        "colab_type": "code",
        "outputId": "d51c8f59-7b0b-4735-afd1-2ee4fc20ff2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "model = torch.load('The_7_epoch_model.pt')\n",
        "predict(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5d066bfed3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The_7_epoch_model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rEepkiwS9sJ",
        "colab_type": "text"
      },
      "source": [
        "### **attention**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjQ1CXCjAp78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, tag_to_ix, embedding_dim, hidden_dim, heads, layers=1):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        self.layers = layers\n",
        "        # self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=self.layers, bidirectional=True)\n",
        "        self.attn = nn.MultiheadAttention(embedding_dim, num_heads=10)\n",
        "        self.attn2 = nn.MultiheadAttention(hidden_dim, num_heads=8)\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "        \n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def argmax(self, vec):\n",
        "        # return the argmax as a python int\n",
        "        _, idx = torch.max(vec, 1)\n",
        "        return idx.item()\n",
        "    \n",
        "    # Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "    def log_sum_exp(self, vec):\n",
        "        max_score = vec[0, self.argmax(vec)]\n",
        "        max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "        return max_score + \\\n",
        "            torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2 * self.layers, 1, self.hidden_dim // 2),\n",
        "                torch.randn(2 * self.layers, 1, self.hidden_dim // 2))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(self.log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = self.log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        # embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        # lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        attn_output, _ = self.attn(sentence, sentence, sentence)\n",
        "        lstm_out, self.hidden = self.lstm(attn_output, self.hidden)\n",
        "        # print(lstm_out.shape)\n",
        "\n",
        "        # cat = torch.cat((self.hidden[0][0,:,:], self.hidden[0][1,:,:]), 1)\n",
        "        # attn_output2, _ = self.attn2(lstm_out, cat, cat)\n",
        "\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = self.argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = self.argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(feats)\n",
        "        return forward_score - gold_score, tag_seq\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4xUTNbhrANM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embeddings(sentence, index, flag, emb_dim):\n",
        "    N = len(sentence.split())\n",
        "    sentence_emb = torch.empty((0, emb_dim), dtype=torch.float32)\n",
        "    parse = nlp(sentence)\n",
        "    for token in parse:\n",
        "        word_emb = gensim_emb(str(token))\n",
        "        pos_emb = get_pos(token, parse)\n",
        "        dep_emb = get_dep(token, parse)\n",
        "        tag_emb = get_tag(token, parse)\n",
        "        shape_emb = get_shape(token, parse)\n",
        "        tf_idf_emb = get_tf_idf(token, parse, index, flag)\n",
        "        pad_emb = torch.FloatTensor([0., 0., 0.])\n",
        "        embeddings = torch.cat((word_emb, pos_emb, dep_emb, tag_emb, shape_emb, tf_idf_emb, pad_emb), axis=-1).view(1, -1)\n",
        "        sentence_emb = torch.cat((sentence_emb, embeddings), axis=0)\n",
        "    return sentence_emb.view(N, 1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXv_dWMxBkzS",
        "colab_type": "code",
        "outputId": "6212401a-15b2-4afb-fc9f-6a7441610870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "HIDDEN_DIM = 512\n",
        "EMBEDDING_DIM = 420\n",
        "\n",
        "model = BiLSTM_CRF(tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, heads=10, layers=1)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "train_model(model, device, optimizer, num_epochs=10, emb_dim=EMBEDDING_DIM)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "[ 500/3000]: Training Loss:  9.1503, Training Precision: 0.7504, Training Recall: 0.7504, Training F_1: 0.7504\n",
            "[1000/3000]: Training Loss:  7.9898, Training Precision: 0.6859, Training Recall: 0.6859, Training F_1: 0.6859\n",
            "[1500/3000]: Training Loss:  7.0877, Training Precision: 0.8760, Training Recall: 0.8760, Training F_1: 0.8760\n",
            "[2000/3000]: Training Loss:  4.5720, Training Precision: 0.8965, Training Recall: 0.8965, Training F_1: 0.8965\n",
            "[2500/3000]: Training Loss:  2.8306, Training Precision: 0.8860, Training Recall: 0.8860, Training F_1: 0.8860\n",
            "[3000/3000]: Training Loss:  2.9944, Training Precision: 0.9173, Training Recall: 0.9173, Training F_1: 0.9173\n",
            "Epoch training time: 213.10 s.\n",
            "############ Val Loss:  2.7358, Val Precision: 0.9097, Val Recall: 0.9097, Val F_1: 0.9097\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 2/10\n",
            "[ 500/3000]: Training Loss:  3.3028, Training Precision: 0.9018, Training Recall: 0.9018, Training F_1: 0.9018\n",
            "[1000/3000]: Training Loss:  1.7336, Training Precision: 0.9371, Training Recall: 0.9371, Training F_1: 0.9371\n",
            "[1500/3000]: Training Loss:  2.1917, Training Precision: 0.9412, Training Recall: 0.9412, Training F_1: 0.9412\n",
            "[2000/3000]: Training Loss:  2.5363, Training Precision: 0.9450, Training Recall: 0.9450, Training F_1: 0.9450\n",
            "[2500/3000]: Training Loss:  1.4843, Training Precision: 0.9332, Training Recall: 0.9332, Training F_1: 0.9332\n",
            "[3000/3000]: Training Loss:  1.8257, Training Precision: 0.9532, Training Recall: 0.9532, Training F_1: 0.9532\n",
            "Epoch training time: 213.69 s.\n",
            "############ Val Loss:  1.8842, Val Precision: 0.9322, Val Recall: 0.9322, Val F_1: 0.9322\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 3/10\n",
            "[ 500/3000]: Training Loss:  2.1886, Training Precision: 0.9303, Training Recall: 0.9303, Training F_1: 0.9303\n",
            "[1000/3000]: Training Loss:  1.0503, Training Precision: 0.9643, Training Recall: 0.9643, Training F_1: 0.9643\n",
            "[1500/3000]: Training Loss:  1.4027, Training Precision: 0.9693, Training Recall: 0.9693, Training F_1: 0.9693\n",
            "[2000/3000]: Training Loss:  1.9250, Training Precision: 0.9603, Training Recall: 0.9603, Training F_1: 0.9603\n",
            "[2500/3000]: Training Loss:  0.9474, Training Precision: 0.9628, Training Recall: 0.9628, Training F_1: 0.9628\n",
            "[3000/3000]: Training Loss:  1.2930, Training Precision: 0.9676, Training Recall: 0.9676, Training F_1: 0.9676\n",
            "Epoch training time: 214.19 s.\n",
            "############ Val Loss:  1.6781, Val Precision: 0.9395, Val Recall: 0.9395, Val F_1: 0.9395\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 4/10\n",
            "[ 500/3000]: Training Loss:  1.6305, Training Precision: 0.9457, Training Recall: 0.9457, Training F_1: 0.9457\n",
            "[1000/3000]: Training Loss:  0.7535, Training Precision: 0.9753, Training Recall: 0.9753, Training F_1: 0.9753\n",
            "[1500/3000]: Training Loss:  1.0758, Training Precision: 0.9771, Training Recall: 0.9771, Training F_1: 0.9771\n",
            "[2000/3000]: Training Loss:  1.4682, Training Precision: 0.9704, Training Recall: 0.9704, Training F_1: 0.9704\n",
            "[2500/3000]: Training Loss:  0.6513, Training Precision: 0.9755, Training Recall: 0.9755, Training F_1: 0.9755\n",
            "[3000/3000]: Training Loss:  1.0145, Training Precision: 0.9729, Training Recall: 0.9729, Training F_1: 0.9729\n",
            "Epoch training time: 214.41 s.\n",
            "############ Val Loss:  1.3286, Val Precision: 0.9557, Val Recall: 0.9557, Val F_1: 0.9557\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 5/10\n",
            "[ 500/3000]: Training Loss:  1.2668, Training Precision: 0.9593, Training Recall: 0.9593, Training F_1: 0.9593\n",
            "[1000/3000]: Training Loss:  0.6053, Training Precision: 0.9781, Training Recall: 0.9781, Training F_1: 0.9781\n",
            "[1500/3000]: Training Loss:  0.8712, Training Precision: 0.9798, Training Recall: 0.9798, Training F_1: 0.9798\n",
            "[2000/3000]: Training Loss:  1.2060, Training Precision: 0.9737, Training Recall: 0.9737, Training F_1: 0.9737\n",
            "[2500/3000]: Training Loss:  0.4575, Training Precision: 0.9844, Training Recall: 0.9844, Training F_1: 0.9844\n",
            "[3000/3000]: Training Loss:  0.8146, Training Precision: 0.9797, Training Recall: 0.9797, Training F_1: 0.9797\n",
            "Epoch training time: 215.00 s.\n",
            "############ Val Loss:  1.4707, Val Precision: 0.9473, Val Recall: 0.9473, Val F_1: 0.9473\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 6/10\n",
            "[ 500/3000]: Training Loss:  1.0549, Training Precision: 0.9607, Training Recall: 0.9607, Training F_1: 0.9607\n",
            "[1000/3000]: Training Loss:  0.4897, Training Precision: 0.9818, Training Recall: 0.9818, Training F_1: 0.9818\n",
            "[1500/3000]: Training Loss:  0.7365, Training Precision: 0.9889, Training Recall: 0.9889, Training F_1: 0.9889\n",
            "[2000/3000]: Training Loss:  1.0169, Training Precision: 0.9802, Training Recall: 0.9802, Training F_1: 0.9802\n",
            "[2500/3000]: Training Loss:  0.3566, Training Precision: 0.9906, Training Recall: 0.9906, Training F_1: 0.9906\n",
            "[3000/3000]: Training Loss:  0.6847, Training Precision: 0.9835, Training Recall: 0.9835, Training F_1: 0.9835\n",
            "Epoch training time: 215.18 s.\n",
            "############ Val Loss:  1.4900, Val Precision: 0.9516, Val Recall: 0.9516, Val F_1: 0.9516\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 7/10\n",
            "[ 500/3000]: Training Loss:  0.8495, Training Precision: 0.9711, Training Recall: 0.9711, Training F_1: 0.9711\n",
            "[1000/3000]: Training Loss:  0.4636, Training Precision: 0.9837, Training Recall: 0.9837, Training F_1: 0.9837\n",
            "[1500/3000]: Training Loss:  0.6745, Training Precision: 0.9902, Training Recall: 0.9902, Training F_1: 0.9902\n",
            "[2000/3000]: Training Loss:  0.8285, Training Precision: 0.9832, Training Recall: 0.9832, Training F_1: 0.9832\n",
            "[2500/3000]: Training Loss:  0.3588, Training Precision: 0.9912, Training Recall: 0.9912, Training F_1: 0.9912\n",
            "[3000/3000]: Training Loss:  0.6000, Training Precision: 0.9870, Training Recall: 0.9870, Training F_1: 0.9870\n",
            "Epoch training time: 214.54 s.\n",
            "############ Val Loss:  1.5873, Val Precision: 0.9476, Val Recall: 0.9476, Val F_1: 0.9476\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 8/10\n",
            "[ 500/3000]: Training Loss:  0.7315, Training Precision: 0.9723, Training Recall: 0.9723, Training F_1: 0.9723\n",
            "[1000/3000]: Training Loss:  0.3340, Training Precision: 0.9893, Training Recall: 0.9893, Training F_1: 0.9893\n",
            "[1500/3000]: Training Loss:  0.5785, Training Precision: 0.9921, Training Recall: 0.9921, Training F_1: 0.9921\n",
            "[2000/3000]: Training Loss:  0.7603, Training Precision: 0.9821, Training Recall: 0.9821, Training F_1: 0.9821\n",
            "[2500/3000]: Training Loss:  0.3091, Training Precision: 0.9884, Training Recall: 0.9884, Training F_1: 0.9884\n",
            "[3000/3000]: Training Loss:  0.5297, Training Precision: 0.9889, Training Recall: 0.9889, Training F_1: 0.9889\n",
            "Epoch training time: 215.58 s.\n",
            "############ Val Loss:  1.7704, Val Precision: 0.9484, Val Recall: 0.9484, Val F_1: 0.9484\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 9/10\n",
            "[ 500/3000]: Training Loss:  0.5909, Training Precision: 0.9779, Training Recall: 0.9779, Training F_1: 0.9779\n",
            "[1000/3000]: Training Loss:  0.2861, Training Precision: 0.9911, Training Recall: 0.9911, Training F_1: 0.9911\n",
            "[1500/3000]: Training Loss:  0.5023, Training Precision: 0.9920, Training Recall: 0.9920, Training F_1: 0.9920\n",
            "[2000/3000]: Training Loss:  0.7512, Training Precision: 0.9847, Training Recall: 0.9847, Training F_1: 0.9847\n",
            "[2500/3000]: Training Loss:  0.2274, Training Precision: 0.9934, Training Recall: 0.9934, Training F_1: 0.9934\n",
            "[3000/3000]: Training Loss:  0.4222, Training Precision: 0.9914, Training Recall: 0.9914, Training F_1: 0.9914\n",
            "Epoch training time: 214.85 s.\n",
            "############ Val Loss:  1.5114, Val Precision: 0.9554, Val Recall: 0.9554, Val F_1: 0.9554\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 10/10\n",
            "[ 500/3000]: Training Loss:  0.5477, Training Precision: 0.9777, Training Recall: 0.9777, Training F_1: 0.9777\n",
            "[1000/3000]: Training Loss:  0.2429, Training Precision: 0.9874, Training Recall: 0.9874, Training F_1: 0.9874\n",
            "[1500/3000]: Training Loss:  0.4563, Training Precision: 0.9923, Training Recall: 0.9923, Training F_1: 0.9923\n",
            "[2000/3000]: Training Loss:  0.5680, Training Precision: 0.9874, Training Recall: 0.9874, Training F_1: 0.9874\n",
            "[2500/3000]: Training Loss:  0.2081, Training Precision: 0.9929, Training Recall: 0.9929, Training F_1: 0.9929\n",
            "[3000/3000]: Training Loss:  0.4387, Training Precision: 0.9890, Training Recall: 0.9890, Training F_1: 0.9890\n",
            "Epoch training time: 215.29 s.\n",
            "############ Val Loss:  1.9280, Val Precision: 0.9473, Val Recall: 0.9473, Val F_1: 0.9473\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Training complete in 38m 18s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCouH21b1Q8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.load('The_4_epoch_model.pt')\n",
        "predict(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diXEdVkf2Qoh",
        "colab_type": "text"
      },
      "source": [
        "### **attention lstm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br0MQPrF2QXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, tag_to_ix, embedding_dim, hidden_dim, heads, layers=1):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        self.layers = layers\n",
        "        # self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=self.layers, bidirectional=True)\n",
        "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim // 2,\n",
        "                            num_layers=self.layers, bidirectional=True)\n",
        "        self.attn = nn.MultiheadAttention(embedding_dim, num_heads=10)\n",
        "        self.attn2 = nn.MultiheadAttention(hidden_dim, num_heads=8)\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "        \n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def argmax(self, vec):\n",
        "        # return the argmax as a python int\n",
        "        _, idx = torch.max(vec, 1)\n",
        "        return idx.item()\n",
        "    \n",
        "    # Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "    def log_sum_exp(self, vec):\n",
        "        max_score = vec[0, self.argmax(vec)]\n",
        "        max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "        return max_score + \\\n",
        "            torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2 * self.layers, 1, self.hidden_dim // 2),\n",
        "                torch.randn(2 * self.layers, 1, self.hidden_dim // 2))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(self.log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = self.log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        # embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        # lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        # attn_output, _ = self.attn(sentence, sentence, sentence)\n",
        "        lstm_out, self.hidden = self.lstm(sentence, self.hidden)\n",
        "        # print(lstm_out.shape)\n",
        "        # print(self.hidden[0].shape)\n",
        "        cat = torch.cat((self.hidden[0][0,:,:], self.hidden[0][1,:,:]), 1)\n",
        "        # print(cat.shape)\n",
        "        attn_output, _ = self.attn2(lstm_out, cat, cat)\n",
        "        # cat = torch.cat((self.hidden[0][0,:,:], self.hidden[0][1,:,:]), 1)\n",
        "        # attn_output2, _ = self.attn2(lstm_out, cat, cat)\n",
        "        lstm_out2, _ = self.lstm2(attn_output, self.hidden)\n",
        "        lstm_out = lstm_out2.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = self.argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = self.argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(feats)\n",
        "        return forward_score - gold_score, tag_seq\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xZYaBC93aro",
        "colab_type": "code",
        "outputId": "63191db0-39af-4c2b-fa5e-2796b7869abe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "HIDDEN_DIM = 512\n",
        "EMBEDDING_DIM = 420\n",
        "\n",
        "model = BiLSTM_CRF(tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, heads=10, layers=1)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "train_model(model, device, optimizer, num_epochs=10, emb_dim=EMBEDDING_DIM)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "[ 500/3000]: Training Loss:  9.2271, Training Precision: 0.7374, Training Recall: 0.7374, Training F_1: 0.7374\n",
            "[1000/3000]: Training Loss:  7.9901, Training Precision: 0.6854, Training Recall: 0.6854, Training F_1: 0.6854\n",
            "[1500/3000]: Training Loss:  7.3823, Training Precision: 0.8562, Training Recall: 0.8562, Training F_1: 0.8562\n",
            "[2000/3000]: Training Loss:  7.4629, Training Precision: 0.8747, Training Recall: 0.8747, Training F_1: 0.8747\n",
            "[2500/3000]: Training Loss:  6.9847, Training Precision: 0.7442, Training Recall: 0.7442, Training F_1: 0.7442\n",
            "[3000/3000]: Training Loss:  7.2828, Training Precision: 0.7200, Training Recall: 0.7200, Training F_1: 0.7200\n",
            "Epoch training time: 316.17 s.\n",
            "############ Val Loss:  7.1270, Val Precision: 0.7675, Val Recall: 0.7675, Val F_1: 0.7675\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 2/10\n",
            "[ 500/3000]: Training Loss:  7.4035, Training Precision: 0.8166, Training Recall: 0.8166, Training F_1: 0.8166\n",
            "[1000/3000]: Training Loss:  6.7512, Training Precision: 0.7220, Training Recall: 0.7220, Training F_1: 0.7220\n",
            "[1500/3000]: Training Loss:  6.8940, Training Precision: 0.8922, Training Recall: 0.8922, Training F_1: 0.8922\n",
            "[2000/3000]: Training Loss:  7.0670, Training Precision: 0.8872, Training Recall: 0.8872, Training F_1: 0.8872\n",
            "[2500/3000]: Training Loss:  6.3442, Training Precision: 0.7744, Training Recall: 0.7744, Training F_1: 0.7744\n",
            "[3000/3000]: Training Loss:  6.7352, Training Precision: 0.7940, Training Recall: 0.7940, Training F_1: 0.7940\n",
            "Epoch training time: 315.84 s.\n",
            "############ Val Loss:  6.7119, Val Precision: 0.7900, Val Recall: 0.7900, Val F_1: 0.7900\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 3/10\n",
            "[ 500/3000]: Training Loss:  7.1847, Training Precision: 0.8227, Training Recall: 0.8227, Training F_1: 0.8227\n",
            "[1000/3000]: Training Loss:  6.1233, Training Precision: 0.7591, Training Recall: 0.7591, Training F_1: 0.7591\n",
            "[1500/3000]: Training Loss:  8.2994, Training Precision: 0.8654, Training Recall: 0.8654, Training F_1: 0.8654\n",
            "[2000/3000]: Training Loss:  7.4564, Training Precision: 0.8823, Training Recall: 0.8823, Training F_1: 0.8823\n",
            "[2500/3000]: Training Loss:  7.1934, Training Precision: 0.7456, Training Recall: 0.7456, Training F_1: 0.7456\n",
            "[3000/3000]: Training Loss:  7.2485, Training Precision: 0.7381, Training Recall: 0.7381, Training F_1: 0.7381\n",
            "Epoch training time: 313.64 s.\n",
            "############ Val Loss:  7.2096, Val Precision: 0.7722, Val Recall: 0.7722, Val F_1: 0.7722\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 4/10\n",
            "[ 500/3000]: Training Loss:  7.3995, Training Precision: 0.8232, Training Recall: 0.8232, Training F_1: 0.8232\n",
            "[1000/3000]: Training Loss:  6.8515, Training Precision: 0.7157, Training Recall: 0.7157, Training F_1: 0.7157\n",
            "[1500/3000]: Training Loss:  6.7705, Training Precision: 0.8928, Training Recall: 0.8928, Training F_1: 0.8928\n",
            "[2000/3000]: Training Loss:  7.2190, Training Precision: 0.8910, Training Recall: 0.8910, Training F_1: 0.8910\n",
            "[2500/3000]: Training Loss:  6.3573, Training Precision: 0.7747, Training Recall: 0.7747, Training F_1: 0.7747\n",
            "[3000/3000]: Training Loss:  6.3739, Training Precision: 0.7911, Training Recall: 0.7911, Training F_1: 0.7911\n",
            "Epoch training time: 316.92 s.\n",
            "############ Val Loss:  6.3610, Val Precision: 0.7965, Val Recall: 0.7965, Val F_1: 0.7965\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 5/10\n",
            "[ 500/3000]: Training Loss:  7.0076, Training Precision: 0.8357, Training Recall: 0.8357, Training F_1: 0.8357\n",
            "[1000/3000]: Training Loss:  6.1853, Training Precision: 0.7598, Training Recall: 0.7598, Training F_1: 0.7598\n",
            "[1500/3000]: Training Loss:  6.3060, Training Precision: 0.8980, Training Recall: 0.8980, Training F_1: 0.8980\n",
            "[2000/3000]: Training Loss:  6.7544, Training Precision: 0.8931, Training Recall: 0.8931, Training F_1: 0.8931\n",
            "[2500/3000]: Training Loss:  5.7539, Training Precision: 0.8095, Training Recall: 0.8095, Training F_1: 0.8095\n",
            "[3000/3000]: Training Loss:  5.6059, Training Precision: 0.8631, Training Recall: 0.8631, Training F_1: 0.8631\n",
            "Epoch training time: 313.98 s.\n",
            "############ Val Loss:  5.9744, Val Precision: 0.8049, Val Recall: 0.8049, Val F_1: 0.8049\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 6/10\n",
            "[ 500/3000]: Training Loss:  6.6854, Training Precision: 0.8410, Training Recall: 0.8410, Training F_1: 0.8410\n",
            "[1000/3000]: Training Loss:  5.7588, Training Precision: 0.7816, Training Recall: 0.7816, Training F_1: 0.7816\n",
            "[1500/3000]: Training Loss:  6.0575, Training Precision: 0.9057, Training Recall: 0.9057, Training F_1: 0.9057\n",
            "[2000/3000]: Training Loss:  6.4428, Training Precision: 0.8964, Training Recall: 0.8964, Training F_1: 0.8964\n",
            "[2500/3000]: Training Loss:  5.3870, Training Precision: 0.8253, Training Recall: 0.8253, Training F_1: 0.8253\n",
            "[3000/3000]: Training Loss:  5.1293, Training Precision: 0.8867, Training Recall: 0.8867, Training F_1: 0.8867\n",
            "Epoch training time: 315.22 s.\n",
            "############ Val Loss:  5.5117, Val Precision: 0.8131, Val Recall: 0.8131, Val F_1: 0.8131\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 7/10\n",
            "[ 500/3000]: Training Loss:  6.3273, Training Precision: 0.8461, Training Recall: 0.8461, Training F_1: 0.8461\n",
            "[1000/3000]: Training Loss:  5.4223, Training Precision: 0.7956, Training Recall: 0.7956, Training F_1: 0.7956\n",
            "[1500/3000]: Training Loss:  5.6612, Training Precision: 0.9119, Training Recall: 0.9119, Training F_1: 0.9119\n",
            "[2000/3000]: Training Loss:  6.2284, Training Precision: 0.9046, Training Recall: 0.9046, Training F_1: 0.9046\n",
            "[2500/3000]: Training Loss:  5.0370, Training Precision: 0.8416, Training Recall: 0.8416, Training F_1: 0.8416\n",
            "[3000/3000]: Training Loss:  4.8545, Training Precision: 0.8953, Training Recall: 0.8953, Training F_1: 0.8953\n",
            "Epoch training time: 313.29 s.\n",
            "############ Val Loss:  5.3121, Val Precision: 0.8313, Val Recall: 0.8313, Val F_1: 0.8313\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 8/10\n",
            "[ 500/3000]: Training Loss:  6.1009, Training Precision: 0.8592, Training Recall: 0.8592, Training F_1: 0.8592\n",
            "[1000/3000]: Training Loss:  5.1976, Training Precision: 0.8100, Training Recall: 0.8100, Training F_1: 0.8100\n",
            "[1500/3000]: Training Loss:  5.5335, Training Precision: 0.9100, Training Recall: 0.9100, Training F_1: 0.9100\n",
            "[2000/3000]: Training Loss:  5.9987, Training Precision: 0.9080, Training Recall: 0.9080, Training F_1: 0.9080\n",
            "[2500/3000]: Training Loss:  4.8092, Training Precision: 0.8558, Training Recall: 0.8558, Training F_1: 0.8558\n",
            "[3000/3000]: Training Loss:  4.5942, Training Precision: 0.9016, Training Recall: 0.9016, Training F_1: 0.9016\n",
            "Epoch training time: 315.86 s.\n",
            "############ Val Loss:  5.4722, Val Precision: 0.8422, Val Recall: 0.8422, Val F_1: 0.8422\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 9/10\n",
            "[ 500/3000]: Training Loss:  5.9148, Training Precision: 0.8532, Training Recall: 0.8532, Training F_1: 0.8532\n",
            "[1000/3000]: Training Loss:  4.9730, Training Precision: 0.8236, Training Recall: 0.8236, Training F_1: 0.8236\n",
            "[1500/3000]: Training Loss:  5.4886, Training Precision: 0.9129, Training Recall: 0.9129, Training F_1: 0.9129\n",
            "[2000/3000]: Training Loss:  5.8218, Training Precision: 0.9066, Training Recall: 0.9066, Training F_1: 0.9066\n",
            "[2500/3000]: Training Loss:  4.6537, Training Precision: 0.8671, Training Recall: 0.8671, Training F_1: 0.8671\n",
            "[3000/3000]: Training Loss:  4.6223, Training Precision: 0.8977, Training Recall: 0.8977, Training F_1: 0.8977\n",
            "Epoch training time: 313.72 s.\n",
            "############ Val Loss:  5.3453, Val Precision: 0.8082, Val Recall: 0.8082, Val F_1: 0.8082\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 10/10\n",
            "[ 500/3000]: Training Loss:  5.8151, Training Precision: 0.8592, Training Recall: 0.8592, Training F_1: 0.8592\n",
            "[1000/3000]: Training Loss:  4.8182, Training Precision: 0.8253, Training Recall: 0.8253, Training F_1: 0.8253\n",
            "[1500/3000]: Training Loss:  5.1530, Training Precision: 0.9190, Training Recall: 0.9190, Training F_1: 0.9190\n",
            "[2000/3000]: Training Loss:  5.6901, Training Precision: 0.9140, Training Recall: 0.9140, Training F_1: 0.9140\n",
            "[2500/3000]: Training Loss:  4.4250, Training Precision: 0.8780, Training Recall: 0.8780, Training F_1: 0.8780\n",
            "[3000/3000]: Training Loss:  4.2528, Training Precision: 0.9071, Training Recall: 0.9071, Training F_1: 0.9071\n",
            "Epoch training time: 315.31 s.\n",
            "############ Val Loss:  4.7650, Val Precision: 0.8415, Val Recall: 0.8415, Val F_1: 0.8415\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Training complete in 55m 26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtbQWv2325xm",
        "colab_type": "text"
      },
      "source": [
        "### **attention after lstm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOBrhQe626_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, tag_to_ix, embedding_dim, hidden_dim, heads, layers=1):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        self.layers = layers\n",
        "        # self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=self.layers, bidirectional=True)\n",
        "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim // 2,\n",
        "                            num_layers=self.layers, bidirectional=True)\n",
        "        self.attn = nn.MultiheadAttention(embedding_dim, num_heads=10)\n",
        "        self.attn2 = nn.MultiheadAttention(hidden_dim, num_heads=8)\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "        \n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def argmax(self, vec):\n",
        "        # return the argmax as a python int\n",
        "        _, idx = torch.max(vec, 1)\n",
        "        return idx.item()\n",
        "    \n",
        "    # Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "    def log_sum_exp(self, vec):\n",
        "        max_score = vec[0, self.argmax(vec)]\n",
        "        max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "        return max_score + \\\n",
        "            torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2 * self.layers, 1, self.hidden_dim // 2),\n",
        "                torch.randn(2 * self.layers, 1, self.hidden_dim // 2))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(self.log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = self.log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        # embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        # lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        # attn_output, _ = self.attn(sentence, sentence, sentence)\n",
        "        lstm_out, self.hidden = self.lstm(sentence, self.hidden)\n",
        "        # print(lstm_out.shape)\n",
        "        # print(self.hidden[0].shape)\n",
        "        # cat = torch.cat((self.hidden[0][0,:,:], self.hidden[0][1,:,:]), 1)\n",
        "        # print(cat.shape)\n",
        "        # attn_output, _ = self.attn2(lstm_out, cat, cat)\n",
        "        # cat = torch.cat((self.hidden[0][0,:,:], self.hidden[0][1,:,:]), 1)\n",
        "        # attn_output2, _ = self.attn2(lstm_out, cat, cat)\n",
        "        # self.hidden = self.init_hidden()\n",
        "        # lstm_out2, self.hidden = self.lstm2(lstm_out, self.hidden)\n",
        "        # cat = torch.cat((self.hidden[0][0,:,:], self.hidden[0][1,:,:]), 1)\n",
        "        attn_output, _ = self.attn2(lstm_out, lstm_out, lstm_out)\n",
        "        lstm_out = attn_output.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = self.argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = self.argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(feats)\n",
        "        return forward_score - gold_score, tag_seq\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gua3uBIb3TS1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2baa0806-f3b1-451c-9e85-ba6c1fcaf2a9"
      },
      "source": [
        "HIDDEN_DIM = 512\n",
        "EMBEDDING_DIM = 420\n",
        "\n",
        "model = BiLSTM_CRF(tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, heads=10, layers=1)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "train_model(model, device, optimizer, num_epochs=10, emb_dim=EMBEDDING_DIM)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "[ 500/3000]: Training Loss:  9.3941, Training Precision: 0.7757, Training Recall: 0.7757, Training F_1: 0.7757\n",
            "[1000/3000]: Training Loss:  7.9603, Training Precision: 0.6873, Training Recall: 0.6873, Training F_1: 0.6873\n",
            "[1500/3000]: Training Loss:  7.4042, Training Precision: 0.8791, Training Recall: 0.8791, Training F_1: 0.8791\n",
            "[2000/3000]: Training Loss:  7.5490, Training Precision: 0.8719, Training Recall: 0.8719, Training F_1: 0.8719\n",
            "[2500/3000]: Training Loss:  6.7966, Training Precision: 0.7555, Training Recall: 0.7555, Training F_1: 0.7555\n",
            "[3000/3000]: Training Loss:  7.2752, Training Precision: 0.7148, Training Recall: 0.7148, Training F_1: 0.7148\n",
            "Epoch training time: 218.04 s.\n",
            "############ Val Loss:  6.9544, Val Precision: 0.7536, Val Recall: 0.7536, Val F_1: 0.7536\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 2/10\n",
            "[ 500/3000]: Training Loss:  7.4084, Training Precision: 0.8158, Training Recall: 0.8158, Training F_1: 0.8158\n",
            "[1000/3000]: Training Loss:  6.8425, Training Precision: 0.7046, Training Recall: 0.7046, Training F_1: 0.7046\n",
            "[1500/3000]: Training Loss:  6.7906, Training Precision: 0.8877, Training Recall: 0.8877, Training F_1: 0.8877\n",
            "[2000/3000]: Training Loss:  7.1511, Training Precision: 0.8800, Training Recall: 0.8800, Training F_1: 0.8800\n",
            "[2500/3000]: Training Loss:  4.4311, Training Precision: 0.8224, Training Recall: 0.8224, Training F_1: 0.8224\n",
            "[3000/3000]: Training Loss:  3.3550, Training Precision: 0.9219, Training Recall: 0.9219, Training F_1: 0.9219\n",
            "Epoch training time: 216.91 s.\n",
            "############ Val Loss:  3.3365, Val Precision: 0.8686, Val Recall: 0.8686, Val F_1: 0.8686\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 3/10\n",
            "[ 500/3000]: Training Loss:  3.4940, Training Precision: 0.8987, Training Recall: 0.8987, Training F_1: 0.8987\n",
            "[1000/3000]: Training Loss:  2.1104, Training Precision: 0.9178, Training Recall: 0.9178, Training F_1: 0.9178\n",
            "[1500/3000]: Training Loss:  2.6491, Training Precision: 0.9412, Training Recall: 0.9412, Training F_1: 0.9412\n",
            "[2000/3000]: Training Loss:  3.0014, Training Precision: 0.9297, Training Recall: 0.9297, Training F_1: 0.9297\n",
            "[2500/3000]: Training Loss:  2.0984, Training Precision: 0.9195, Training Recall: 0.9195, Training F_1: 0.9195\n",
            "[3000/3000]: Training Loss:  2.2498, Training Precision: 0.9443, Training Recall: 0.9443, Training F_1: 0.9443\n",
            "Epoch training time: 219.29 s.\n",
            "############ Val Loss:  2.3413, Val Precision: 0.9218, Val Recall: 0.9218, Val F_1: 0.9218\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 4/10\n",
            "[ 500/3000]: Training Loss:  2.6363, Training Precision: 0.9157, Training Recall: 0.9157, Training F_1: 0.9157\n",
            "[1000/3000]: Training Loss:  1.5785, Training Precision: 0.9396, Training Recall: 0.9396, Training F_1: 0.9396\n",
            "[1500/3000]: Training Loss:  1.8914, Training Precision: 0.9549, Training Recall: 0.9549, Training F_1: 0.9549\n",
            "[2000/3000]: Training Loss:  2.2171, Training Precision: 0.9475, Training Recall: 0.9475, Training F_1: 0.9475\n",
            "[2500/3000]: Training Loss:  1.2828, Training Precision: 0.9528, Training Recall: 0.9528, Training F_1: 0.9528\n",
            "[3000/3000]: Training Loss:  1.6181, Training Precision: 0.9591, Training Recall: 0.9591, Training F_1: 0.9591\n",
            "Epoch training time: 218.57 s.\n",
            "############ Val Loss:  1.6538, Val Precision: 0.9410, Val Recall: 0.9410, Val F_1: 0.9410\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 5/10\n",
            "[ 500/3000]: Training Loss:  1.8903, Training Precision: 0.9350, Training Recall: 0.9350, Training F_1: 0.9350\n",
            "[1000/3000]: Training Loss:  1.1304, Training Precision: 0.9585, Training Recall: 0.9585, Training F_1: 0.9585\n",
            "[1500/3000]: Training Loss:  1.2761, Training Precision: 0.9697, Training Recall: 0.9697, Training F_1: 0.9697\n",
            "[2000/3000]: Training Loss:  1.7663, Training Precision: 0.9581, Training Recall: 0.9581, Training F_1: 0.9581\n",
            "[2500/3000]: Training Loss:  0.9480, Training Precision: 0.9561, Training Recall: 0.9561, Training F_1: 0.9561\n",
            "[3000/3000]: Training Loss:  1.2115, Training Precision: 0.9687, Training Recall: 0.9687, Training F_1: 0.9687\n",
            "Epoch training time: 216.99 s.\n",
            "############ Val Loss:  1.3984, Val Precision: 0.9502, Val Recall: 0.9502, Val F_1: 0.9502\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 6/10\n",
            "[ 500/3000]: Training Loss:  1.5373, Training Precision: 0.9451, Training Recall: 0.9451, Training F_1: 0.9451\n",
            "[1000/3000]: Training Loss:  0.8948, Training Precision: 0.9609, Training Recall: 0.9609, Training F_1: 0.9609\n",
            "[1500/3000]: Training Loss:  1.0338, Training Precision: 0.9765, Training Recall: 0.9765, Training F_1: 0.9765\n",
            "[2000/3000]: Training Loss:  1.5467, Training Precision: 0.9641, Training Recall: 0.9641, Training F_1: 0.9641\n",
            "[2500/3000]: Training Loss:  0.7357, Training Precision: 0.9714, Training Recall: 0.9714, Training F_1: 0.9714\n",
            "[3000/3000]: Training Loss:  1.0670, Training Precision: 0.9745, Training Recall: 0.9745, Training F_1: 0.9745\n",
            "Epoch training time: 218.44 s.\n",
            "############ Val Loss:  1.3571, Val Precision: 0.9502, Val Recall: 0.9502, Val F_1: 0.9502\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 7/10\n",
            "[ 500/3000]: Training Loss:  1.2670, Training Precision: 0.9547, Training Recall: 0.9547, Training F_1: 0.9547\n",
            "[1000/3000]: Training Loss:  0.7560, Training Precision: 0.9657, Training Recall: 0.9657, Training F_1: 0.9657\n",
            "[1500/3000]: Training Loss:  0.8536, Training Precision: 0.9819, Training Recall: 0.9819, Training F_1: 0.9819\n",
            "[2000/3000]: Training Loss:  1.3185, Training Precision: 0.9747, Training Recall: 0.9747, Training F_1: 0.9747\n",
            "[2500/3000]: Training Loss:  0.6078, Training Precision: 0.9660, Training Recall: 0.9660, Training F_1: 0.9660\n",
            "[3000/3000]: Training Loss:  0.7958, Training Precision: 0.9757, Training Recall: 0.9757, Training F_1: 0.9757\n",
            "Epoch training time: 216.69 s.\n",
            "############ Val Loss:  1.3945, Val Precision: 0.9541, Val Recall: 0.9541, Val F_1: 0.9541\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 8/10\n",
            "[ 500/3000]: Training Loss:  1.0537, Training Precision: 0.9614, Training Recall: 0.9614, Training F_1: 0.9614\n",
            "[1000/3000]: Training Loss:  0.6500, Training Precision: 0.9670, Training Recall: 0.9670, Training F_1: 0.9670\n",
            "[1500/3000]: Training Loss:  0.7579, Training Precision: 0.9833, Training Recall: 0.9833, Training F_1: 0.9833\n",
            "[2000/3000]: Training Loss:  1.1278, Training Precision: 0.9745, Training Recall: 0.9745, Training F_1: 0.9745\n",
            "[2500/3000]: Training Loss:  0.4936, Training Precision: 0.9804, Training Recall: 0.9804, Training F_1: 0.9804\n",
            "[3000/3000]: Training Loss:  0.6971, Training Precision: 0.9795, Training Recall: 0.9795, Training F_1: 0.9795\n",
            "Epoch training time: 216.89 s.\n",
            "############ Val Loss:  1.6643, Val Precision: 0.9485, Val Recall: 0.9485, Val F_1: 0.9485\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 9/10\n",
            "[ 500/3000]: Training Loss:  0.9298, Training Precision: 0.9629, Training Recall: 0.9629, Training F_1: 0.9629\n",
            "[1000/3000]: Training Loss:  0.5139, Training Precision: 0.9752, Training Recall: 0.9752, Training F_1: 0.9752\n",
            "[1500/3000]: Training Loss:  0.6711, Training Precision: 0.9850, Training Recall: 0.9850, Training F_1: 0.9850\n",
            "[2000/3000]: Training Loss:  0.9906, Training Precision: 0.9777, Training Recall: 0.9777, Training F_1: 0.9777\n",
            "[2500/3000]: Training Loss:  0.6262, Training Precision: 0.9785, Training Recall: 0.9785, Training F_1: 0.9785\n",
            "[3000/3000]: Training Loss:  0.6444, Training Precision: 0.9835, Training Recall: 0.9835, Training F_1: 0.9835\n",
            "Epoch training time: 218.71 s.\n",
            "############ Val Loss:  2.0068, Val Precision: 0.9485, Val Recall: 0.9485, Val F_1: 0.9485\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 10/10\n",
            "[ 500/3000]: Training Loss:  0.8272, Training Precision: 0.9720, Training Recall: 0.9720, Training F_1: 0.9720\n",
            "[1000/3000]: Training Loss:  0.4639, Training Precision: 0.9780, Training Recall: 0.9780, Training F_1: 0.9780\n",
            "[1500/3000]: Training Loss:  0.7303, Training Precision: 0.9793, Training Recall: 0.9793, Training F_1: 0.9793\n",
            "[2000/3000]: Training Loss:  0.7921, Training Precision: 0.9834, Training Recall: 0.9834, Training F_1: 0.9834\n",
            "[2500/3000]: Training Loss:  0.3977, Training Precision: 0.9800, Training Recall: 0.9800, Training F_1: 0.9800\n",
            "[3000/3000]: Training Loss:  0.5074, Training Precision: 0.9871, Training Recall: 0.9871, Training F_1: 0.9871\n",
            "Epoch training time: 216.69 s.\n",
            "############ Val Loss:  1.6707, Val Precision: 0.9538, Val Recall: 0.9538, Val F_1: 0.9538\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Training complete in 38m 48s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adzPD9My1Dfb",
        "colab_type": "text"
      },
      "source": [
        "### **2layer with attention**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsXF5pz90-sm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, tag_to_ix, embedding_dim, hidden_dim, heads=2, layers=1):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        self.layers = layers\n",
        "        self.heads = heads\n",
        "        # self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=self.layers, bidirectional=True)\n",
        "        # self.lstm2 = nn.LSTM(hidden_dim, hidden_dim // 2,\n",
        "        #                     num_layers=self.layers, bidirectional=True)\n",
        "        self.attn = nn.MultiheadAttention(embedding_dim, num_heads=self.heads)\n",
        "        # self.attn2 = nn.MultiheadAttention(hidden_dim, num_heads=8)\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "        \n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def argmax(self, vec):\n",
        "        # return the argmax as a python int\n",
        "        _, idx = torch.max(vec, 1)\n",
        "        return idx.item()\n",
        "    \n",
        "    # Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "    def log_sum_exp(self, vec):\n",
        "        max_score = vec[0, self.argmax(vec)]\n",
        "        max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "        return max_score + \\\n",
        "            torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2 * self.layers, 1, self.hidden_dim // 2),\n",
        "                torch.randn(2 * self.layers, 1, self.hidden_dim // 2))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(self.log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = self.log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        # embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        # lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        attn_output, _ = self.attn(sentence, sentence, sentence)\n",
        "        lstm_out, self.hidden = self.lstm(attn_output, self.hidden)\n",
        "        # print(lstm_out.shape)\n",
        "        # print(self.hidden[0].shape)\n",
        "        # cat = torch.cat((self.hidden[0][0,:,:], self.hidden[0][1,:,:]), 1)\n",
        "        # print(cat.shape)\n",
        "        # attn_output, _ = self.attn2(lstm_out, cat, cat)\n",
        "        # cat = torch.cat((self.hidden[0][0,:,:], self.hidden[0][1,:,:]), 1)\n",
        "        # attn_output2, _ = self.attn2(lstm_out, cat, cat)\n",
        "        # self.hidden = self.init_hidden()\n",
        "        # lstm_out2, self.hidden = self.lstm2(lstm_out, self.hidden)\n",
        "        # cat = torch.cat((self.hidden[0][0,:,:], self.hidden[0][1,:,:]), 1)\n",
        "        # attn_output, _ = self.attn2(lstm_out, lstm_out, lstm_out)\n",
        "        lstm_out1 = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out1)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = self.argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = self.argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(feats)\n",
        "        return forward_score - gold_score, tag_seq\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwd3bxUB1xTm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "91410b9f-3778-4a79-f1dd-4b5ceceb7afb"
      },
      "source": [
        "HIDDEN_DIM = 512\n",
        "EMBEDDING_DIM = 420\n",
        "\n",
        "model = BiLSTM_CRF(tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, heads=2, layers=2)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "train_model(model, device, optimizer, num_epochs=10, emb_dim=EMBEDDING_DIM)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "[ 500/3000]: Training Loss:  9.4092, Training Precision: 0.7636, Training Recall: 0.7636, Training F_1: 0.7636\n",
            "[1000/3000]: Training Loss:  8.1202, Training Precision: 0.6810, Training Recall: 0.6810, Training F_1: 0.6810\n",
            "[1500/3000]: Training Loss:  7.4021, Training Precision: 0.8553, Training Recall: 0.8553, Training F_1: 0.8553\n",
            "[2000/3000]: Training Loss:  7.4184, Training Precision: 0.8619, Training Recall: 0.8619, Training F_1: 0.8619\n",
            "[2500/3000]: Training Loss:  6.7341, Training Precision: 0.7524, Training Recall: 0.7524, Training F_1: 0.7524\n",
            "[3000/3000]: Training Loss:  4.4194, Training Precision: 0.8820, Training Recall: 0.8820, Training F_1: 0.8820\n",
            "Epoch training time: 295.18 s.\n",
            "############ Val Loss:  3.6652, Val Precision: 0.8516, Val Recall: 0.8516, Val F_1: 0.8516\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 2/10\n",
            "[ 500/3000]: Training Loss:  4.0966, Training Precision: 0.8672, Training Recall: 0.8672, Training F_1: 0.8672\n",
            "[1000/3000]: Training Loss:  2.3902, Training Precision: 0.8853, Training Recall: 0.8853, Training F_1: 0.8853\n",
            "[1500/3000]: Training Loss:  2.8750, Training Precision: 0.9335, Training Recall: 0.9335, Training F_1: 0.9335\n",
            "[2000/3000]: Training Loss:  3.1400, Training Precision: 0.9257, Training Recall: 0.9257, Training F_1: 0.9257\n",
            "[2500/3000]: Training Loss:  2.1064, Training Precision: 0.9022, Training Recall: 0.9022, Training F_1: 0.9022\n",
            "[3000/3000]: Training Loss:  2.1781, Training Precision: 0.9387, Training Recall: 0.9387, Training F_1: 0.9387\n",
            "Epoch training time: 297.92 s.\n",
            "############ Val Loss:  2.1994, Val Precision: 0.9309, Val Recall: 0.9309, Val F_1: 0.9309\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 3/10\n",
            "[ 500/3000]: Training Loss:  2.6056, Training Precision: 0.9137, Training Recall: 0.9137, Training F_1: 0.9137\n",
            "[1000/3000]: Training Loss:  1.4339, Training Precision: 0.9523, Training Recall: 0.9523, Training F_1: 0.9523\n",
            "[1500/3000]: Training Loss:  1.8165, Training Precision: 0.9545, Training Recall: 0.9545, Training F_1: 0.9545\n",
            "[2000/3000]: Training Loss:  2.2358, Training Precision: 0.9496, Training Recall: 0.9496, Training F_1: 0.9496\n",
            "[2500/3000]: Training Loss:  1.2587, Training Precision: 0.9446, Training Recall: 0.9446, Training F_1: 0.9446\n",
            "[3000/3000]: Training Loss:  1.5333, Training Precision: 0.9580, Training Recall: 0.9580, Training F_1: 0.9580\n",
            "Epoch training time: 295.22 s.\n",
            "############ Val Loss:  1.6967, Val Precision: 0.9383, Val Recall: 0.9383, Val F_1: 0.9383\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 4/10\n",
            "[ 500/3000]: Training Loss:  1.8729, Training Precision: 0.9399, Training Recall: 0.9399, Training F_1: 0.9399\n",
            "[1000/3000]: Training Loss:  0.9847, Training Precision: 0.9620, Training Recall: 0.9620, Training F_1: 0.9620\n",
            "[1500/3000]: Training Loss:  1.2769, Training Precision: 0.9747, Training Recall: 0.9747, Training F_1: 0.9747\n",
            "[2000/3000]: Training Loss:  1.7690, Training Precision: 0.9643, Training Recall: 0.9643, Training F_1: 0.9643\n",
            "[2500/3000]: Training Loss:  0.8705, Training Precision: 0.9636, Training Recall: 0.9636, Training F_1: 0.9636\n",
            "[3000/3000]: Training Loss:  1.1895, Training Precision: 0.9624, Training Recall: 0.9624, Training F_1: 0.9624\n",
            "Epoch training time: 297.10 s.\n",
            "############ Val Loss:  1.3780, Val Precision: 0.9496, Val Recall: 0.9496, Val F_1: 0.9496\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 5/10\n",
            "[ 500/3000]: Training Loss:  1.4382, Training Precision: 0.9498, Training Recall: 0.9498, Training F_1: 0.9498\n",
            "[1000/3000]: Training Loss:  0.7179, Training Precision: 0.9786, Training Recall: 0.9786, Training F_1: 0.9786\n",
            "[1500/3000]: Training Loss:  1.0021, Training Precision: 0.9802, Training Recall: 0.9802, Training F_1: 0.9802\n",
            "[2000/3000]: Training Loss:  1.4307, Training Precision: 0.9695, Training Recall: 0.9695, Training F_1: 0.9695\n",
            "[2500/3000]: Training Loss:  0.7051, Training Precision: 0.9748, Training Recall: 0.9748, Training F_1: 0.9748\n",
            "[3000/3000]: Training Loss:  0.9211, Training Precision: 0.9741, Training Recall: 0.9741, Training F_1: 0.9741\n",
            "Epoch training time: 297.55 s.\n",
            "############ Val Loss:  1.3618, Val Precision: 0.9539, Val Recall: 0.9539, Val F_1: 0.9539\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 6/10\n",
            "[ 500/3000]: Training Loss:  1.1703, Training Precision: 0.9563, Training Recall: 0.9563, Training F_1: 0.9563\n",
            "[1000/3000]: Training Loss:  0.5361, Training Precision: 0.9828, Training Recall: 0.9828, Training F_1: 0.9828\n",
            "[1500/3000]: Training Loss:  0.8162, Training Precision: 0.9855, Training Recall: 0.9855, Training F_1: 0.9855\n",
            "[2000/3000]: Training Loss:  1.1064, Training Precision: 0.9767, Training Recall: 0.9767, Training F_1: 0.9767\n",
            "[2500/3000]: Training Loss:  0.5181, Training Precision: 0.9816, Training Recall: 0.9816, Training F_1: 0.9816\n",
            "[3000/3000]: Training Loss:  0.7686, Training Precision: 0.9821, Training Recall: 0.9821, Training F_1: 0.9821\n",
            "Epoch training time: 299.03 s.\n",
            "############ Val Loss:  1.2224, Val Precision: 0.9603, Val Recall: 0.9603, Val F_1: 0.9603\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 7/10\n",
            "[ 500/3000]: Training Loss:  0.9342, Training Precision: 0.9693, Training Recall: 0.9693, Training F_1: 0.9693\n",
            "[1000/3000]: Training Loss:  0.4285, Training Precision: 0.9840, Training Recall: 0.9840, Training F_1: 0.9840\n",
            "[1500/3000]: Training Loss:  0.7047, Training Precision: 0.9892, Training Recall: 0.9892, Training F_1: 0.9892\n",
            "[2000/3000]: Training Loss:  0.9186, Training Precision: 0.9814, Training Recall: 0.9814, Training F_1: 0.9814\n",
            "[2500/3000]: Training Loss:  0.3822, Training Precision: 0.9871, Training Recall: 0.9871, Training F_1: 0.9871\n",
            "[3000/3000]: Training Loss:  0.6284, Training Precision: 0.9841, Training Recall: 0.9841, Training F_1: 0.9841\n",
            "Epoch training time: 294.91 s.\n",
            "############ Val Loss:  1.3442, Val Precision: 0.9599, Val Recall: 0.9599, Val F_1: 0.9599\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 8/10\n",
            "[ 500/3000]: Training Loss:  0.7599, Training Precision: 0.9704, Training Recall: 0.9704, Training F_1: 0.9704\n",
            "[1000/3000]: Training Loss:  0.3819, Training Precision: 0.9896, Training Recall: 0.9896, Training F_1: 0.9896\n",
            "[1500/3000]: Training Loss:  0.6347, Training Precision: 0.9888, Training Recall: 0.9888, Training F_1: 0.9888\n",
            "[2000/3000]: Training Loss:  0.7737, Training Precision: 0.9858, Training Recall: 0.9858, Training F_1: 0.9858\n",
            "[2500/3000]: Training Loss:  0.3177, Training Precision: 0.9933, Training Recall: 0.9933, Training F_1: 0.9933\n",
            "[3000/3000]: Training Loss:  0.5367, Training Precision: 0.9863, Training Recall: 0.9863, Training F_1: 0.9863\n",
            "Epoch training time: 296.85 s.\n",
            "############ Val Loss:  1.3041, Val Precision: 0.9618, Val Recall: 0.9618, Val F_1: 0.9618\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 9/10\n",
            "[ 500/3000]: Training Loss:  0.6274, Training Precision: 0.9808, Training Recall: 0.9808, Training F_1: 0.9808\n",
            "[1000/3000]: Training Loss:  0.3294, Training Precision: 0.9846, Training Recall: 0.9846, Training F_1: 0.9846\n",
            "[1500/3000]: Training Loss:  0.5433, Training Precision: 0.9880, Training Recall: 0.9880, Training F_1: 0.9880\n",
            "[2000/3000]: Training Loss:  0.6651, Training Precision: 0.9867, Training Recall: 0.9867, Training F_1: 0.9867\n",
            "[2500/3000]: Training Loss:  0.2651, Training Precision: 0.9938, Training Recall: 0.9938, Training F_1: 0.9938\n",
            "[3000/3000]: Training Loss:  0.4337, Training Precision: 0.9900, Training Recall: 0.9900, Training F_1: 0.9900\n",
            "Epoch training time: 301.91 s.\n",
            "############ Val Loss:  1.2769, Val Precision: 0.9628, Val Recall: 0.9628, Val F_1: 0.9628\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 10/10\n",
            "[ 500/3000]: Training Loss:  0.5946, Training Precision: 0.9744, Training Recall: 0.9744, Training F_1: 0.9744\n",
            "[1000/3000]: Training Loss:  0.2509, Training Precision: 0.9916, Training Recall: 0.9916, Training F_1: 0.9916\n",
            "[1500/3000]: Training Loss:  0.5999, Training Precision: 0.9903, Training Recall: 0.9903, Training F_1: 0.9903\n",
            "[2000/3000]: Training Loss:  0.5882, Training Precision: 0.9878, Training Recall: 0.9878, Training F_1: 0.9878\n",
            "[2500/3000]: Training Loss:  0.2321, Training Precision: 0.9943, Training Recall: 0.9943, Training F_1: 0.9943\n",
            "[3000/3000]: Training Loss:  0.3491, Training Precision: 0.9933, Training Recall: 0.9933, Training F_1: 0.9933\n",
            "Epoch training time: 304.24 s.\n",
            "############ Val Loss:  1.3227, Val Precision: 0.9633, Val Recall: 0.9633, Val F_1: 0.9633\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Training complete in 52m 29s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEZwmImsOSCg",
        "colab_type": "text"
      },
      "source": [
        "### **attention after lstm2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtKySTWdORt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, tag_to_ix, embedding_dim, hidden_dim, heads=2, layers=1):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        self.layers = layers\n",
        "        self.heads = heads\n",
        "        # self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=self.layers, bidirectional=True)\n",
        "        # self.lstm2 = nn.LSTM(hidden_dim, hidden_dim // 2,\n",
        "        #                     num_layers=self.layers, bidirectional=True)\n",
        "        # self.attn = nn.MultiheadAttention(embedding_dim, num_heads=self.heads)\n",
        "        self.attn2 = nn.MultiheadAttention(hidden_dim, num_heads=self.heads)\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "        \n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def argmax(self, vec):\n",
        "        # return the argmax as a python int\n",
        "        _, idx = torch.max(vec, 1)\n",
        "        return idx.item()\n",
        "    \n",
        "    # Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "    def log_sum_exp(self, vec):\n",
        "        max_score = vec[0, self.argmax(vec)]\n",
        "        max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "        return max_score + \\\n",
        "            torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2 * self.layers, 1, self.hidden_dim // 2),\n",
        "                torch.randn(2 * self.layers, 1, self.hidden_dim // 2))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(self.log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = self.log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        # embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        # lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        # attn_output, _ = self.attn(sentence, sentence, sentence)\n",
        "        lstm_out, self.hidden = self.lstm(sentence, self.hidden)\n",
        "        # print(lstm_out.shape)\n",
        "        # print(self.hidden[0].shape)\n",
        "        # cat = torch.cat((self.hidden[0][0,:,:], self.hidden[0][1,:,:]), 1)\n",
        "        # print(cat.shape)\n",
        "        # attn_output, _ = self.attn2(lstm_out, cat, cat)\n",
        "        # cat = torch.cat((self.hidden[0][0,:,:], self.hidden[0][1,:,:]), 1)\n",
        "        # attn_output2, _ = self.attn2(lstm_out, cat, cat)\n",
        "        # self.hidden = self.init_hidden()\n",
        "        # lstm_out2, self.hidden = self.lstm2(lstm_out, self.hidden)\n",
        "        # cat = torch.cat((self.hidden[0][0,:,:], self.hidden[0][1,:,:]), 1)\n",
        "        attn_output, _ = self.attn2(lstm_out, lstm_out, lstm_out)\n",
        "        lstm_out1 = attn_output.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out1)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = self.argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = self.argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(feats)\n",
        "        return forward_score - gold_score, tag_seq\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MayqgSLJOtVf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd4e0c69-383c-4f73-d359-dbda055afef5"
      },
      "source": [
        "HIDDEN_DIM = 512\n",
        "EMBEDDING_DIM = 420\n",
        "\n",
        "model = BiLSTM_CRF(tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, heads=16, layers=2)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "train_model(model, device, optimizer, num_epochs=10, emb_dim=EMBEDDING_DIM)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "[ 500/3000]: Training Loss: 10.0502, Training Precision: 0.7572, Training Recall: 0.7572, Training F_1: 0.7572\n",
            "[1000/3000]: Training Loss:  8.3816, Training Precision: 0.6783, Training Recall: 0.6783, Training F_1: 0.6783\n",
            "[1500/3000]: Training Loss:  7.4672, Training Precision: 0.8488, Training Recall: 0.8488, Training F_1: 0.8488\n",
            "[2000/3000]: Training Loss:  7.5670, Training Precision: 0.8652, Training Recall: 0.8652, Training F_1: 0.8652\n",
            "[2500/3000]: Training Loss:  7.1809, Training Precision: 0.7273, Training Recall: 0.7273, Training F_1: 0.7273\n",
            "[3000/3000]: Training Loss:  7.4377, Training Precision: 0.7205, Training Recall: 0.7205, Training F_1: 0.7205\n",
            "Epoch training time: 307.27 s.\n",
            "############ Val Loss:  7.3327, Val Precision: 0.7245, Val Recall: 0.7245, Val F_1: 0.7245\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 2/10\n",
            "[ 500/3000]: Training Loss:  7.6394, Training Precision: 0.7914, Training Recall: 0.7914, Training F_1: 0.7914\n",
            "[1000/3000]: Training Loss:  7.2595, Training Precision: 0.6787, Training Recall: 0.6787, Training F_1: 0.6787\n",
            "[1500/3000]: Training Loss:  6.9311, Training Precision: 0.8750, Training Recall: 0.8750, Training F_1: 0.8750\n",
            "[2000/3000]: Training Loss:  7.2248, Training Precision: 0.8688, Training Recall: 0.8688, Training F_1: 0.8688\n",
            "[2500/3000]: Training Loss:  6.7940, Training Precision: 0.7397, Training Recall: 0.7397, Training F_1: 0.7397\n",
            "[3000/3000]: Training Loss:  7.2276, Training Precision: 0.7104, Training Recall: 0.7104, Training F_1: 0.7104\n",
            "Epoch training time: 302.70 s.\n",
            "############ Val Loss:  6.9924, Val Precision: 0.7597, Val Recall: 0.7597, Val F_1: 0.7597\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 3/10\n",
            "[ 500/3000]: Training Loss:  7.3904, Training Precision: 0.8017, Training Recall: 0.8017, Training F_1: 0.8017\n",
            "[1000/3000]: Training Loss:  6.9499, Training Precision: 0.6788, Training Recall: 0.6788, Training F_1: 0.6788\n",
            "[1500/3000]: Training Loss:  6.7728, Training Precision: 0.8791, Training Recall: 0.8791, Training F_1: 0.8791\n",
            "[2000/3000]: Training Loss:  7.1893, Training Precision: 0.8723, Training Recall: 0.8723, Training F_1: 0.8723\n",
            "[2500/3000]: Training Loss:  6.5862, Training Precision: 0.7545, Training Recall: 0.7545, Training F_1: 0.7545\n",
            "[3000/3000]: Training Loss:  7.0557, Training Precision: 0.7154, Training Recall: 0.7154, Training F_1: 0.7154\n",
            "Epoch training time: 304.31 s.\n",
            "############ Val Loss:  6.8963, Val Precision: 0.7557, Val Recall: 0.7557, Val F_1: 0.7557\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 4/10\n",
            "[ 500/3000]: Training Loss:  7.2383, Training Precision: 0.8070, Training Recall: 0.8070, Training F_1: 0.8070\n",
            "[1000/3000]: Training Loss:  6.7082, Training Precision: 0.6987, Training Recall: 0.6987, Training F_1: 0.6987\n",
            "[1500/3000]: Training Loss:  4.7658, Training Precision: 0.8987, Training Recall: 0.8987, Training F_1: 0.8987\n",
            "[2000/3000]: Training Loss:  3.6021, Training Precision: 0.9136, Training Recall: 0.9136, Training F_1: 0.9136\n",
            "[2500/3000]: Training Loss:  2.7387, Training Precision: 0.8888, Training Recall: 0.8888, Training F_1: 0.8888\n",
            "[3000/3000]: Training Loss:  2.9465, Training Precision: 0.9195, Training Recall: 0.9195, Training F_1: 0.9195\n",
            "Epoch training time: 302.54 s.\n",
            "############ Val Loss:  3.1790, Val Precision: 0.8661, Val Recall: 0.8661, Val F_1: 0.8661\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 5/10\n",
            "[ 500/3000]: Training Loss:  3.3186, Training Precision: 0.8910, Training Recall: 0.8910, Training F_1: 0.8910\n",
            "[1000/3000]: Training Loss:  2.1781, Training Precision: 0.9075, Training Recall: 0.9075, Training F_1: 0.9075\n",
            "[1500/3000]: Training Loss:  2.4820, Training Precision: 0.9361, Training Recall: 0.9361, Training F_1: 0.9361\n",
            "[2000/3000]: Training Loss:  2.8916, Training Precision: 0.9376, Training Recall: 0.9376, Training F_1: 0.9376\n",
            "[2500/3000]: Training Loss:  2.1747, Training Precision: 0.9155, Training Recall: 0.9155, Training F_1: 0.9155\n",
            "[3000/3000]: Training Loss:  2.3168, Training Precision: 0.9362, Training Recall: 0.9362, Training F_1: 0.9362\n",
            "Epoch training time: 304.57 s.\n",
            "############ Val Loss:  2.4039, Val Precision: 0.9182, Val Recall: 0.9182, Val F_1: 0.9182\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 6/10\n",
            "[ 500/3000]: Training Loss:  2.7833, Training Precision: 0.9069, Training Recall: 0.9069, Training F_1: 0.9069\n",
            "[1000/3000]: Training Loss:  1.7887, Training Precision: 0.9276, Training Recall: 0.9276, Training F_1: 0.9276\n",
            "[1500/3000]: Training Loss:  2.1284, Training Precision: 0.9465, Training Recall: 0.9465, Training F_1: 0.9465\n",
            "[2000/3000]: Training Loss:  2.3990, Training Precision: 0.9361, Training Recall: 0.9361, Training F_1: 0.9361\n",
            "[2500/3000]: Training Loss:  1.5481, Training Precision: 0.9382, Training Recall: 0.9382, Training F_1: 0.9382\n",
            "[3000/3000]: Training Loss:  1.7798, Training Precision: 0.9492, Training Recall: 0.9492, Training F_1: 0.9492\n",
            "Epoch training time: 304.04 s.\n",
            "############ Val Loss:  1.8985, Val Precision: 0.9273, Val Recall: 0.9273, Val F_1: 0.9273\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 7/10\n",
            "[ 500/3000]: Training Loss:  2.0854, Training Precision: 0.9215, Training Recall: 0.9215, Training F_1: 0.9215\n",
            "[1000/3000]: Training Loss:  1.2386, Training Precision: 0.9533, Training Recall: 0.9533, Training F_1: 0.9533\n",
            "[1500/3000]: Training Loss:  1.4087, Training Precision: 0.9638, Training Recall: 0.9638, Training F_1: 0.9638\n",
            "[2000/3000]: Training Loss:  1.8746, Training Precision: 0.9536, Training Recall: 0.9536, Training F_1: 0.9536\n",
            "[2500/3000]: Training Loss:  1.1374, Training Precision: 0.9446, Training Recall: 0.9446, Training F_1: 0.9446\n",
            "[3000/3000]: Training Loss:  1.3705, Training Precision: 0.9620, Training Recall: 0.9620, Training F_1: 0.9620\n",
            "Epoch training time: 302.05 s.\n",
            "############ Val Loss:  1.6306, Val Precision: 0.9426, Val Recall: 0.9426, Val F_1: 0.9426\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 8/10\n",
            "[ 500/3000]: Training Loss:  1.7894, Training Precision: 0.9403, Training Recall: 0.9403, Training F_1: 0.9403\n",
            "[1000/3000]: Training Loss:  1.0142, Training Precision: 0.9568, Training Recall: 0.9568, Training F_1: 0.9568\n",
            "[1500/3000]: Training Loss:  1.0980, Training Precision: 0.9716, Training Recall: 0.9716, Training F_1: 0.9716\n",
            "[2000/3000]: Training Loss:  1.6126, Training Precision: 0.9586, Training Recall: 0.9586, Training F_1: 0.9586\n",
            "[2500/3000]: Training Loss:  0.9214, Training Precision: 0.9585, Training Recall: 0.9585, Training F_1: 0.9585\n",
            "[3000/3000]: Training Loss:  1.1271, Training Precision: 0.9682, Training Recall: 0.9682, Training F_1: 0.9682\n",
            "Epoch training time: 303.24 s.\n",
            "############ Val Loss:  1.7255, Val Precision: 0.9455, Val Recall: 0.9455, Val F_1: 0.9455\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 9/10\n",
            "[ 500/3000]: Training Loss:  1.4963, Training Precision: 0.9500, Training Recall: 0.9500, Training F_1: 0.9500\n",
            "[1000/3000]: Training Loss:  0.8649, Training Precision: 0.9620, Training Recall: 0.9620, Training F_1: 0.9620\n",
            "[1500/3000]: Training Loss:  0.9753, Training Precision: 0.9742, Training Recall: 0.9742, Training F_1: 0.9742\n",
            "[2000/3000]: Training Loss:  1.3916, Training Precision: 0.9666, Training Recall: 0.9666, Training F_1: 0.9666\n",
            "[2500/3000]: Training Loss:  0.7093, Training Precision: 0.9649, Training Recall: 0.9649, Training F_1: 0.9649\n",
            "[3000/3000]: Training Loss:  0.8694, Training Precision: 0.9758, Training Recall: 0.9758, Training F_1: 0.9758\n",
            "Epoch training time: 299.51 s.\n",
            "############ Val Loss:  1.4919, Val Precision: 0.9525, Val Recall: 0.9525, Val F_1: 0.9525\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 10/10\n",
            "[ 500/3000]: Training Loss:  1.2407, Training Precision: 0.9493, Training Recall: 0.9493, Training F_1: 0.9493\n",
            "[1000/3000]: Training Loss:  0.7472, Training Precision: 0.9704, Training Recall: 0.9704, Training F_1: 0.9704\n",
            "[1500/3000]: Training Loss:  0.8455, Training Precision: 0.9765, Training Recall: 0.9765, Training F_1: 0.9765\n",
            "[2000/3000]: Training Loss:  1.2371, Training Precision: 0.9683, Training Recall: 0.9683, Training F_1: 0.9683\n",
            "[2500/3000]: Training Loss:  0.6177, Training Precision: 0.9697, Training Recall: 0.9697, Training F_1: 0.9697\n",
            "[3000/3000]: Training Loss:  0.7154, Training Precision: 0.9797, Training Recall: 0.9797, Training F_1: 0.9797\n",
            "Epoch training time: 301.01 s.\n",
            "############ Val Loss:  1.6712, Val Precision: 0.9500, Val Recall: 0.9500, Val F_1: 0.9500\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Training complete in 53m 27s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zys78ZdYbFdn",
        "colab_type": "text"
      },
      "source": [
        "### **h=2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuDtqpphbE1H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f8a4e597-60c8-4435-9aeb-17dad9ca72ef"
      },
      "source": [
        "HIDDEN_DIM = 512\n",
        "EMBEDDING_DIM = 420\n",
        "\n",
        "model = BiLSTM_CRF(tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, heads=2, layers=2)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "train_model(model, device, optimizer, num_epochs=10, emb_dim=EMBEDDING_DIM)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "[ 500/3000]: Training Loss: 10.1235, Training Precision: 0.7760, Training Recall: 0.7760, Training F_1: 0.7760\n",
            "[1000/3000]: Training Loss:  8.6124, Training Precision: 0.6814, Training Recall: 0.6814, Training F_1: 0.6814\n",
            "[1500/3000]: Training Loss:  7.9153, Training Precision: 0.8486, Training Recall: 0.8486, Training F_1: 0.8486\n",
            "[2000/3000]: Training Loss:  7.9505, Training Precision: 0.8608, Training Recall: 0.8608, Training F_1: 0.8608\n",
            "[2500/3000]: Training Loss:  7.1804, Training Precision: 0.7284, Training Recall: 0.7284, Training F_1: 0.7284\n",
            "[3000/3000]: Training Loss:  7.4669, Training Precision: 0.7104, Training Recall: 0.7104, Training F_1: 0.7104\n",
            "Epoch training time: 300.99 s.\n",
            "############ Val Loss:  7.2026, Val Precision: 0.7479, Val Recall: 0.7479, Val F_1: 0.7479\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 2/10\n",
            "[ 500/3000]: Training Loss:  7.6136, Training Precision: 0.7951, Training Recall: 0.7951, Training F_1: 0.7951\n",
            "[1000/3000]: Training Loss:  7.2071, Training Precision: 0.6827, Training Recall: 0.6827, Training F_1: 0.6827\n",
            "[1500/3000]: Training Loss:  6.9390, Training Precision: 0.8711, Training Recall: 0.8711, Training F_1: 0.8711\n",
            "[2000/3000]: Training Loss:  7.2296, Training Precision: 0.8690, Training Recall: 0.8690, Training F_1: 0.8690\n",
            "[2500/3000]: Training Loss:  6.7043, Training Precision: 0.7447, Training Recall: 0.7447, Training F_1: 0.7447\n",
            "[3000/3000]: Training Loss:  7.1036, Training Precision: 0.7134, Training Recall: 0.7134, Training F_1: 0.7134\n",
            "Epoch training time: 305.22 s.\n",
            "############ Val Loss:  6.8563, Val Precision: 0.7560, Val Recall: 0.7560, Val F_1: 0.7560\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 3/10\n",
            "[ 500/3000]: Training Loss:  6.3856, Training Precision: 0.8251, Training Recall: 0.8251, Training F_1: 0.8251\n",
            "[1000/3000]: Training Loss:  2.8976, Training Precision: 0.8718, Training Recall: 0.8718, Training F_1: 0.8718\n",
            "[1500/3000]: Training Loss:  3.3079, Training Precision: 0.9210, Training Recall: 0.9210, Training F_1: 0.9210\n",
            "[2000/3000]: Training Loss:  3.3866, Training Precision: 0.9146, Training Recall: 0.9146, Training F_1: 0.9146\n",
            "[2500/3000]: Training Loss:  2.5036, Training Precision: 0.8931, Training Recall: 0.8931, Training F_1: 0.8931\n",
            "[3000/3000]: Training Loss:  2.8950, Training Precision: 0.9242, Training Recall: 0.9242, Training F_1: 0.9242\n",
            "Epoch training time: 302.86 s.\n",
            "############ Val Loss:  3.0570, Val Precision: 0.8866, Val Recall: 0.8866, Val F_1: 0.8866\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 4/10\n",
            "[ 500/3000]: Training Loss:  3.2200, Training Precision: 0.9040, Training Recall: 0.9040, Training F_1: 0.9040\n",
            "[1000/3000]: Training Loss:  2.0209, Training Precision: 0.9121, Training Recall: 0.9121, Training F_1: 0.9121\n",
            "[1500/3000]: Training Loss:  2.3393, Training Precision: 0.9384, Training Recall: 0.9384, Training F_1: 0.9384\n",
            "[2000/3000]: Training Loss:  2.8009, Training Precision: 0.9339, Training Recall: 0.9339, Training F_1: 0.9339\n",
            "[2500/3000]: Training Loss:  1.9874, Training Precision: 0.9223, Training Recall: 0.9223, Training F_1: 0.9223\n",
            "[3000/3000]: Training Loss:  2.1618, Training Precision: 0.9439, Training Recall: 0.9439, Training F_1: 0.9439\n",
            "Epoch training time: 304.61 s.\n",
            "############ Val Loss:  2.3041, Val Precision: 0.9223, Val Recall: 0.9223, Val F_1: 0.9223\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 5/10\n",
            "[ 500/3000]: Training Loss:  2.5743, Training Precision: 0.9160, Training Recall: 0.9160, Training F_1: 0.9160\n",
            "[1000/3000]: Training Loss:  1.4207, Training Precision: 0.9368, Training Recall: 0.9368, Training F_1: 0.9368\n",
            "[1500/3000]: Training Loss:  1.6878, Training Precision: 0.9553, Training Recall: 0.9553, Training F_1: 0.9553\n",
            "[2000/3000]: Training Loss:  2.2049, Training Precision: 0.9373, Training Recall: 0.9373, Training F_1: 0.9373\n",
            "[2500/3000]: Training Loss:  1.2391, Training Precision: 0.9413, Training Recall: 0.9413, Training F_1: 0.9413\n",
            "[3000/3000]: Training Loss:  1.6693, Training Precision: 0.9512, Training Recall: 0.9512, Training F_1: 0.9512\n",
            "Epoch training time: 303.70 s.\n",
            "############ Val Loss:  1.6666, Val Precision: 0.9404, Val Recall: 0.9404, Val F_1: 0.9404\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 6/10\n",
            "[ 500/3000]: Training Loss:  1.9948, Training Precision: 0.9264, Training Recall: 0.9264, Training F_1: 0.9264\n",
            "[1000/3000]: Training Loss:  1.1132, Training Precision: 0.9532, Training Recall: 0.9532, Training F_1: 0.9532\n",
            "[1500/3000]: Training Loss:  1.3920, Training Precision: 0.9591, Training Recall: 0.9591, Training F_1: 0.9591\n",
            "[2000/3000]: Training Loss:  1.8571, Training Precision: 0.9514, Training Recall: 0.9514, Training F_1: 0.9514\n",
            "[2500/3000]: Training Loss:  0.9797, Training Precision: 0.9475, Training Recall: 0.9475, Training F_1: 0.9475\n",
            "[3000/3000]: Training Loss:  1.3844, Training Precision: 0.9578, Training Recall: 0.9578, Training F_1: 0.9578\n",
            "Epoch training time: 305.52 s.\n",
            "############ Val Loss:  1.6415, Val Precision: 0.9422, Val Recall: 0.9422, Val F_1: 0.9422\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 7/10\n",
            "[ 500/3000]: Training Loss:  1.6859, Training Precision: 0.9415, Training Recall: 0.9415, Training F_1: 0.9415\n",
            "[1000/3000]: Training Loss:  0.8680, Training Precision: 0.9565, Training Recall: 0.9565, Training F_1: 0.9565\n",
            "[1500/3000]: Training Loss:  1.1344, Training Precision: 0.9721, Training Recall: 0.9721, Training F_1: 0.9721\n",
            "[2000/3000]: Training Loss:  1.5318, Training Precision: 0.9641, Training Recall: 0.9641, Training F_1: 0.9641\n",
            "[2500/3000]: Training Loss:  0.7838, Training Precision: 0.9648, Training Recall: 0.9648, Training F_1: 0.9648\n",
            "[3000/3000]: Training Loss:  1.0574, Training Precision: 0.9693, Training Recall: 0.9693, Training F_1: 0.9693\n",
            "Epoch training time: 303.58 s.\n",
            "############ Val Loss:  1.4182, Val Precision: 0.9538, Val Recall: 0.9538, Val F_1: 0.9538\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 8/10\n",
            "[ 500/3000]: Training Loss:  1.3652, Training Precision: 0.9493, Training Recall: 0.9493, Training F_1: 0.9493\n",
            "[1000/3000]: Training Loss:  0.7454, Training Precision: 0.9626, Training Recall: 0.9626, Training F_1: 0.9626\n",
            "[1500/3000]: Training Loss:  0.9420, Training Precision: 0.9738, Training Recall: 0.9738, Training F_1: 0.9738\n",
            "[2000/3000]: Training Loss:  1.3001, Training Precision: 0.9687, Training Recall: 0.9687, Training F_1: 0.9687\n",
            "[2500/3000]: Training Loss:  0.6168, Training Precision: 0.9735, Training Recall: 0.9735, Training F_1: 0.9735\n",
            "[3000/3000]: Training Loss:  0.8063, Training Precision: 0.9761, Training Recall: 0.9761, Training F_1: 0.9761\n",
            "Epoch training time: 305.75 s.\n",
            "############ Val Loss:  1.6094, Val Precision: 0.9521, Val Recall: 0.9521, Val F_1: 0.9521\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 9/10\n",
            "[ 500/3000]: Training Loss:  1.1635, Training Precision: 0.9554, Training Recall: 0.9554, Training F_1: 0.9554\n",
            "[1000/3000]: Training Loss:  0.6711, Training Precision: 0.9687, Training Recall: 0.9687, Training F_1: 0.9687\n",
            "[1500/3000]: Training Loss:  0.7678, Training Precision: 0.9760, Training Recall: 0.9760, Training F_1: 0.9760\n",
            "[2000/3000]: Training Loss:  1.2011, Training Precision: 0.9671, Training Recall: 0.9671, Training F_1: 0.9671\n",
            "[2500/3000]: Training Loss:  0.6207, Training Precision: 0.9771, Training Recall: 0.9771, Training F_1: 0.9771\n",
            "[3000/3000]: Training Loss:  0.7299, Training Precision: 0.9736, Training Recall: 0.9736, Training F_1: 0.9736\n",
            "Epoch training time: 304.65 s.\n",
            "############ Val Loss:  1.5886, Val Precision: 0.9546, Val Recall: 0.9546, Val F_1: 0.9546\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 10/10\n",
            "[ 500/3000]: Training Loss:  0.9607, Training Precision: 0.9645, Training Recall: 0.9645, Training F_1: 0.9645\n",
            "[1000/3000]: Training Loss:  0.5718, Training Precision: 0.9718, Training Recall: 0.9718, Training F_1: 0.9718\n",
            "[1500/3000]: Training Loss:  0.7029, Training Precision: 0.9822, Training Recall: 0.9822, Training F_1: 0.9822\n",
            "[2000/3000]: Training Loss:  1.0473, Training Precision: 0.9769, Training Recall: 0.9769, Training F_1: 0.9769\n",
            "[2500/3000]: Training Loss:  0.4549, Training Precision: 0.9812, Training Recall: 0.9812, Training F_1: 0.9812\n",
            "[3000/3000]: Training Loss:  0.6105, Training Precision: 0.9835, Training Recall: 0.9835, Training F_1: 0.9835\n",
            "Epoch training time: 304.02 s.\n",
            "############ Val Loss:  1.5016, Val Precision: 0.9588, Val Recall: 0.9588, Val F_1: 0.9588\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Training complete in 53m 35s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5ZvggaaS_IE",
        "colab_type": "text"
      },
      "source": [
        "### **without attention**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn3ko2ME0Pux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, tag_to_ix, embedding_dim, hidden_dim, layers=1):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        self.layers = layers\n",
        "        # self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=self.layers, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "        \n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def argmax(self, vec):\n",
        "        # return the argmax as a python int\n",
        "        _, idx = torch.max(vec, 1)\n",
        "        return idx.item()\n",
        "    \n",
        "    # Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "    def log_sum_exp(self, vec):\n",
        "        max_score = vec[0, self.argmax(vec)]\n",
        "        max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "        return max_score + \\\n",
        "            torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2 * self.layers, 1, self.hidden_dim // 2),\n",
        "                torch.randn(2 * self.layers, 1, self.hidden_dim // 2))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(self.log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = self.log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        # embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        # lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        lstm_out, self.hidden = self.lstm(sentence, self.hidden)\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = self.argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = self.argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(feats)\n",
        "        return forward_score - gold_score, tag_seq\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cN74Yo3FHB7L",
        "colab_type": "text"
      },
      "source": [
        "### **emb+pos+dep+tag+tf_idf**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF122VudHBQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embeddings(sentence, index, flag, emb_dim):\n",
        "    N = len(sentence.split())\n",
        "    sentence_emb = torch.empty((0, emb_dim), dtype=torch.float32)\n",
        "    parse = nlp(sentence)\n",
        "    for token in parse:\n",
        "        word_emb = gensim_emb(str(token))\n",
        "        pos_emb = get_pos(token, parse)\n",
        "        dep_emb = get_dep(token, parse)\n",
        "        tag_emb = get_tag(token, parse)\n",
        "        tf_idf_emb = get_tf_idf(token, parse, index, flag)\n",
        "        embeddings = torch.cat((word_emb, pos_emb, dep_emb, tag_emb, tf_idf_emb), axis=-1).view(1, -1)\n",
        "        sentence_emb = torch.cat((sentence_emb, embeddings), axis=0)\n",
        "    return sentence_emb.view(N, 1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik0D_m73HMVx",
        "colab_type": "code",
        "outputId": "256b7c83-784b-4b62-87dd-2aa29f0ecd62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "HIDDEN_DIM = 1024\n",
        "EMBEDDING_DIM = 410\n",
        "\n",
        "model = BiLSTM_CRF(tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, layers=2)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "train_model(model, device, optimizer, num_epochs=10, emb_dim=EMBEDDING_DIM)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "[ 500/3000]: Training Loss:  7.7020, Training Precision: 0.7669, Training Recall: 0.7669, Training F_1: 0.7669\n",
            "[1000/3000]: Training Loss:  3.5784, Training Precision: 0.8530, Training Recall: 0.8530, Training F_1: 0.8530\n",
            "[1500/3000]: Training Loss:  3.6145, Training Precision: 0.9132, Training Recall: 0.9132, Training F_1: 0.9132\n",
            "[2000/3000]: Training Loss:  3.5121, Training Precision: 0.9080, Training Recall: 0.9080, Training F_1: 0.9080\n",
            "[2500/3000]: Training Loss:  2.2104, Training Precision: 0.8817, Training Recall: 0.8817, Training F_1: 0.8817\n",
            "[3000/3000]: Training Loss:  2.4998, Training Precision: 0.9259, Training Recall: 0.9259, Training F_1: 0.9259\n",
            "Epoch training time: 738.68 s.\n",
            "############ Val Loss:  2.4294, Val Precision: 0.9209, Val Recall: 0.9209, Val F_1: 0.9209\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 2/10\n",
            "[ 500/3000]: Training Loss:  2.6779, Training Precision: 0.9067, Training Recall: 0.9067, Training F_1: 0.9067\n",
            "[1000/3000]: Training Loss:  1.5043, Training Precision: 0.9248, Training Recall: 0.9248, Training F_1: 0.9248\n",
            "[1500/3000]: Training Loss:  2.2625, Training Precision: 0.9339, Training Recall: 0.9339, Training F_1: 0.9339\n",
            "[2000/3000]: Training Loss:  2.7027, Training Precision: 0.9294, Training Recall: 0.9294, Training F_1: 0.9294\n",
            "[2500/3000]: Training Loss:  1.4728, Training Precision: 0.9256, Training Recall: 0.9256, Training F_1: 0.9256\n",
            "[3000/3000]: Training Loss:  1.8528, Training Precision: 0.9457, Training Recall: 0.9457, Training F_1: 0.9457\n",
            "Epoch training time: 770.33 s.\n",
            "############ Val Loss:  2.0584, Val Precision: 0.9334, Val Recall: 0.9334, Val F_1: 0.9334\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 3/10\n",
            "[ 500/3000]: Training Loss:  2.0702, Training Precision: 0.9153, Training Recall: 0.9153, Training F_1: 0.9153\n",
            "[1000/3000]: Training Loss:  1.1619, Training Precision: 0.9458, Training Recall: 0.9458, Training F_1: 0.9458\n",
            "[1500/3000]: Training Loss:  1.7644, Training Precision: 0.9507, Training Recall: 0.9507, Training F_1: 0.9507\n",
            "[2000/3000]: Training Loss:  2.2533, Training Precision: 0.9410, Training Recall: 0.9410, Training F_1: 0.9410\n",
            "[2500/3000]: Training Loss:  1.2014, Training Precision: 0.9375, Training Recall: 0.9375, Training F_1: 0.9375\n",
            "[3000/3000]: Training Loss:  1.5134, Training Precision: 0.9543, Training Recall: 0.9543, Training F_1: 0.9543\n",
            "Epoch training time: 779.05 s.\n",
            "############ Val Loss:  1.8278, Val Precision: 0.9389, Val Recall: 0.9389, Val F_1: 0.9389\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 4/10\n",
            "[ 500/3000]: Training Loss:  1.7246, Training Precision: 0.9244, Training Recall: 0.9244, Training F_1: 0.9244\n",
            "[1000/3000]: Training Loss:  0.9356, Training Precision: 0.9597, Training Recall: 0.9597, Training F_1: 0.9597\n",
            "[1500/3000]: Training Loss:  1.4709, Training Precision: 0.9524, Training Recall: 0.9524, Training F_1: 0.9524\n",
            "[2000/3000]: Training Loss:  1.9340, Training Precision: 0.9494, Training Recall: 0.9494, Training F_1: 0.9494\n",
            "[2500/3000]: Training Loss:  1.0021, Training Precision: 0.9509, Training Recall: 0.9509, Training F_1: 0.9509\n",
            "[3000/3000]: Training Loss:  1.3388, Training Precision: 0.9475, Training Recall: 0.9475, Training F_1: 0.9475\n",
            "Epoch training time: 791.70 s.\n",
            "############ Val Loss:  1.7262, Val Precision: 0.9426, Val Recall: 0.9426, Val F_1: 0.9426\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 5/10\n",
            "[ 500/3000]: Training Loss:  1.4147, Training Precision: 0.9369, Training Recall: 0.9369, Training F_1: 0.9369\n",
            "[1000/3000]: Training Loss:  0.8077, Training Precision: 0.9534, Training Recall: 0.9534, Training F_1: 0.9534\n",
            "[1500/3000]: Training Loss:  1.2340, Training Precision: 0.9582, Training Recall: 0.9582, Training F_1: 0.9582\n",
            "[2000/3000]: Training Loss:  1.6923, Training Precision: 0.9586, Training Recall: 0.9586, Training F_1: 0.9586\n",
            "[2500/3000]: Training Loss:  0.8435, Training Precision: 0.9584, Training Recall: 0.9584, Training F_1: 0.9584\n",
            "[3000/3000]: Training Loss:  1.1074, Training Precision: 0.9651, Training Recall: 0.9651, Training F_1: 0.9651\n",
            "Epoch training time: 766.17 s.\n",
            "############ Val Loss:  1.6035, Val Precision: 0.9449, Val Recall: 0.9449, Val F_1: 0.9449\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 6/10\n",
            "[ 500/3000]: Training Loss:  1.1818, Training Precision: 0.9552, Training Recall: 0.9552, Training F_1: 0.9552\n",
            "[1000/3000]: Training Loss:  0.6876, Training Precision: 0.9556, Training Recall: 0.9556, Training F_1: 0.9556\n",
            "[1500/3000]: Training Loss:  1.0100, Training Precision: 0.9716, Training Recall: 0.9716, Training F_1: 0.9716\n",
            "[2000/3000]: Training Loss:  1.5059, Training Precision: 0.9502, Training Recall: 0.9502, Training F_1: 0.9502\n",
            "[2500/3000]: Training Loss:  0.7061, Training Precision: 0.9661, Training Recall: 0.9661, Training F_1: 0.9661\n",
            "[3000/3000]: Training Loss:  0.8739, Training Precision: 0.9707, Training Recall: 0.9707, Training F_1: 0.9707\n",
            "Epoch training time: 704.84 s.\n",
            "############ Val Loss:  1.5700, Val Precision: 0.9538, Val Recall: 0.9538, Val F_1: 0.9538\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 7/10\n",
            "[ 500/3000]: Training Loss:  0.9346, Training Precision: 0.9586, Training Recall: 0.9586, Training F_1: 0.9586\n",
            "[1000/3000]: Training Loss:  0.5651, Training Precision: 0.9664, Training Recall: 0.9664, Training F_1: 0.9664\n",
            "[1500/3000]: Training Loss:  0.8417, Training Precision: 0.9707, Training Recall: 0.9707, Training F_1: 0.9707\n",
            "[2000/3000]: Training Loss:  1.2370, Training Precision: 0.9571, Training Recall: 0.9571, Training F_1: 0.9571\n",
            "[2500/3000]: Training Loss:  0.5870, Training Precision: 0.9771, Training Recall: 0.9771, Training F_1: 0.9771\n",
            "[3000/3000]: Training Loss:  0.7755, Training Precision: 0.9753, Training Recall: 0.9753, Training F_1: 0.9753\n",
            "Epoch training time: 744.69 s.\n",
            "############ Val Loss:  1.6170, Val Precision: 0.9531, Val Recall: 0.9531, Val F_1: 0.9531\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 8/10\n",
            "[ 500/3000]: Training Loss:  0.8843, Training Precision: 0.9501, Training Recall: 0.9501, Training F_1: 0.9501\n",
            "[1000/3000]: Training Loss:  0.4915, Training Precision: 0.9637, Training Recall: 0.9637, Training F_1: 0.9637\n",
            "[1500/3000]: Training Loss:  0.6878, Training Precision: 0.9706, Training Recall: 0.9706, Training F_1: 0.9706\n",
            "[2000/3000]: Training Loss:  1.0274, Training Precision: 0.9620, Training Recall: 0.9620, Training F_1: 0.9620\n",
            "[2500/3000]: Training Loss:  0.5098, Training Precision: 0.9745, Training Recall: 0.9745, Training F_1: 0.9745\n",
            "[3000/3000]: Training Loss:  0.6278, Training Precision: 0.9698, Training Recall: 0.9698, Training F_1: 0.9698\n",
            "Epoch training time: 780.69 s.\n",
            "############ Val Loss:  1.6167, Val Precision: 0.9539, Val Recall: 0.9539, Val F_1: 0.9539\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 9/10\n",
            "[ 500/3000]: Training Loss:  0.7274, Training Precision: 0.9608, Training Recall: 0.9608, Training F_1: 0.9608\n",
            "[1000/3000]: Training Loss:  0.4280, Training Precision: 0.9748, Training Recall: 0.9748, Training F_1: 0.9748\n",
            "[1500/3000]: Training Loss:  0.5703, Training Precision: 0.9791, Training Recall: 0.9791, Training F_1: 0.9791\n",
            "[2000/3000]: Training Loss:  0.9098, Training Precision: 0.9703, Training Recall: 0.9703, Training F_1: 0.9703\n",
            "[2500/3000]: Training Loss:  0.4708, Training Precision: 0.9669, Training Recall: 0.9669, Training F_1: 0.9669\n",
            "[3000/3000]: Training Loss:  0.4935, Training Precision: 0.9804, Training Recall: 0.9804, Training F_1: 0.9804\n",
            "Epoch training time: 787.00 s.\n",
            "############ Val Loss:  1.5453, Val Precision: 0.9588, Val Recall: 0.9588, Val F_1: 0.9588\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 10/10\n",
            "[ 500/3000]: Training Loss:  0.6135, Training Precision: 0.9622, Training Recall: 0.9622, Training F_1: 0.9622\n",
            "[1000/3000]: Training Loss:  0.3768, Training Precision: 0.9749, Training Recall: 0.9749, Training F_1: 0.9749\n",
            "[1500/3000]: Training Loss:  0.5075, Training Precision: 0.9748, Training Recall: 0.9748, Training F_1: 0.9748\n",
            "[2000/3000]: Training Loss:  0.7427, Training Precision: 0.9685, Training Recall: 0.9685, Training F_1: 0.9685\n",
            "[2500/3000]: Training Loss:  0.3785, Training Precision: 0.9744, Training Recall: 0.9744, Training F_1: 0.9744\n",
            "[3000/3000]: Training Loss:  0.4245, Training Precision: 0.9821, Training Recall: 0.9821, Training F_1: 0.9821\n",
            "Epoch training time: 763.38 s.\n",
            "############ Val Loss:  1.6309, Val Precision: 0.9591, Val Recall: 0.9591, Val F_1: 0.9591\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Training complete in 131m 36s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp8j_c6qMmR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.load('The_6_epoch_model.pt')\n",
        "predict(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKPH1va7Cf85",
        "colab_type": "text"
      },
      "source": [
        "### **two layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f4u36M-ClfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, tag_to_ix, embedding_dim, hidden_dim, layers=1):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # self.hidden_dim_2 = hidden_dim_2\n",
        "        # self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        self.layers = layers\n",
        "        # self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=self.layers, bidirectional=True)\n",
        "        # self.lstm_2 = nn.LSTM(hidden_dim_1, hidden_dim_2 // 2,\n",
        "        #                     num_layers=1, bidirectional=True)\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "        \n",
        "        # self.hidden_1 = self.init_hidden_1()\n",
        "        # self.hidden_2 = self.init_hidden_2()\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def argmax(self, vec):\n",
        "        # return the argmax as a python int\n",
        "        _, idx = torch.max(vec, 1)\n",
        "        return idx.item()\n",
        "    \n",
        "    # Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "    def log_sum_exp(self, vec):\n",
        "        max_score = vec[0, self.argmax(vec)]\n",
        "        max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "        return max_score + \\\n",
        "            torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2*self.layers, 1, self.hidden_dim // 2),\n",
        "                torch.randn(2*self.layers, 1, self.hidden_dim // 2))\n",
        "        \n",
        "    # def init_hidden_2(self):\n",
        "    #     return (torch.randn(2, 1, self.hidden_dim_2 // 2),\n",
        "    #             torch.randn(2, 1, self.hidden_dim_2 // 2))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(self.log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = self.log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        lstm_out, self.hidden = self.lstm(sentence, self.hidden)\n",
        "\n",
        "        # self.hidden_2 = self.init_hidden_2()\n",
        "        # lstm_out_2, self.hidden_2 = self.lstm_2(lstm_out_1, self.hidden_1)\n",
        "\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = self.argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = self.argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(feats)\n",
        "        return forward_score - gold_score, tag_seq\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU78RQ3ZCfwt",
        "colab_type": "code",
        "outputId": "41b70d81-5dd4-4efd-dacd-53a67d1f0a4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# HIDDEN_DIM_1 = 256\n",
        "HIDDEN_DIM = 256\n",
        "EMBEDDING_DIM = 420\n",
        "\n",
        "model = BiLSTM_CRF(tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, layers=2)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "train_model(model, device, optimizer, num_epochs=10, emb_dim=EMBEDDING_DIM)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "[ 500/3000]: Training Loss:  8.2449, Training Precision: 0.7749, Training Recall: 0.7749, Training F_1: 0.7749\n",
            "[1000/3000]: Training Loss:  3.4919, Training Precision: 0.8552, Training Recall: 0.8552, Training F_1: 0.8552\n",
            "[1500/3000]: Training Loss:  2.7711, Training Precision: 0.9211, Training Recall: 0.9211, Training F_1: 0.9211\n",
            "[2000/3000]: Training Loss:  2.6259, Training Precision: 0.9339, Training Recall: 0.9339, Training F_1: 0.9339\n",
            "[2500/3000]: Training Loss:  1.6706, Training Precision: 0.9072, Training Recall: 0.9072, Training F_1: 0.9072\n",
            "[3000/3000]: Training Loss:  1.7089, Training Precision: 0.9493, Training Recall: 0.9493, Training F_1: 0.9493\n",
            "Epoch training time: 177.67 s.\n",
            "############ Val Loss:  1.7244, Val Precision: 0.9407, Val Recall: 0.9407, Val F_1: 0.9407\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 2/10\n",
            "[ 500/3000]: Training Loss:  2.0273, Training Precision: 0.9275, Training Recall: 0.9275, Training F_1: 0.9275\n",
            "[1000/3000]: Training Loss:  1.2157, Training Precision: 0.9424, Training Recall: 0.9424, Training F_1: 0.9424\n",
            "[1500/3000]: Training Loss:  1.3564, Training Precision: 0.9667, Training Recall: 0.9667, Training F_1: 0.9667\n",
            "[2000/3000]: Training Loss:  1.6753, Training Precision: 0.9585, Training Recall: 0.9585, Training F_1: 0.9585\n",
            "[2500/3000]: Training Loss:  0.9411, Training Precision: 0.9502, Training Recall: 0.9502, Training F_1: 0.9502\n",
            "[3000/3000]: Training Loss:  1.1321, Training Precision: 0.9666, Training Recall: 0.9666, Training F_1: 0.9666\n",
            "Epoch training time: 176.66 s.\n",
            "############ Val Loss:  1.3796, Val Precision: 0.9525, Val Recall: 0.9525, Val F_1: 0.9525\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 3/10\n",
            "[ 500/3000]: Training Loss:  1.3912, Training Precision: 0.9428, Training Recall: 0.9428, Training F_1: 0.9428\n",
            "[1000/3000]: Training Loss:  0.8214, Training Precision: 0.9631, Training Recall: 0.9631, Training F_1: 0.9631\n",
            "[1500/3000]: Training Loss:  0.9296, Training Precision: 0.9781, Training Recall: 0.9781, Training F_1: 0.9781\n",
            "[2000/3000]: Training Loss:  1.3058, Training Precision: 0.9661, Training Recall: 0.9661, Training F_1: 0.9661\n",
            "[2500/3000]: Training Loss:  0.6208, Training Precision: 0.9714, Training Recall: 0.9714, Training F_1: 0.9714\n",
            "[3000/3000]: Training Loss:  0.7761, Training Precision: 0.9795, Training Recall: 0.9795, Training F_1: 0.9795\n",
            "Epoch training time: 178.79 s.\n",
            "############ Val Loss:  1.3755, Val Precision: 0.9525, Val Recall: 0.9525, Val F_1: 0.9525\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 4/10\n",
            "[ 500/3000]: Training Loss:  1.0795, Training Precision: 0.9582, Training Recall: 0.9582, Training F_1: 0.9582\n",
            "[1000/3000]: Training Loss:  0.6442, Training Precision: 0.9709, Training Recall: 0.9709, Training F_1: 0.9709\n",
            "[1500/3000]: Training Loss:  0.7026, Training Precision: 0.9845, Training Recall: 0.9845, Training F_1: 0.9845\n",
            "[2000/3000]: Training Loss:  1.0234, Training Precision: 0.9736, Training Recall: 0.9736, Training F_1: 0.9736\n",
            "[2500/3000]: Training Loss:  0.4659, Training Precision: 0.9832, Training Recall: 0.9832, Training F_1: 0.9832\n",
            "[3000/3000]: Training Loss:  0.5863, Training Precision: 0.9814, Training Recall: 0.9814, Training F_1: 0.9814\n",
            "Epoch training time: 176.68 s.\n",
            "############ Val Loss:  1.3585, Val Precision: 0.9567, Val Recall: 0.9567, Val F_1: 0.9567\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 5/10\n",
            "[ 500/3000]: Training Loss:  0.8472, Training Precision: 0.9611, Training Recall: 0.9611, Training F_1: 0.9611\n",
            "[1000/3000]: Training Loss:  0.4615, Training Precision: 0.9739, Training Recall: 0.9739, Training F_1: 0.9739\n",
            "[1500/3000]: Training Loss:  0.5389, Training Precision: 0.9893, Training Recall: 0.9893, Training F_1: 0.9893\n",
            "[2000/3000]: Training Loss:  0.7987, Training Precision: 0.9787, Training Recall: 0.9787, Training F_1: 0.9787\n",
            "[2500/3000]: Training Loss:  0.3765, Training Precision: 0.9898, Training Recall: 0.9898, Training F_1: 0.9898\n",
            "[3000/3000]: Training Loss:  0.4646, Training Precision: 0.9866, Training Recall: 0.9866, Training F_1: 0.9866\n",
            "Epoch training time: 176.19 s.\n",
            "############ Val Loss:  1.3642, Val Precision: 0.9584, Val Recall: 0.9584, Val F_1: 0.9584\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 6/10\n",
            "[ 500/3000]: Training Loss:  0.6469, Training Precision: 0.9675, Training Recall: 0.9675, Training F_1: 0.9675\n",
            "[1000/3000]: Training Loss:  0.3702, Training Precision: 0.9798, Training Recall: 0.9798, Training F_1: 0.9798\n",
            "[1500/3000]: Training Loss:  0.4466, Training Precision: 0.9900, Training Recall: 0.9900, Training F_1: 0.9900\n",
            "[2000/3000]: Training Loss:  0.6655, Training Precision: 0.9825, Training Recall: 0.9825, Training F_1: 0.9825\n",
            "[2500/3000]: Training Loss:  0.3331, Training Precision: 0.9872, Training Recall: 0.9872, Training F_1: 0.9872\n",
            "[3000/3000]: Training Loss:  0.3803, Training Precision: 0.9887, Training Recall: 0.9887, Training F_1: 0.9887\n",
            "Epoch training time: 176.01 s.\n",
            "############ Val Loss:  1.2811, Val Precision: 0.9629, Val Recall: 0.9629, Val F_1: 0.9629\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 7/10\n",
            "[ 500/3000]: Training Loss:  0.5001, Training Precision: 0.9730, Training Recall: 0.9730, Training F_1: 0.9730\n",
            "[1000/3000]: Training Loss:  0.2830, Training Precision: 0.9864, Training Recall: 0.9864, Training F_1: 0.9864\n",
            "[1500/3000]: Training Loss:  0.3343, Training Precision: 0.9881, Training Recall: 0.9881, Training F_1: 0.9881\n",
            "[2000/3000]: Training Loss:  0.4902, Training Precision: 0.9860, Training Recall: 0.9860, Training F_1: 0.9860\n",
            "[2500/3000]: Training Loss:  0.1982, Training Precision: 0.9899, Training Recall: 0.9899, Training F_1: 0.9899\n",
            "[3000/3000]: Training Loss:  0.2959, Training Precision: 0.9909, Training Recall: 0.9909, Training F_1: 0.9909\n",
            "Epoch training time: 178.75 s.\n",
            "############ Val Loss:  1.3781, Val Precision: 0.9592, Val Recall: 0.9592, Val F_1: 0.9592\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 8/10\n",
            "[ 500/3000]: Training Loss:  0.3981, Training Precision: 0.9750, Training Recall: 0.9750, Training F_1: 0.9750\n",
            "[1000/3000]: Training Loss:  0.2157, Training Precision: 0.9892, Training Recall: 0.9892, Training F_1: 0.9892\n",
            "[1500/3000]: Training Loss:  0.2702, Training Precision: 0.9916, Training Recall: 0.9916, Training F_1: 0.9916\n",
            "[2000/3000]: Training Loss:  0.4138, Training Precision: 0.9892, Training Recall: 0.9892, Training F_1: 0.9892\n",
            "[2500/3000]: Training Loss:  0.2102, Training Precision: 0.9941, Training Recall: 0.9941, Training F_1: 0.9941\n",
            "[3000/3000]: Training Loss:  0.2421, Training Precision: 0.9932, Training Recall: 0.9932, Training F_1: 0.9932\n",
            "Epoch training time: 177.02 s.\n",
            "############ Val Loss:  1.2310, Val Precision: 0.9660, Val Recall: 0.9660, Val F_1: 0.9660\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 9/10\n",
            "[ 500/3000]: Training Loss:  0.2756, Training Precision: 0.9821, Training Recall: 0.9821, Training F_1: 0.9821\n",
            "[1000/3000]: Training Loss:  0.1776, Training Precision: 0.9885, Training Recall: 0.9885, Training F_1: 0.9885\n",
            "[1500/3000]: Training Loss:  0.2045, Training Precision: 0.9892, Training Recall: 0.9892, Training F_1: 0.9892\n",
            "[2000/3000]: Training Loss:  0.2931, Training Precision: 0.9944, Training Recall: 0.9944, Training F_1: 0.9944\n",
            "[2500/3000]: Training Loss:  0.1522, Training Precision: 0.9934, Training Recall: 0.9934, Training F_1: 0.9934\n",
            "[3000/3000]: Training Loss:  0.2274, Training Precision: 0.9939, Training Recall: 0.9939, Training F_1: 0.9939\n",
            "Epoch training time: 176.99 s.\n",
            "############ Val Loss:  1.1560, Val Precision: 0.9696, Val Recall: 0.9696, Val F_1: 0.9696\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 10/10\n",
            "[ 500/3000]: Training Loss:  0.2186, Training Precision: 0.9808, Training Recall: 0.9808, Training F_1: 0.9808\n",
            "[1000/3000]: Training Loss:  0.1533, Training Precision: 0.9942, Training Recall: 0.9942, Training F_1: 0.9942\n",
            "[1500/3000]: Training Loss:  0.1803, Training Precision: 0.9957, Training Recall: 0.9957, Training F_1: 0.9957\n",
            "[2000/3000]: Training Loss:  0.2341, Training Precision: 0.9925, Training Recall: 0.9925, Training F_1: 0.9925\n",
            "[2500/3000]: Training Loss:  0.1187, Training Precision: 0.9933, Training Recall: 0.9933, Training F_1: 0.9933\n",
            "[3000/3000]: Training Loss:  0.1304, Training Precision: 0.9974, Training Recall: 0.9974, Training F_1: 0.9974\n",
            "Epoch training time: 178.77 s.\n",
            "############ Val Loss:  1.2894, Val Precision: 0.9715, Val Recall: 0.9715, Val F_1: 0.9715\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Training complete in 31m 52s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB9h-_eVJx9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.load('The_2_epoch_model.pt')\n",
        "\n",
        "predict(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A1JSmJNW823",
        "colab_type": "text"
      },
      "source": [
        "### **layer 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tmA8nXRW8bG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, tag_to_ix, embedding_dim, hidden_dim, layers=1):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # self.hidden_dim_2 = hidden_dim_2\n",
        "        # self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        self.layers = layers\n",
        "        # self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=self.layers, bidirectional=True)\n",
        "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim // 2,\n",
        "                            num_layers=self.layers, bidirectional=True)\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "        \n",
        "        # self.hidden_1 = self.init_hidden_1()\n",
        "        # self.hidden_2 = self.init_hidden_2()\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def argmax(self, vec):\n",
        "        # return the argmax as a python int\n",
        "        _, idx = torch.max(vec, 1)\n",
        "        return idx.item()\n",
        "    \n",
        "    # Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "    def log_sum_exp(self, vec):\n",
        "        max_score = vec[0, self.argmax(vec)]\n",
        "        max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "        return max_score + \\\n",
        "            torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2*self.layers, 1, self.hidden_dim // 2),\n",
        "                torch.randn(2*self.layers, 1, self.hidden_dim // 2))\n",
        "        \n",
        "    # def init_hidden_2(self):\n",
        "    #     return (torch.randn(2, 1, self.hidden_dim_2 // 2),\n",
        "    #             torch.randn(2, 1, self.hidden_dim_2 // 2))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(self.log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = self.log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        lstm_out1, self.hidden = self.lstm(sentence, self.hidden)\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "        lstm_out2, self.hidden = self.lstm2(lstm_out1, self.hidden)\n",
        "\n",
        "        lstm_out = lstm_out2.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = self.argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = self.argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(feats)\n",
        "        return forward_score - gold_score, tag_seq\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtQuPZwaXI20",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "166bc5eb-5088-4a76-a1f2-88090d2e91b8"
      },
      "source": [
        "# HIDDEN_DIM_1 = 256\n",
        "HIDDEN_DIM = 512\n",
        "EMBEDDING_DIM = 420\n",
        "\n",
        "model = BiLSTM_CRF(tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, layers=2)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "train_model(model, device, optimizer, num_epochs=10, emb_dim=EMBEDDING_DIM)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "[ 500/3000]: Training Loss: 10.0823, Training Precision: 0.7729, Training Recall: 0.7729, Training F_1: 0.7729\n",
            "[1000/3000]: Training Loss:  8.5388, Training Precision: 0.6830, Training Recall: 0.6830, Training F_1: 0.6830\n",
            "[1500/3000]: Training Loss:  7.0018, Training Precision: 0.8418, Training Recall: 0.8418, Training F_1: 0.8418\n",
            "[2000/3000]: Training Loss:  6.0765, Training Precision: 0.8595, Training Recall: 0.8595, Training F_1: 0.8595\n",
            "[2500/3000]: Training Loss:  4.4710, Training Precision: 0.7849, Training Recall: 0.7849, Training F_1: 0.7849\n",
            "[3000/3000]: Training Loss:  3.4440, Training Precision: 0.9028, Training Recall: 0.9028, Training F_1: 0.9028\n",
            "Epoch training time: 439.74 s.\n",
            "############ Val Loss:  3.5560, Val Precision: 0.8702, Val Recall: 0.8702, Val F_1: 0.8702\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 2/10\n",
            "[ 500/3000]: Training Loss:  3.7730, Training Precision: 0.8693, Training Recall: 0.8693, Training F_1: 0.8693\n",
            "[1000/3000]: Training Loss:  2.5615, Training Precision: 0.8656, Training Recall: 0.8656, Training F_1: 0.8656\n",
            "[1500/3000]: Training Loss:  2.7317, Training Precision: 0.9159, Training Recall: 0.9159, Training F_1: 0.9159\n",
            "[2000/3000]: Training Loss:  2.8907, Training Precision: 0.9194, Training Recall: 0.9194, Training F_1: 0.9194\n",
            "[2500/3000]: Training Loss:  2.1283, Training Precision: 0.8777, Training Recall: 0.8777, Training F_1: 0.8777\n",
            "[3000/3000]: Training Loss:  2.1735, Training Precision: 0.9241, Training Recall: 0.9241, Training F_1: 0.9241\n",
            "Epoch training time: 444.37 s.\n",
            "############ Val Loss:  2.2261, Val Precision: 0.9209, Val Recall: 0.9209, Val F_1: 0.9209\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 3/10\n",
            "[ 500/3000]: Training Loss:  2.6098, Training Precision: 0.9050, Training Recall: 0.9050, Training F_1: 0.9050\n",
            "[1000/3000]: Training Loss:  1.7366, Training Precision: 0.9045, Training Recall: 0.9045, Training F_1: 0.9045\n",
            "[1500/3000]: Training Loss:  1.9929, Training Precision: 0.9343, Training Recall: 0.9343, Training F_1: 0.9343\n",
            "[2000/3000]: Training Loss:  2.1976, Training Precision: 0.9413, Training Recall: 0.9413, Training F_1: 0.9413\n",
            "[2500/3000]: Training Loss:  1.5400, Training Precision: 0.9119, Training Recall: 0.9119, Training F_1: 0.9119\n",
            "[3000/3000]: Training Loss:  1.6107, Training Precision: 0.9375, Training Recall: 0.9375, Training F_1: 0.9375\n",
            "Epoch training time: 445.37 s.\n",
            "############ Val Loss:  1.9308, Val Precision: 0.9303, Val Recall: 0.9303, Val F_1: 0.9303\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 4/10\n",
            "[ 500/3000]: Training Loss:  2.0009, Training Precision: 0.9256, Training Recall: 0.9256, Training F_1: 0.9256\n",
            "[1000/3000]: Training Loss:  1.3777, Training Precision: 0.9206, Training Recall: 0.9206, Training F_1: 0.9206\n",
            "[1500/3000]: Training Loss:  1.4848, Training Precision: 0.9483, Training Recall: 0.9483, Training F_1: 0.9483\n",
            "[2000/3000]: Training Loss:  1.8088, Training Precision: 0.9535, Training Recall: 0.9535, Training F_1: 0.9535\n",
            "[2500/3000]: Training Loss:  1.1975, Training Precision: 0.9136, Training Recall: 0.9136, Training F_1: 0.9136\n",
            "[3000/3000]: Training Loss:  1.1811, Training Precision: 0.9667, Training Recall: 0.9667, Training F_1: 0.9667\n",
            "Epoch training time: 443.71 s.\n",
            "############ Val Loss:  1.8195, Val Precision: 0.9385, Val Recall: 0.9385, Val F_1: 0.9385\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 5/10\n",
            "[ 500/3000]: Training Loss:  1.6363, Training Precision: 0.9341, Training Recall: 0.9341, Training F_1: 0.9341\n",
            "[1000/3000]: Training Loss:  1.1473, Training Precision: 0.9316, Training Recall: 0.9316, Training F_1: 0.9316\n",
            "[1500/3000]: Training Loss:  1.1646, Training Precision: 0.9644, Training Recall: 0.9644, Training F_1: 0.9644\n",
            "[2000/3000]: Training Loss:  1.5872, Training Precision: 0.9593, Training Recall: 0.9593, Training F_1: 0.9593\n",
            "[2500/3000]: Training Loss:  0.9255, Training Precision: 0.9383, Training Recall: 0.9383, Training F_1: 0.9383\n",
            "[3000/3000]: Training Loss:  0.9071, Training Precision: 0.9703, Training Recall: 0.9703, Training F_1: 0.9703\n",
            "Epoch training time: 442.43 s.\n",
            "############ Val Loss:  1.6538, Val Precision: 0.9440, Val Recall: 0.9440, Val F_1: 0.9440\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 6/10\n",
            "[ 500/3000]: Training Loss:  1.2729, Training Precision: 0.9501, Training Recall: 0.9501, Training F_1: 0.9501\n",
            "[1000/3000]: Training Loss:  0.9562, Training Precision: 0.9549, Training Recall: 0.9549, Training F_1: 0.9549\n",
            "[1500/3000]: Training Loss:  0.9160, Training Precision: 0.9723, Training Recall: 0.9723, Training F_1: 0.9723\n",
            "[2000/3000]: Training Loss:  1.3438, Training Precision: 0.9617, Training Recall: 0.9617, Training F_1: 0.9617\n",
            "[2500/3000]: Training Loss:  0.7132, Training Precision: 0.9676, Training Recall: 0.9676, Training F_1: 0.9676\n",
            "[3000/3000]: Training Loss:  0.7483, Training Precision: 0.9773, Training Recall: 0.9773, Training F_1: 0.9773\n",
            "Epoch training time: 441.84 s.\n",
            "############ Val Loss:  1.6623, Val Precision: 0.9463, Val Recall: 0.9463, Val F_1: 0.9463\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 7/10\n",
            "[ 500/3000]: Training Loss:  1.1157, Training Precision: 0.9553, Training Recall: 0.9553, Training F_1: 0.9553\n",
            "[1000/3000]: Training Loss:  0.7190, Training Precision: 0.9638, Training Recall: 0.9638, Training F_1: 0.9638\n",
            "[1500/3000]: Training Loss:  0.7793, Training Precision: 0.9785, Training Recall: 0.9785, Training F_1: 0.9785\n",
            "[2000/3000]: Training Loss:  1.1794, Training Precision: 0.9662, Training Recall: 0.9662, Training F_1: 0.9662\n",
            "[2500/3000]: Training Loss:  0.6107, Training Precision: 0.9753, Training Recall: 0.9753, Training F_1: 0.9753\n",
            "[3000/3000]: Training Loss:  0.5930, Training Precision: 0.9775, Training Recall: 0.9775, Training F_1: 0.9775\n",
            "Epoch training time: 439.26 s.\n",
            "############ Val Loss:  1.6205, Val Precision: 0.9512, Val Recall: 0.9512, Val F_1: 0.9512\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 8/10\n",
            "[ 500/3000]: Training Loss:  0.8837, Training Precision: 0.9661, Training Recall: 0.9661, Training F_1: 0.9661\n",
            "[1000/3000]: Training Loss:  0.6177, Training Precision: 0.9664, Training Recall: 0.9664, Training F_1: 0.9664\n",
            "[1500/3000]: Training Loss:  0.6051, Training Precision: 0.9820, Training Recall: 0.9820, Training F_1: 0.9820\n",
            "[2000/3000]: Training Loss:  0.9893, Training Precision: 0.9689, Training Recall: 0.9689, Training F_1: 0.9689\n",
            "[2500/3000]: Training Loss:  0.4921, Training Precision: 0.9779, Training Recall: 0.9779, Training F_1: 0.9779\n",
            "[3000/3000]: Training Loss:  0.5067, Training Precision: 0.9832, Training Recall: 0.9832, Training F_1: 0.9832\n",
            "Epoch training time: 438.24 s.\n",
            "############ Val Loss:  1.8389, Val Precision: 0.9467, Val Recall: 0.9467, Val F_1: 0.9467\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 9/10\n",
            "[ 500/3000]: Training Loss:  0.7548, Training Precision: 0.9652, Training Recall: 0.9652, Training F_1: 0.9652\n",
            "[1000/3000]: Training Loss:  0.5314, Training Precision: 0.9811, Training Recall: 0.9811, Training F_1: 0.9811\n",
            "[1500/3000]: Training Loss:  0.5830, Training Precision: 0.9876, Training Recall: 0.9876, Training F_1: 0.9876\n",
            "[2000/3000]: Training Loss:  0.8089, Training Precision: 0.9757, Training Recall: 0.9757, Training F_1: 0.9757\n",
            "[2500/3000]: Training Loss:  0.3839, Training Precision: 0.9757, Training Recall: 0.9757, Training F_1: 0.9757\n",
            "[3000/3000]: Training Loss:  0.4960, Training Precision: 0.9846, Training Recall: 0.9846, Training F_1: 0.9846\n",
            "Epoch training time: 439.33 s.\n",
            "############ Val Loss:  1.5253, Val Precision: 0.9565, Val Recall: 0.9565, Val F_1: 0.9565\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 10/10\n",
            "[ 500/3000]: Training Loss:  0.6919, Training Precision: 0.9650, Training Recall: 0.9650, Training F_1: 0.9650\n",
            "[1000/3000]: Training Loss:  0.4468, Training Precision: 0.9769, Training Recall: 0.9769, Training F_1: 0.9769\n",
            "[1500/3000]: Training Loss:  0.4606, Training Precision: 0.9867, Training Recall: 0.9867, Training F_1: 0.9867\n",
            "[2000/3000]: Training Loss:  0.6531, Training Precision: 0.9835, Training Recall: 0.9835, Training F_1: 0.9835\n",
            "[2500/3000]: Training Loss:  0.3186, Training Precision: 0.9843, Training Recall: 0.9843, Training F_1: 0.9843\n",
            "[3000/3000]: Training Loss:  0.3990, Training Precision: 0.9889, Training Recall: 0.9889, Training F_1: 0.9889\n",
            "Epoch training time: 436.96 s.\n",
            "############ Val Loss:  1.6879, Val Precision: 0.9512, Val Recall: 0.9512, Val F_1: 0.9512\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Training complete in 76m 57s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt-NC50GpfN1",
        "colab_type": "text"
      },
      "source": [
        "### **layer 3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb-l7_qbpjMY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "403c567a-bc2f-4591-fac9-4c96027d1ae9"
      },
      "source": [
        "# HIDDEN_DIM_1 = 256\n",
        "HIDDEN_DIM = 512\n",
        "EMBEDDING_DIM = 420\n",
        "\n",
        "model = BiLSTM_CRF(tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, layers=2)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "train_model(model, device, optimizer, num_epochs=10, emb_dim=EMBEDDING_DIM)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "[ 500/3000]: Training Loss:  7.4430, Training Precision: 0.8019, Training Recall: 0.8019, Training F_1: 0.8019\n",
            "[1000/3000]: Training Loss:  3.1148, Training Precision: 0.8557, Training Recall: 0.8557, Training F_1: 0.8557\n",
            "[1500/3000]: Training Loss:  2.7156, Training Precision: 0.9296, Training Recall: 0.9296, Training F_1: 0.9296\n",
            "[2000/3000]: Training Loss:  2.5548, Training Precision: 0.9342, Training Recall: 0.9342, Training F_1: 0.9342\n",
            "[2500/3000]: Training Loss:  1.6866, Training Precision: 0.9065, Training Recall: 0.9065, Training F_1: 0.9065\n",
            "[3000/3000]: Training Loss:  1.7803, Training Precision: 0.9451, Training Recall: 0.9451, Training F_1: 0.9451\n",
            "Epoch training time: 274.61 s.\n",
            "############ Val Loss:  1.7316, Val Precision: 0.9379, Val Recall: 0.9379, Val F_1: 0.9379\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 2/10\n",
            "[ 500/3000]: Training Loss:  2.0774, Training Precision: 0.9282, Training Recall: 0.9282, Training F_1: 0.9282\n",
            "[1000/3000]: Training Loss:  1.1545, Training Precision: 0.9361, Training Recall: 0.9361, Training F_1: 0.9361\n",
            "[1500/3000]: Training Loss:  1.4564, Training Precision: 0.9558, Training Recall: 0.9558, Training F_1: 0.9558\n",
            "[2000/3000]: Training Loss:  1.7363, Training Precision: 0.9594, Training Recall: 0.9594, Training F_1: 0.9594\n",
            "[2500/3000]: Training Loss:  1.0295, Training Precision: 0.9391, Training Recall: 0.9391, Training F_1: 0.9391\n",
            "[3000/3000]: Training Loss:  1.2544, Training Precision: 0.9641, Training Recall: 0.9641, Training F_1: 0.9641\n",
            "Epoch training time: 273.01 s.\n",
            "############ Val Loss:  1.3652, Val Precision: 0.9554, Val Recall: 0.9554, Val F_1: 0.9554\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 3/10\n",
            "[ 500/3000]: Training Loss:  1.4897, Training Precision: 0.9479, Training Recall: 0.9479, Training F_1: 0.9479\n",
            "[1000/3000]: Training Loss:  0.8431, Training Precision: 0.9655, Training Recall: 0.9655, Training F_1: 0.9655\n",
            "[1500/3000]: Training Loss:  1.0657, Training Precision: 0.9750, Training Recall: 0.9750, Training F_1: 0.9750\n",
            "[2000/3000]: Training Loss:  1.4213, Training Precision: 0.9635, Training Recall: 0.9635, Training F_1: 0.9635\n",
            "[2500/3000]: Training Loss:  0.7579, Training Precision: 0.9603, Training Recall: 0.9603, Training F_1: 0.9603\n",
            "[3000/3000]: Training Loss:  0.9490, Training Precision: 0.9712, Training Recall: 0.9712, Training F_1: 0.9712\n",
            "Epoch training time: 274.10 s.\n",
            "############ Val Loss:  1.2955, Val Precision: 0.9582, Val Recall: 0.9582, Val F_1: 0.9582\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 4/10\n",
            "[ 500/3000]: Training Loss:  1.2039, Training Precision: 0.9526, Training Recall: 0.9526, Training F_1: 0.9526\n",
            "[1000/3000]: Training Loss:  0.7043, Training Precision: 0.9684, Training Recall: 0.9684, Training F_1: 0.9684\n",
            "[1500/3000]: Training Loss:  0.7984, Training Precision: 0.9765, Training Recall: 0.9765, Training F_1: 0.9765\n",
            "[2000/3000]: Training Loss:  1.1364, Training Precision: 0.9700, Training Recall: 0.9700, Training F_1: 0.9700\n",
            "[2500/3000]: Training Loss:  0.5444, Training Precision: 0.9778, Training Recall: 0.9778, Training F_1: 0.9778\n",
            "[3000/3000]: Training Loss:  0.7322, Training Precision: 0.9823, Training Recall: 0.9823, Training F_1: 0.9823\n",
            "Epoch training time: 273.17 s.\n",
            "############ Val Loss:  1.2351, Val Precision: 0.9608, Val Recall: 0.9608, Val F_1: 0.9608\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 5/10\n",
            "[ 500/3000]: Training Loss:  0.9810, Training Precision: 0.9601, Training Recall: 0.9601, Training F_1: 0.9601\n",
            "[1000/3000]: Training Loss:  0.5361, Training Precision: 0.9706, Training Recall: 0.9706, Training F_1: 0.9706\n",
            "[1500/3000]: Training Loss:  0.6653, Training Precision: 0.9770, Training Recall: 0.9770, Training F_1: 0.9770\n",
            "[2000/3000]: Training Loss:  0.9293, Training Precision: 0.9777, Training Recall: 0.9777, Training F_1: 0.9777\n",
            "[2500/3000]: Training Loss:  0.5023, Training Precision: 0.9769, Training Recall: 0.9769, Training F_1: 0.9769\n",
            "[3000/3000]: Training Loss:  0.6168, Training Precision: 0.9790, Training Recall: 0.9790, Training F_1: 0.9790\n",
            "Epoch training time: 275.07 s.\n",
            "############ Val Loss:  1.3202, Val Precision: 0.9612, Val Recall: 0.9612, Val F_1: 0.9612\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 6/10\n",
            "[ 500/3000]: Training Loss:  0.7862, Training Precision: 0.9660, Training Recall: 0.9660, Training F_1: 0.9660\n",
            "[1000/3000]: Training Loss:  0.4551, Training Precision: 0.9794, Training Recall: 0.9794, Training F_1: 0.9794\n",
            "[1500/3000]: Training Loss:  0.5126, Training Precision: 0.9868, Training Recall: 0.9868, Training F_1: 0.9868\n",
            "[2000/3000]: Training Loss:  0.7520, Training Precision: 0.9792, Training Recall: 0.9792, Training F_1: 0.9792\n",
            "[2500/3000]: Training Loss:  0.3680, Training Precision: 0.9856, Training Recall: 0.9856, Training F_1: 0.9856\n",
            "[3000/3000]: Training Loss:  0.4608, Training Precision: 0.9864, Training Recall: 0.9864, Training F_1: 0.9864\n",
            "Epoch training time: 272.63 s.\n",
            "############ Val Loss:  1.3053, Val Precision: 0.9618, Val Recall: 0.9618, Val F_1: 0.9618\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 7/10\n",
            "[ 500/3000]: Training Loss:  0.6284, Training Precision: 0.9728, Training Recall: 0.9728, Training F_1: 0.9728\n",
            "[1000/3000]: Training Loss:  0.3637, Training Precision: 0.9854, Training Recall: 0.9854, Training F_1: 0.9854\n",
            "[1500/3000]: Training Loss:  0.4204, Training Precision: 0.9876, Training Recall: 0.9876, Training F_1: 0.9876\n",
            "[2000/3000]: Training Loss:  0.6764, Training Precision: 0.9814, Training Recall: 0.9814, Training F_1: 0.9814\n",
            "[2500/3000]: Training Loss:  0.2926, Training Precision: 0.9875, Training Recall: 0.9875, Training F_1: 0.9875\n",
            "[3000/3000]: Training Loss:  0.3454, Training Precision: 0.9869, Training Recall: 0.9869, Training F_1: 0.9869\n",
            "Epoch training time: 275.18 s.\n",
            "############ Val Loss:  1.2802, Val Precision: 0.9639, Val Recall: 0.9639, Val F_1: 0.9639\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 8/10\n",
            "[ 500/3000]: Training Loss:  0.5023, Training Precision: 0.9762, Training Recall: 0.9762, Training F_1: 0.9762\n",
            "[1000/3000]: Training Loss:  0.2919, Training Precision: 0.9829, Training Recall: 0.9829, Training F_1: 0.9829\n",
            "[1500/3000]: Training Loss:  0.3207, Training Precision: 0.9889, Training Recall: 0.9889, Training F_1: 0.9889\n",
            "[2000/3000]: Training Loss:  0.5124, Training Precision: 0.9847, Training Recall: 0.9847, Training F_1: 0.9847\n",
            "[2500/3000]: Training Loss:  0.2667, Training Precision: 0.9863, Training Recall: 0.9863, Training F_1: 0.9863\n",
            "[3000/3000]: Training Loss:  0.2934, Training Precision: 0.9900, Training Recall: 0.9900, Training F_1: 0.9900\n",
            "Epoch training time: 273.60 s.\n",
            "############ Val Loss:  1.1739, Val Precision: 0.9693, Val Recall: 0.9693, Val F_1: 0.9693\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 9/10\n",
            "[ 500/3000]: Training Loss:  0.3973, Training Precision: 0.9773, Training Recall: 0.9773, Training F_1: 0.9773\n",
            "[1000/3000]: Training Loss:  0.2814, Training Precision: 0.9831, Training Recall: 0.9831, Training F_1: 0.9831\n",
            "[1500/3000]: Training Loss:  0.2600, Training Precision: 0.9893, Training Recall: 0.9893, Training F_1: 0.9893\n",
            "[2000/3000]: Training Loss:  0.3883, Training Precision: 0.9891, Training Recall: 0.9891, Training F_1: 0.9891\n",
            "[2500/3000]: Training Loss:  0.2051, Training Precision: 0.9907, Training Recall: 0.9907, Training F_1: 0.9907\n",
            "[3000/3000]: Training Loss:  0.2850, Training Precision: 0.9884, Training Recall: 0.9884, Training F_1: 0.9884\n",
            "Epoch training time: 276.24 s.\n",
            "############ Val Loss:  1.2665, Val Precision: 0.9688, Val Recall: 0.9688, Val F_1: 0.9688\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 10/10\n",
            "[ 500/3000]: Training Loss:  0.3146, Training Precision: 0.9773, Training Recall: 0.9773, Training F_1: 0.9773\n",
            "[1000/3000]: Training Loss:  0.2533, Training Precision: 0.9861, Training Recall: 0.9861, Training F_1: 0.9861\n",
            "[1500/3000]: Training Loss:  0.1953, Training Precision: 0.9939, Training Recall: 0.9939, Training F_1: 0.9939\n",
            "[2000/3000]: Training Loss:  0.3512, Training Precision: 0.9881, Training Recall: 0.9881, Training F_1: 0.9881\n",
            "[2500/3000]: Training Loss:  0.1766, Training Precision: 0.9907, Training Recall: 0.9907, Training F_1: 0.9907\n",
            "[3000/3000]: Training Loss:  0.2022, Training Precision: 0.9931, Training Recall: 0.9931, Training F_1: 0.9931\n",
            "Epoch training time: 273.55 s.\n",
            "############ Val Loss:  1.1866, Val Precision: 0.9734, Val Recall: 0.9734, Val F_1: 0.9734\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Training complete in 48m 21s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG8QBGgRCqSU",
        "colab_type": "text"
      },
      "source": [
        "### **one LSTM layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRjUlf3i-075",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HIDDEN_DIM = 128\n",
        "EMBEDDING_DIM = 157\n",
        "\n",
        "model = BiLSTM_CRF(tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, weight_decay=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BOhMdDR5l8t",
        "colab_type": "text"
      },
      "source": [
        "### **word_emb+pos+dep+tf_idf**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Sxh4uuZ5oah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def calculate_acuracy(labels, model_pred):\n",
        "    precision = precision_score(labels, model_pred, average='micro')\n",
        "    recall = recall_score(labels, model_pred, average='micro')\n",
        "    f1 = f1_score(labels, model_pred, average='micro')\n",
        "    return precision, recall, f1\n",
        "\n",
        "\n",
        "def train_iter(model, device, optimizer, sentence, tags, index):\n",
        "    '''\n",
        "    Train the model for a single iteration.\n",
        "    An iteration is when a single batch of data is passed forward and backward through the neural network.\n",
        "    '''\n",
        "    # move input and output to gpu\n",
        "    # sentence, tags = sentence.to(device), tags.to(device)\n",
        "    # gradient\n",
        "    model.zero_grad()\n",
        "    # forward propagation\n",
        "    sentence_in = emb_pos_dep_tf_idf(sentence, index, flag='train')\n",
        "    targets = torch.tensor([tag_to_ix[t] for t in tags.split()], dtype=torch.long)\n",
        "\n",
        "    loss, outputs = model.neg_log_likelihood(sentence_in, targets)\n",
        "    # with torch.no_grad():\n",
        "    #     _, outputs = model(sentence_in)\n",
        "    # calculate precision and recall\n",
        "    precision, recall, f1 = calculate_acuracy(targets.tolist(), outputs)\n",
        "    # backward propagation\n",
        "    loss.backward()\n",
        "    # Update the parameters. \n",
        "    optimizer.step()\n",
        "    return loss, precision, recall, f1\n",
        "\n",
        "\n",
        "def train_epoch(model, device, optimizer, nlp, emb_dim):\n",
        "    '''\n",
        "    in one epoch, loop through the whole data, keep track and record the precision and recall of each batch\n",
        "    '''\n",
        "    # set model to train mode\n",
        "    time_since = time.time()\n",
        "    model.train()\n",
        "    running_loss = []\n",
        "    running_precision = []\n",
        "    running_recall = []\n",
        "    running_f1 = []\n",
        "    for i, (sentence, tags) in enumerate(zip(sentence_train, ner_train)):\n",
        "        loss, precision, recall, f1 = train_iter(model, device, optimizer, sentence, tags, i)\n",
        "        running_loss.append(loss.item())\n",
        "        running_precision.append(precision)\n",
        "        running_recall.append(recall)\n",
        "        running_f1.append(f1)\n",
        "        if i % 500 == 499:\n",
        "            print('[{:4}/{:4}]'.format(i + 1, len(sentence_train)), end=': ')\n",
        "            print('Training Loss: {:>7.4f}'.format(np.mean(running_loss)), end=', ')\n",
        "            print('Training Precision: {:.4f}'.format(np.mean(running_precision)), end=', ')\n",
        "            print('Training Recall: {:.4f}'.format(np.mean(running_recall)), end=', ')\n",
        "            print('Training F_1: {:.4f}'.format(np.mean(running_f1)))\n",
        "            running_loss = []\n",
        "            running_precision = []\n",
        "            running_recall = []\n",
        "            running_f1 = []\n",
        "    # print('[{:4}/{:4}]'.format(len(sentence_train), len(sentence_train)), end=': ')\n",
        "    # print('Training Loss: {:2.4f}'.format(np.mean(running_loss)), end=', ')\n",
        "    # print('Training Precision: {:.4f}'.format(np.mean(running_precision)), end=', ')\n",
        "    # print('Training Recall: {:.4f}'.format(np.mean(running_recall)), end=', ')\n",
        "    # print('Training F_1: {:.4f}'.format(np.mean(running_f1)))\n",
        "    print('Epoch training time: {:.2f} s.'.format(time.time() - time_since))\n",
        "    return \n",
        "\n",
        "\n",
        "def val_epoch(model, device, nlp, emb_dim):\n",
        "    '''\n",
        "    valid current model on validation set\n",
        "    '''\n",
        "    # set the model to validating mode, without gradient\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        loss_list = []\n",
        "        predictions = []\n",
        "        true_tags = []\n",
        "        for i, (sentence, tags) in enumerate(zip(sentence_val, ner_val)):\n",
        "            sentence_in = emb_pos_dep_tf_idf(sentence, i, flag='val')\n",
        "            targets = torch.tensor([tag_to_ix[t] for t in tags.split()], dtype=torch.long)\n",
        "            for t in targets:\n",
        "                true_tags.append(t.item())\n",
        "            loss, outputs = model.neg_log_likelihood(sentence_in, targets)\n",
        "            loss_list.append(loss.item())\n",
        "            # _, outputs = model(sentence_in)\n",
        "            for p in outputs:\n",
        "                predictions.append(p)\n",
        "        precision, recall, f1 = calculate_acuracy(true_tags, predictions)\n",
        "        print('############ Val Loss: {:>7.4f}'.format(np.mean(loss_list)), end=', ')\n",
        "        print('Val Precision: {:.4f}'.format(precision), end=', ')\n",
        "        print('Val Recall: {:.4f}'.format(recall), end=', ')\n",
        "        print('Val F_1: {:.4f}'.format(f1))\n",
        "    return\n",
        "\n",
        "\n",
        "def train_model(model, device, optimizer, nlp, emb_dim, num_epochs=25):\n",
        "    # record starting time and initialize summary writer\n",
        "    since = time.time()\n",
        "    # train the model num_epoch times\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
        "        # for every epoch, run training and validating\n",
        "        for phase in ['train', 'val']:\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_epoch(model, device, optimizer, nlp, emb_dim)\n",
        "            elif phase == 'val':\n",
        "                val_epoch(model, device, nlp, emb_dim)\n",
        "        torch.save(model, 'The_'+ str(epoch + 1) + '_epoch_model.pt')\n",
        "        print('-' * 109)\n",
        "    \n",
        "    time_cost = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_cost // 60, time_cost % 60))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lTSrpEs6nf5",
        "colab_type": "code",
        "outputId": "993126d0-6d26-494f-e07a-dd627f21aab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "HIDDEN_DIM = 128\n",
        "EMBEDDING_DIM = 158\n",
        "\n",
        "model = BiLSTM_CRF(tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "train_model(model, device, optimizer, num_epochs=5, nlp=nlp, emb_dim=EMBEDDING_DIM)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "[ 500/3000]: Training Loss:  5.3003, Training Precision: 0.8611, Training Recall: 0.8611, Training F_1: 0.8611\n",
            "[1000/3000]: Training Loss:  2.6641, Training Precision: 0.8973, Training Recall: 0.8973, Training F_1: 0.8973\n",
            "[1500/3000]: Training Loss:  3.3774, Training Precision: 0.9210, Training Recall: 0.9210, Training F_1: 0.9210\n",
            "[2000/3000]: Training Loss:  3.3047, Training Precision: 0.9244, Training Recall: 0.9244, Training F_1: 0.9244\n",
            "[2500/3000]: Training Loss:  2.1720, Training Precision: 0.9149, Training Recall: 0.9149, Training F_1: 0.9149\n",
            "[3000/3000]: Training Loss:  2.4789, Training Precision: 0.9256, Training Recall: 0.9256, Training F_1: 0.9256\n",
            "Epoch training time: 134.21 s.\n",
            "############ Val Loss:  2.9632, Val Precision: 0.8937, Val Recall: 0.8937, Val F_1: 0.8937\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 2/5\n",
            "[ 500/3000]: Training Loss:  2.6533, Training Precision: 0.9069, Training Recall: 0.9069, Training F_1: 0.9069\n",
            "[1000/3000]: Training Loss:  1.5074, Training Precision: 0.9387, Training Recall: 0.9387, Training F_1: 0.9387\n",
            "[1500/3000]: Training Loss:  2.3642, Training Precision: 0.9395, Training Recall: 0.9395, Training F_1: 0.9395\n",
            "[2000/3000]: Training Loss:  2.4303, Training Precision: 0.9450, Training Recall: 0.9450, Training F_1: 0.9450\n",
            "[2500/3000]: Training Loss:  1.4422, Training Precision: 0.9435, Training Recall: 0.9435, Training F_1: 0.9435\n",
            "[3000/3000]: Training Loss:  1.8056, Training Precision: 0.9497, Training Recall: 0.9497, Training F_1: 0.9497\n",
            "Epoch training time: 134.07 s.\n",
            "############ Val Loss:  2.9366, Val Precision: 0.8911, Val Recall: 0.8911, Val F_1: 0.8911\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 3/5\n",
            "[ 500/3000]: Training Loss:  1.9019, Training Precision: 0.9292, Training Recall: 0.9292, Training F_1: 0.9292\n",
            "[1000/3000]: Training Loss:  1.0893, Training Precision: 0.9633, Training Recall: 0.9633, Training F_1: 0.9633\n",
            "[1500/3000]: Training Loss:  1.7661, Training Precision: 0.9507, Training Recall: 0.9507, Training F_1: 0.9507\n",
            "[2000/3000]: Training Loss:  1.8436, Training Precision: 0.9574, Training Recall: 0.9574, Training F_1: 0.9574\n",
            "[2500/3000]: Training Loss:  0.9715, Training Precision: 0.9710, Training Recall: 0.9710, Training F_1: 0.9710\n",
            "[3000/3000]: Training Loss:  1.3459, Training Precision: 0.9610, Training Recall: 0.9610, Training F_1: 0.9610\n",
            "Epoch training time: 133.55 s.\n",
            "############ Val Loss:  2.7714, Val Precision: 0.9079, Val Recall: 0.9079, Val F_1: 0.9079\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 4/5\n",
            "[ 500/3000]: Training Loss:  1.3711, Training Precision: 0.9409, Training Recall: 0.9409, Training F_1: 0.9409\n",
            "[1000/3000]: Training Loss:  0.8236, Training Precision: 0.9675, Training Recall: 0.9675, Training F_1: 0.9675\n",
            "[1500/3000]: Training Loss:  1.2257, Training Precision: 0.9682, Training Recall: 0.9682, Training F_1: 0.9682\n",
            "[2000/3000]: Training Loss:  1.3279, Training Precision: 0.9673, Training Recall: 0.9673, Training F_1: 0.9673\n",
            "[2500/3000]: Training Loss:  0.6875, Training Precision: 0.9721, Training Recall: 0.9721, Training F_1: 0.9721\n",
            "[3000/3000]: Training Loss:  0.9530, Training Precision: 0.9773, Training Recall: 0.9773, Training F_1: 0.9773\n",
            "Epoch training time: 133.88 s.\n",
            "############ Val Loss:  2.8189, Val Precision: 0.9109, Val Recall: 0.9109, Val F_1: 0.9109\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 5/5\n",
            "[ 500/3000]: Training Loss:  0.9648, Training Precision: 0.9673, Training Recall: 0.9673, Training F_1: 0.9673\n",
            "[1000/3000]: Training Loss:  0.5907, Training Precision: 0.9814, Training Recall: 0.9814, Training F_1: 0.9814\n",
            "[1500/3000]: Training Loss:  0.7769, Training Precision: 0.9776, Training Recall: 0.9776, Training F_1: 0.9776\n",
            "[2000/3000]: Training Loss:  0.9889, Training Precision: 0.9759, Training Recall: 0.9759, Training F_1: 0.9759\n",
            "[2500/3000]: Training Loss:  0.4592, Training Precision: 0.9799, Training Recall: 0.9799, Training F_1: 0.9799\n",
            "[3000/3000]: Training Loss:  0.6597, Training Precision: 0.9794, Training Recall: 0.9794, Training F_1: 0.9794\n",
            "Epoch training time: 134.37 s.\n",
            "############ Val Loss:  2.8114, Val Precision: 0.9132, Val Recall: 0.9132, Val F_1: 0.9132\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Training complete in 12m 12s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiEH250hDyQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbpVBcAbQ9B0",
        "colab_type": "text"
      },
      "source": [
        "### **word_emb+pos+dep**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGCbQsdWrdM2",
        "colab_type": "code",
        "outputId": "ad08754c-f486-483a-ade6-34107a9a021c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "HIDDEN_DIM = 128\n",
        "EMBEDDING_DIM = 157\n",
        "\n",
        "model = BiLSTM_CRF(tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "train_model(model, device, optimizer, num_epochs=5, nlp=nlp, emb_dim=EMBEDDING_DIM)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "[ 500/3000]: Training Loss:  5.5581, Training Precision: 0.8568, Training Recall: 0.8568, Training F_1: 0.8568\n",
            "[1000/3000]: Training Loss:  2.5450, Training Precision: 0.9013, Training Recall: 0.9013, Training F_1: 0.9013\n",
            "[1500/3000]: Training Loss:  3.3812, Training Precision: 0.9219, Training Recall: 0.9219, Training F_1: 0.9219\n",
            "[2000/3000]: Training Loss:  3.3821, Training Precision: 0.9211, Training Recall: 0.9211, Training F_1: 0.9211\n",
            "[2500/3000]: Training Loss:  2.1253, Training Precision: 0.9230, Training Recall: 0.9230, Training F_1: 0.9230\n",
            "[3000/3000]: Training Loss:  2.4866, Training Precision: 0.9355, Training Recall: 0.9355, Training F_1: 0.9355\n",
            "Epoch training time: 140.41 s.\n",
            "############ Val Loss:  3.0109, Val Precision: 0.8933, Val Recall: 0.8933, Val F_1: 0.8933\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 2/5\n",
            "[ 500/3000]: Training Loss:  2.6851, Training Precision: 0.9193, Training Recall: 0.9193, Training F_1: 0.9193\n",
            "[1000/3000]: Training Loss:  1.5156, Training Precision: 0.9361, Training Recall: 0.9361, Training F_1: 0.9361\n",
            "[1500/3000]: Training Loss:  2.3728, Training Precision: 0.9398, Training Recall: 0.9398, Training F_1: 0.9398\n",
            "[2000/3000]: Training Loss:  2.4770, Training Precision: 0.9374, Training Recall: 0.9374, Training F_1: 0.9374\n",
            "[2500/3000]: Training Loss:  1.4566, Training Precision: 0.9492, Training Recall: 0.9492, Training F_1: 0.9492\n",
            "[3000/3000]: Training Loss:  1.8432, Training Precision: 0.9463, Training Recall: 0.9463, Training F_1: 0.9463\n",
            "Epoch training time: 138.09 s.\n",
            "############ Val Loss:  2.7017, Val Precision: 0.9076, Val Recall: 0.9076, Val F_1: 0.9076\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 3/5\n",
            "[ 500/3000]: Training Loss:  1.9389, Training Precision: 0.9371, Training Recall: 0.9371, Training F_1: 0.9371\n",
            "[1000/3000]: Training Loss:  1.1206, Training Precision: 0.9571, Training Recall: 0.9571, Training F_1: 0.9571\n",
            "[1500/3000]: Training Loss:  1.7255, Training Precision: 0.9584, Training Recall: 0.9584, Training F_1: 0.9584\n",
            "[2000/3000]: Training Loss:  1.9223, Training Precision: 0.9539, Training Recall: 0.9539, Training F_1: 0.9539\n",
            "[2500/3000]: Training Loss:  1.0279, Training Precision: 0.9631, Training Recall: 0.9631, Training F_1: 0.9631\n",
            "[3000/3000]: Training Loss:  1.3803, Training Precision: 0.9533, Training Recall: 0.9533, Training F_1: 0.9533\n",
            "Epoch training time: 139.12 s.\n",
            "############ Val Loss:  2.7952, Val Precision: 0.9068, Val Recall: 0.9068, Val F_1: 0.9068\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 4/5\n",
            "[ 500/3000]: Training Loss:  1.4198, Training Precision: 0.9504, Training Recall: 0.9504, Training F_1: 0.9504\n",
            "[1000/3000]: Training Loss:  0.8534, Training Precision: 0.9757, Training Recall: 0.9757, Training F_1: 0.9757\n",
            "[1500/3000]: Training Loss:  1.2924, Training Precision: 0.9596, Training Recall: 0.9596, Training F_1: 0.9596\n",
            "[2000/3000]: Training Loss:  1.3665, Training Precision: 0.9654, Training Recall: 0.9654, Training F_1: 0.9654\n",
            "[2500/3000]: Training Loss:  0.7357, Training Precision: 0.9756, Training Recall: 0.9756, Training F_1: 0.9756\n",
            "[3000/3000]: Training Loss:  0.9615, Training Precision: 0.9704, Training Recall: 0.9704, Training F_1: 0.9704\n",
            "Epoch training time: 138.24 s.\n",
            "############ Val Loss:  2.8514, Val Precision: 0.9113, Val Recall: 0.9113, Val F_1: 0.9113\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 5/5\n",
            "[ 500/3000]: Training Loss:  1.0063, Training Precision: 0.9655, Training Recall: 0.9655, Training F_1: 0.9655\n",
            "[1000/3000]: Training Loss:  0.6324, Training Precision: 0.9770, Training Recall: 0.9770, Training F_1: 0.9770\n",
            "[1500/3000]: Training Loss:  0.9191, Training Precision: 0.9728, Training Recall: 0.9728, Training F_1: 0.9728\n",
            "[2000/3000]: Training Loss:  1.0269, Training Precision: 0.9750, Training Recall: 0.9750, Training F_1: 0.9750\n",
            "[2500/3000]: Training Loss:  0.5343, Training Precision: 0.9848, Training Recall: 0.9848, Training F_1: 0.9848\n",
            "[3000/3000]: Training Loss:  0.6809, Training Precision: 0.9763, Training Recall: 0.9763, Training F_1: 0.9763\n",
            "Epoch training time: 139.44 s.\n",
            "############ Val Loss:  3.0569, Val Precision: 0.9058, Val Recall: 0.9058, Val F_1: 0.9058\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Training complete in 12m 37s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xFxMjkZJOH7",
        "colab_type": "text"
      },
      "source": [
        "### **baseline model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiPLGM8CJN2l",
        "colab_type": "code",
        "outputId": "a74e349a-d45f-412c-8559-fb43c0f671f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "HIDDEN_DIM = 50\n",
        "EMBEDDING_DIM = 50\n",
        "\n",
        "model = BiLSTM_CRF(tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "train_model(model, device, optimizer, num_epochs=5, nlp=None, emb_dim=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "[ 500/3000]: Training Loss: 10.2738, Training Precision: 0.7489, Training Recall: 0.7489, Training F_1: 0.7489\n",
            "[1000/3000]: Training Loss:  8.5752, Training Precision: 0.6726, Training Recall: 0.6726, Training F_1: 0.6726\n",
            "[1500/3000]: Training Loss:  7.7830, Training Precision: 0.8310, Training Recall: 0.8310, Training F_1: 0.8310\n",
            "[2000/3000]: Training Loss:  7.8989, Training Precision: 0.8516, Training Recall: 0.8516, Training F_1: 0.8516\n",
            "[2500/3000]: Training Loss:  7.8406, Training Precision: 0.7180, Training Recall: 0.7180, Training F_1: 0.7180\n",
            "[3000/3000]: Training Loss:  8.0194, Training Precision: 0.7141, Training Recall: 0.7141, Training F_1: 0.7141\n",
            "Epoch training time: 135.87 s.\n",
            "############ Val Loss:  8.7840, Val Precision: 0.7663, Val Recall: 0.7663, Val F_1: 0.7663\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 2/5\n",
            "[ 500/3000]: Training Loss:  8.2153, Training Precision: 0.7804, Training Recall: 0.7804, Training F_1: 0.7804\n",
            "[1000/3000]: Training Loss:  8.0825, Training Precision: 0.6660, Training Recall: 0.6660, Training F_1: 0.6660\n",
            "[1500/3000]: Training Loss:  7.5685, Training Precision: 0.8310, Training Recall: 0.8310, Training F_1: 0.8310\n",
            "[2000/3000]: Training Loss:  7.7566, Training Precision: 0.8516, Training Recall: 0.8516, Training F_1: 0.8516\n",
            "[2500/3000]: Training Loss:  7.7359, Training Precision: 0.7187, Training Recall: 0.7187, Training F_1: 0.7187\n",
            "[3000/3000]: Training Loss:  7.9663, Training Precision: 0.7130, Training Recall: 0.7130, Training F_1: 0.7130\n",
            "Epoch training time: 137.18 s.\n",
            "############ Val Loss:  8.6723, Val Precision: 0.7663, Val Recall: 0.7663, Val F_1: 0.7663\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 3/5\n",
            "[ 500/3000]: Training Loss:  8.1369, Training Precision: 0.7765, Training Recall: 0.7765, Training F_1: 0.7765\n",
            "[1000/3000]: Training Loss:  8.0217, Training Precision: 0.6688, Training Recall: 0.6688, Training F_1: 0.6688\n",
            "[1500/3000]: Training Loss:  7.5311, Training Precision: 0.8310, Training Recall: 0.8310, Training F_1: 0.8310\n",
            "[2000/3000]: Training Loss:  7.7235, Training Precision: 0.8516, Training Recall: 0.8516, Training F_1: 0.8516\n",
            "[2500/3000]: Training Loss:  7.6895, Training Precision: 0.7202, Training Recall: 0.7202, Training F_1: 0.7202\n",
            "[3000/3000]: Training Loss:  7.9163, Training Precision: 0.7048, Training Recall: 0.7048, Training F_1: 0.7048\n",
            "Epoch training time: 143.28 s.\n",
            "############ Val Loss:  8.6613, Val Precision: 0.7663, Val Recall: 0.7663, Val F_1: 0.7663\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 4/5\n",
            "[ 500/3000]: Training Loss:  8.1336, Training Precision: 0.7813, Training Recall: 0.7813, Training F_1: 0.7813\n",
            "[1000/3000]: Training Loss:  7.9758, Training Precision: 0.6629, Training Recall: 0.6629, Training F_1: 0.6629\n",
            "[1500/3000]: Training Loss:  7.5134, Training Precision: 0.8317, Training Recall: 0.8317, Training F_1: 0.8317\n",
            "[2000/3000]: Training Loss:  7.7058, Training Precision: 0.8516, Training Recall: 0.8516, Training F_1: 0.8516\n",
            "[2500/3000]: Training Loss:  7.6772, Training Precision: 0.7163, Training Recall: 0.7163, Training F_1: 0.7163\n",
            "[3000/3000]: Training Loss:  7.8815, Training Precision: 0.7081, Training Recall: 0.7081, Training F_1: 0.7081\n",
            "Epoch training time: 134.55 s.\n",
            "############ Val Loss:  8.6709, Val Precision: 0.7663, Val Recall: 0.7663, Val F_1: 0.7663\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Epoch 5/5\n",
            "[ 500/3000]: Training Loss:  8.1128, Training Precision: 0.7807, Training Recall: 0.7807, Training F_1: 0.7807\n",
            "[1000/3000]: Training Loss:  7.9425, Training Precision: 0.6642, Training Recall: 0.6642, Training F_1: 0.6642\n",
            "[1500/3000]: Training Loss:  7.5031, Training Precision: 0.8320, Training Recall: 0.8320, Training F_1: 0.8320\n",
            "[2000/3000]: Training Loss:  7.7083, Training Precision: 0.8516, Training Recall: 0.8516, Training F_1: 0.8516\n",
            "[2500/3000]: Training Loss:  7.6829, Training Precision: 0.7137, Training Recall: 0.7137, Training F_1: 0.7137\n",
            "[3000/3000]: Training Loss:  7.8614, Training Precision: 0.6978, Training Recall: 0.6978, Training F_1: 0.6978\n",
            "Epoch training time: 131.65 s.\n",
            "############ Val Loss:  8.6146, Val Precision: 0.7663, Val Recall: 0.7663, Val F_1: 0.7663\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "Training complete in 12m 20s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO6o8gI6aoat",
        "colab_type": "code",
        "outputId": "76e85667-b845-4b74-82ab-ca4640d31e2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "a = [1,2,3]\n",
        "b = [2,3,4]\n",
        "a.append()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-5be973ab5051>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: append() argument after ** must be a mapping, not list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muQUIOZNkuCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.tensor([1,2,3], dtype=torch.long)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooFkdK7lpO_r",
        "colab_type": "code",
        "outputId": "a77d6048-6d60-4aa3-a3b8-5c1070eff1f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Training Loss: {:>5.2f}'.format(4.3333))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss:  4.33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg3cF4dVsYeF",
        "colab_type": "code",
        "outputId": "8970ccbf-177e-409c-cfe3-157327908b90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "5 % 2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVHlccNtwbfQ",
        "colab_type": "code",
        "outputId": "b905c059-d89d-46e9-cc56-76714ac97069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "[e.item() for e in a]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM7qDxGdyDSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rHO_gLsPJ6X",
        "colab_type": "code",
        "outputId": "6d2dad9b-5154-494e-e66b-12dbf99f2f79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!pip install -q --upgrade ipython\n",
        "!pip install -q --upgrade ipykernel"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     || 788kB 11.9MB/s \n",
            "\u001b[K     || 358kB 50.2MB/s \n",
            "\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 3.0.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     || 122kB 14.7MB/s \n",
            "\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 3.0.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.3.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BJM7meOwG0H",
        "colab_type": "code",
        "outputId": "21b1c84a-31ad-4120-9560-e0aae337dbe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "HIDDEN_DIM = 256\n",
        "EMBEDDING_DIM = 157\n",
        "\n",
        "\n",
        "model = BiLSTM_CRF(tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "# Check predictions before training\n",
        "with torch.no_grad():\n",
        "    # precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "    precheck_sent = prepare_embeddings(sentence_train[1], nlp)\n",
        "    precheck_tags = torch.tensor([tag_to_ix[t] for t in ner_train[1].split()], dtype=torch.long)\n",
        "    print(model(precheck_sent))\n",
        "\n",
        "# Make sure prepare_sequence from earlier in the LSTM section is loaded\n",
        "for epoch in range(5):  # again, normally you would NOT do 300 epochs, it is toy data\n",
        "    # for sentence, tags in training_data:\n",
        "\n",
        "    for sentence, tags in zip(sentence_train, ner_train):\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        # sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "        sentence_in = prepare_embeddings(sentence, nlp)\n",
        "        targets = torch.tensor([tag_to_ix[t] for t in tags.split()], dtype=torch.long)\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        print(loss.item())\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Check predictions after training\n",
        "with torch.no_grad():\n",
        "    # precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "    precheck_sent = prepare_embeddings(sentence_train[1], nlp)\n",
        "    print(model(precheck_sent))\n",
        "# We got it!"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor(15.6371), [0, 2, 1, 2, 1, 2, 1, 4, 3])\n",
            "0.6828417778015137\n",
            "17.53197479248047\n",
            "2.8264882564544678\n",
            "1.879255771636963\n",
            "64.332763671875\n",
            "41.680152893066406\n",
            "36.992462158203125\n",
            "18.788185119628906\n",
            "16.35803985595703\n",
            "31.099395751953125\n",
            "14.279205322265625\n",
            "20.549110412597656\n",
            "0.16658544540405273\n",
            "7.825750350952148\n",
            "6.1936492919921875\n",
            "6.334251403808594\n",
            "15.946723937988281\n",
            "33.514747619628906\n",
            "6.8483734130859375\n",
            "4.7913665771484375\n",
            "4.246574401855469\n",
            "0.4911832809448242\n",
            "5.923057556152344\n",
            "1.557264804840088\n",
            "6.61895751953125\n",
            "26.05602264404297\n",
            "6.949073791503906\n",
            "5.9677886962890625\n",
            "7.78851318359375\n",
            "0.4167518615722656\n",
            "0.1352682113647461\n",
            "3.076974868774414\n",
            "1.1157255172729492\n",
            "21.365493774414062\n",
            "16.500274658203125\n",
            "8.538810729980469\n",
            "0.817535400390625\n",
            "13.244148254394531\n",
            "17.302505493164062\n",
            "8.660789489746094\n",
            "0.20551109313964844\n",
            "1.8585643768310547\n",
            "0.7793335914611816\n",
            "1.630828857421875\n",
            "35.75518798828125\n",
            "0.3557615280151367\n",
            "10.623384475708008\n",
            "2.0036354064941406\n",
            "20.11725616455078\n",
            "1.3179550170898438\n",
            "1.0858230590820312\n",
            "1.3635139465332031\n",
            "5.8373870849609375\n",
            "2.6554794311523438\n",
            "2.5644378662109375\n",
            "7.2424468994140625\n",
            "3.4739761352539062\n",
            "7.707820892333984\n",
            "2.9403228759765625\n",
            "1.574676513671875\n",
            "0.1858654022216797\n",
            "4.506183624267578\n",
            "2.164714813232422\n",
            "20.021018981933594\n",
            "9.25726318359375\n",
            "8.934732437133789\n",
            "0.23787546157836914\n",
            "5.429418563842773\n",
            "1.4584946632385254\n",
            "3.988544464111328\n",
            "6.150262355804443\n",
            "4.040882110595703\n",
            "1.7367839813232422\n",
            "0.5707931518554688\n",
            "2.1118717193603516\n",
            "13.112770080566406\n",
            "1.8276138305664062\n",
            "3.384998321533203\n",
            "1.0280685424804688\n",
            "0.7746372222900391\n",
            "6.805820465087891\n",
            "4.99254035949707\n",
            "0.1461491584777832\n",
            "1.8068695068359375\n",
            "1.2118330001831055\n",
            "5.633811950683594\n",
            "7.867254257202148\n",
            "2.5304298400878906\n",
            "3.741201400756836\n",
            "2.4113998413085938\n",
            "2.965566635131836\n",
            "0.2828102111816406\n",
            "15.724735260009766\n",
            "2.124774932861328\n",
            "8.254266738891602\n",
            "1.9842529296875\n",
            "0.2189617156982422\n",
            "4.968105316162109\n",
            "0.21530866622924805\n",
            "13.13563346862793\n",
            "12.832784652709961\n",
            "11.918319702148438\n",
            "0.43135857582092285\n",
            "2.763225555419922\n",
            "3.733370304107666\n",
            "1.1840548515319824\n",
            "3.8102493286132812\n",
            "13.316940307617188\n",
            "2.6870651245117188\n",
            "4.682861328125\n",
            "4.372547149658203\n",
            "10.300765991210938\n",
            "5.005378723144531\n",
            "1.8079490661621094\n",
            "4.977119445800781\n",
            "0.2557373046875\n",
            "20.747879028320312\n",
            "20.2706298828125\n",
            "8.405242919921875\n",
            "2.349872589111328\n",
            "1.8123893737792969\n",
            "0.22797775268554688\n",
            "0.41058349609375\n",
            "5.3806610107421875\n",
            "1.893890380859375\n",
            "2.6645736694335938\n",
            "0.23011398315429688\n",
            "8.47525405883789\n",
            "0.09436798095703125\n",
            "6.270534515380859\n",
            "7.028846740722656\n",
            "0.29689836502075195\n",
            "3.4828739166259766\n",
            "1.1693668365478516\n",
            "18.229751586914062\n",
            "0.33500099182128906\n",
            "9.215164184570312\n",
            "5.106414794921875\n",
            "3.929473876953125\n",
            "0.2857825756072998\n",
            "2.0759811401367188\n",
            "2.0112757682800293\n",
            "0.9080476760864258\n",
            "6.206855773925781\n",
            "34.035865783691406\n",
            "10.411689758300781\n",
            "4.909149169921875\n",
            "9.296012878417969\n",
            "17.18836212158203\n",
            "17.4898681640625\n",
            "2.2077865600585938\n",
            "11.811347961425781\n",
            "2.0008392333984375\n",
            "9.15130615234375\n",
            "8.414352416992188\n",
            "0.22812557220458984\n",
            "2.4614295959472656\n",
            "0.9076342582702637\n",
            "1.8382415771484375\n",
            "1.0361824035644531\n",
            "0.2754364013671875\n",
            "0.17279815673828125\n",
            "2.491668701171875\n",
            "1.4411773681640625\n",
            "0.10987186431884766\n",
            "6.150012969970703\n",
            "0.3390336036682129\n",
            "12.006240844726562\n",
            "0.08537673950195312\n",
            "11.153854370117188\n",
            "13.1119384765625\n",
            "4.4166259765625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-d5965cc757fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag_to_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Step 3. Run our forward pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Step 4. Compute the loss, gradients, and update the parameters by\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-71-6658bfc281e0>\u001b[0m in \u001b[0;36mneg_log_likelihood\u001b[0;34m(self, sentence, tags)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lstm_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mforward_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_alg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mgold_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mforward_score\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgold_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-71-6658bfc281e0>\u001b[0m in \u001b[0;36m_score_sentence\u001b[0;34m(self, feats, tags)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m+\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_to_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSTOP_TAG\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyrnSaBB_MJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "print('!')\n",
        "# Check predictions before training\n",
        "with torch.no_grad():\n",
        "    # precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "    precheck_sent = prepare_embeddings(sentence_train[1], nlp)\n",
        "    precheck_sent = precheck_sent.to(device)\n",
        "    precheck_tags = torch.tensor([tag_to_ix[t] for t in ner_train[1].split()], dtype=torch.long)\n",
        "    print(model(precheck_sent))\n",
        "\n",
        "# Make sure prepare_sequence from earlier in the LSTM section is loaded\n",
        "for epoch in range(5):  # again, normally you would NOT do 300 epochs, it is toy data\n",
        "    # for sentence, tags in training_data:\n",
        "\n",
        "    for sentence, tags in zip(sentence_train, ner_train):\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        # sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "        sentence_in = prepare_embeddings(sentence, nlp)\n",
        "        targets = torch.tensor([tag_to_ix[t] for t in tags.split()], dtype=torch.long)\n",
        "        sentence_in, targets = sentence_in.to(device), targets.to(device)\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        # print(loss.item())\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Check predictions after training\n",
        "with torch.no_grad():\n",
        "    # precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "    precheck_sent = prepare_embeddings(sentence_train[1], nlp)\n",
        "    precheck_sent = precheck_sent.to(device)\n",
        "    print(model(precheck_sent))\n",
        "# We got it!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2S2uKldKwd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    # precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "    precheck_sent = prepare_embeddings(sentence_train[1], nlp)\n",
        "    precheck_sent = precheck_sent.to(device)\n",
        "    # precheck_tags = torch.tensor([tag_to_ix[t] for t in ner_train[1].split()], dtype=torch.long)\n",
        "    # print(model(precheck_sent))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0m5qpM6LOAj",
        "colab_type": "code",
        "outputId": "5ef5468c-3dbd-4de9-db17-0293673e38c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import json\n",
        "\n",
        "with open(\"/var/log/colab-jupyter.log\", \"r\") as fo:\n",
        "  for line in fo:\n",
        "    print(json.loads(line)['msg'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret\n",
            "google.colab serverextension initialized.\n",
            "Serving notebooks from local directory: /\n",
            "0 active kernels\n",
            "The Jupyter Notebook is running at:\n",
            "http://172.28.0.2:9000/\n",
            "Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
            "Kernel started: 1c1905de-178e-470b-ac84-c851b1a73f65\n",
            "Adapting to protocol v5.1 for kernel 1c1905de-178e-470b-ac84-c851b1a73f65\n",
            "KernelRestarter: restarting kernel (1/5), keep random ports\n",
            "WARNING:root:kernel 1c1905de-178e-470b-ac84-c851b1a73f65 restarted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2OIk3GV7sLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfSJx20h7sEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find all pos and dep in this document\n",
        "# nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "pos_tag, dep_tag, tag_set = set(), set(), set()\n",
        "for sentence in sentence_train:\n",
        "    parse = nlp(sentence)\n",
        "    for token in parse:\n",
        "        pos_tag.add(token.pos_)\n",
        "        dep_tag.add(token.dep_)\n",
        "        tag_set.add(token.tag_)\n",
        "\n",
        "for sentence in sentence_val:\n",
        "    parse = nlp(sentence)\n",
        "    for token in parse:\n",
        "        pos_tag.add(token.pos_)\n",
        "        dep_tag.add(token.dep_)\n",
        "        tag_set.add(token.tag_)\n",
        "\n",
        "for sentence in sentence_test:\n",
        "    parse = nlp(sentence)\n",
        "    for token in parse:\n",
        "        pos_tag.add(token.pos_)\n",
        "        dep_tag.add(token.dep_)\n",
        "        tag_set.add(token.tag_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZrMRxYU7_rQ",
        "colab_type": "code",
        "outputId": "87b7f596-c05e-4f7a-8eab-235befbe02ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "tag_set"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'$',\n",
              " \"''\",\n",
              " ',',\n",
              " '-LRB-',\n",
              " '-RRB-',\n",
              " '.',\n",
              " ':',\n",
              " 'ADD',\n",
              " 'CC',\n",
              " 'CD',\n",
              " 'DT',\n",
              " 'EX',\n",
              " 'FW',\n",
              " 'HYPH',\n",
              " 'IN',\n",
              " 'JJ',\n",
              " 'JJR',\n",
              " 'JJS',\n",
              " 'LS',\n",
              " 'MD',\n",
              " 'NFP',\n",
              " 'NN',\n",
              " 'NNP',\n",
              " 'NNPS',\n",
              " 'NNS',\n",
              " 'PDT',\n",
              " 'POS',\n",
              " 'PRP',\n",
              " 'PRP$',\n",
              " 'RB',\n",
              " 'RBR',\n",
              " 'RBS',\n",
              " 'RP',\n",
              " 'SYM',\n",
              " 'TO',\n",
              " 'UH',\n",
              " 'VB',\n",
              " 'VBD',\n",
              " 'VBG',\n",
              " 'VBN',\n",
              " 'VBP',\n",
              " 'VBZ',\n",
              " 'WDT',\n",
              " 'WP',\n",
              " 'WP$',\n",
              " 'WRB',\n",
              " 'XX',\n",
              " '``'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkPUpD238Tr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOcUwxtGAfTG",
        "colab_type": "text"
      },
      "source": [
        "try attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OJB7IXNS-cr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, tag_to_ix, embedding_dim, hidden_dim, num_heads, layers=1):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        self.layers = layers\n",
        "        # self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=self.layers, bidirectional=True)\n",
        "        self.lstm1 = nn.LSTM(embedding_dim*2, hidden_dim // 2,\n",
        "                            num_layers=self.layers, bidirectional=True)\n",
        "        self.lstm2 = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=self.layers, bidirectional=True)\n",
        "        \n",
        "        self.multiheadAtt = nn.MultiheadAttention(self.embedding_dim, num_heads)\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "        \n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def argmax(self, vec):\n",
        "        # return the argmax as a python int\n",
        "        _, idx = torch.max(vec, 1)\n",
        "        return idx.item()\n",
        "    \n",
        "    # Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "    def log_sum_exp(self, vec):\n",
        "        max_score = vec[0, self.argmax(vec)]\n",
        "        max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "        return max_score + \\\n",
        "            torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2 * self.layers, 1, self.hidden_dim // 2),\n",
        "                torch.randn(2 * self.layers, 1, self.hidden_dim // 2))\n",
        "\n",
        "#################################\n",
        "    def cal_summary(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        lstm_out, (h_n, c_n) = self.lstm(sentence, self.hidden)\n",
        "        summary = torch.cat((h_n[0,:,:], h_n[1,:,:]), 1)\n",
        "        return summary.view(1, 1, -1)\n",
        "\n",
        "    def cal_attention(self, summary, input_tensor, method):\n",
        "\n",
        "        if method == 'Dot Product':\n",
        "            # bmm: https://pytorch.org/docs/master/generated/torch.bmm.html\n",
        "            attn_weights = F.softmax(torch.bmm(summary, input_tensor.T.unsqueeze(0)), dim=-1)\n",
        "            attn_output = torch.bmm(attn_weights, input_tensor.unsqueeze(0))\n",
        "            concat_output = torch.cat((attn_output[0], summary[0]), 1)\n",
        "        \n",
        "        elif method == 'Scaled_Dot_Product':\n",
        "            # COMPLETE THIS PART - Scale Dot Product calculation method\n",
        "            # attn_weights = F.softmax(1/np.sqrt(self.hidden_dim // 2) * torch.bmm(summary, input_tensor.T.unsqueeze(0)), dim=-1)\n",
        "            print(input_tensor.shape)\n",
        "            N = input_tensor.shape[0]\n",
        "            input_tensor = input_tensor.view(1, N, -1)\n",
        "            attn_weights = F.softmax(1/np.sqrt(self.hidden_dim // 2) * torch.bmm(summary, input_tensor.T.unsqueeze(0)), dim=-1)\n",
        "            attn_output = torch.bmm(attn_weights, input_tensor.unsqueeze(0))\n",
        "            concat_output = torch.cat((attn_output[0], summary[0]), 1)\n",
        "\n",
        "        return concat_output\n",
        "##################################\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(self.log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = self.log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        summary = self.cal_summary(sentence)\n",
        "        # print(sentence.T.shape)\n",
        "        summary_attn_output1 = self.cal_attention(summary, sentence, method='Scaled_Dot_Product')\n",
        "        print(summary_attn_output1.unsqueeze(1).shape)\n",
        "        self.hidden = self.init_hidden()\n",
        "        lstm_out1, self.hidden = self.lstm1(summary_attn_output1.unsqueeze(1), self.hidden)\n",
        "\n",
        "        self_attn_output, _ = self.multiheadAtt(lstm_out1, lstm_out1, lstm_out1)\n",
        "\n",
        "        lstm_out2, self.hidden = self.lstm2(self_attn_output, self.hidden)\n",
        "        print('lstm2', end=' ')\n",
        "        print(lstm_out2.shape)\n",
        "        # summary_attn_output2 = self.cal_attention(summary, lstm_out2, method='Scaled_Dot_Product')\n",
        "\n",
        "        lstm_out = lstm_out2.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = self.argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = self.argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(feats)\n",
        "        return forward_score - gold_score, tag_seq\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DVAgPCIxL_h",
        "colab_type": "code",
        "outputId": "5278c132-6ca9-4439-adc7-c183b97c3492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "HIDDEN_DIM = 410\n",
        "EMBEDDING_DIM = 410\n",
        "\n",
        "model = BiLSTM_CRF(tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, layers=1, num_heads=10)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "train_model(model, device, optimizer, num_epochs=10, emb_dim=EMBEDDING_DIM)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "torch.Size([1, 1, 410])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-148-7e6750212be8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-70-8c06c67d7a92>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, device, optimizer, emb_dim, num_epochs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-8c06c67d7a92>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, device, optimizer, emb_dim)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mrunning_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mner_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mrunning_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mrunning_precision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-8c06c67d7a92>\u001b[0m in \u001b[0;36mtrain_iter\u001b[0;34m(model, device, optimizer, sentence, tags, index, emb_dim)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag_to_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# with torch.no_grad():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m#     _, outputs = model(sentence_in)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-147-afb3e0808bea>\u001b[0m in \u001b[0;36mneg_log_likelihood\u001b[0;34m(self, sentence, tags)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mneg_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lstm_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0mforward_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_alg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mgold_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-147-afb3e0808bea>\u001b[0m in \u001b[0;36m_get_lstm_features\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcal_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# print(sentence.T.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0msummary_attn_output1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcal_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Scaled_Dot_Product'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_attn_output1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-147-afb3e0808bea>\u001b[0m in \u001b[0;36mcal_attention\u001b[0;34m(self, summary, input_tensor, method)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mconcat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 3-dimensional tensor, but got 4-dimensional tensor for argument #2 'batch2' (while checking arguments for bmm)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SecnjS9fuOWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos_table = {\n",
        "    'ADJ': 0,\n",
        "    'ADP': 1,\n",
        "    'ADV': 2,\n",
        "    'AUX': 3,\n",
        "    'CCONJ': 4,\n",
        "    'DET': 5,\n",
        "    'INTJ': 6,\n",
        "    'NOUN': 7,\n",
        "    'NUM': 8,\n",
        "    'PART': 9,\n",
        "    'PRON': 10,\n",
        "    'PROPN': 11,\n",
        "    'PUNCT': 12,\n",
        "    'SCONJ': 13,\n",
        "    'SYM': 14,\n",
        "    'VERB': 15,\n",
        "    'X': 16\n",
        "}\n",
        "pos_onehot = np.eye(len(pos_table))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHyEfqkquRyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dep_table = {\n",
        "    'ROOT': 0,\n",
        "    'acl': 1,\n",
        "    'acomp': 2,\n",
        "    'advcl': 3,\n",
        "    'advmod': 4,\n",
        "    'agent': 5,\n",
        "    'amod': 6,\n",
        "    'appos': 7,\n",
        "    'attr': 8,\n",
        "    'aux': 9,\n",
        "    'auxpass': 10,\n",
        "    'case': 11,\n",
        "    'cc': 12,\n",
        "    'ccomp': 13,\n",
        "    'compound': 14,\n",
        "    'conj': 15,\n",
        "    'csubj': 16,\n",
        "    'dative': 17,\n",
        "    'dep': 18,\n",
        "    'det': 19,\n",
        "    'dobj': 20,\n",
        "    'expl': 21,\n",
        "    'intj': 22,\n",
        "    'mark': 23,\n",
        "    'meta': 24,\n",
        "    'neg': 25,\n",
        "    'nmod': 26,\n",
        "    'npadvmod': 27,\n",
        "    'nsubj': 28,\n",
        "    'nsubjpass': 29,\n",
        "    'nummod': 30,\n",
        "    'oprd': 31,\n",
        "    'parataxis': 32,\n",
        "    'pcomp': 33,\n",
        "    'pobj': 34,\n",
        "    'poss': 35,\n",
        "    'preconj': 36,\n",
        "    'predet': 37,\n",
        "    'prep': 38,\n",
        "    'prt': 39,\n",
        "    'punct': 40,\n",
        "    'quantmod': 41,\n",
        "    'relcl': 42,\n",
        "    'xcomp': 43,\n",
        "    'csubjpass': 44\n",
        "}\n",
        "dep_onehot = np.eye(len(dep_table))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDKARNc19Fwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag_table = {\n",
        "    '$': 0,\n",
        "    \"''\": 1,\n",
        "    ',': 2,\n",
        "    '-LRB-': 3,\n",
        "    '-RRB-': 4,\n",
        "    '.': 5,\n",
        "    ':': 6,\n",
        "    'ADD': 7,\n",
        "    'CC': 8,\n",
        "    'CD': 9,\n",
        "    'DT': 10,\n",
        "    'EX': 11,\n",
        "    'FW': 12,\n",
        "    'HYPH': 13,\n",
        "    'IN': 14,\n",
        "    'JJ': 15,\n",
        "    'JJR': 16,\n",
        "    'JJS': 17,\n",
        "    'LS': 18,\n",
        "    'MD': 19,\n",
        "    'NFP': 20,\n",
        "    'NN': 21,\n",
        "    'NNP': 22,\n",
        "    'NNPS': 23,\n",
        "    'NNS':24,\n",
        "    'PDT':25,\n",
        "    'POS':26,\n",
        "    'PRP': 27,\n",
        "    'PRP$':28,\n",
        "    'RB': 29,\n",
        "    'RBR': 30,\n",
        "    'RBS': 31,\n",
        "    'RP': 32,\n",
        "    'SYM': 33,\n",
        "    'TO': 34,\n",
        "    'UH': 35,\n",
        "    'VB': 36,\n",
        "    'VBD': 37,\n",
        "    'VBG': 38,\n",
        "    'VBN': 39,\n",
        "    'VBP': 40,\n",
        "    'VBZ': 41,\n",
        "    'WDT': 42,\n",
        "    'WP': 43,\n",
        "    'WP$': 44,\n",
        "    'WRB': 45,\n",
        "    'XX': 46,\n",
        "    '``': 47\n",
        "}\n",
        "tag_onehot_emb = np.eye(len(tag_table))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBHVAkKV5zc8",
        "colab_type": "code",
        "outputId": "47808ed9-9b21-4c3e-afd7-01db47a25869",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "word_model = api.load(\"glove-wiki-gigaword-300\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[=================================================-] 99.3% 373.6/376.1MB downloaded"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnPX1b10uX4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://spacy.io/usage/linguistic-features#tokenization define our own spacy tokenizar by split()\n",
        "class WhitespaceTokenizer(object):\n",
        "    def __init__(self, vocab):\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __call__(self, text):\n",
        "        words = text.split(' ')\n",
        "        # All tokens 'own' a subsequent space character in this tokenizer\n",
        "        spaces = [True] * len(words)\n",
        "        return Doc(self.vocab, words=words, spaces=spaces)\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.tokenizer = WhitespaceTokenizer(nlp.vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsTMKwII2Eha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def prepare_sequence(seq, to_ix):\n",
        "    N = len(seq.split())\n",
        "    idxs = [to_ix[w] for w in seq.split()]\n",
        "    emb = nn.Embedding(len(to_ix), 50)\n",
        "    return emb(idxs).view(N, 1, -1)\n",
        "\n",
        "\n",
        "def prepare_embeddings(seq, nlp, to_ix, emb_dim):\n",
        "    N = len(seq.split())\n",
        "    if not nlp:\n",
        "        idxs = torch.LongTensor([to_ix[w] for w in seq.split()])\n",
        "        emb = nn.Embedding(len(to_ix), emb_dim)\n",
        "        return emb(idxs).view(N, 1, -1)\n",
        "    sentence_emb = torch.empty((0, emb_dim), dtype=torch.float32)\n",
        "    parse = nlp(seq)\n",
        "    for token in parse:\n",
        "        word_emb = torch.FloatTensor(token.vector)\n",
        "        pos_emb = torch.FloatTensor(pos_onehot[pos_table[token.pos_]])\n",
        "        dep_emb = torch.FloatTensor(dep_onehot[dep_table[token.dep_]])\n",
        "        embeddings = torch.cat((word_emb, pos_emb, dep_emb), axis=-1).view(1, -1)\n",
        "        # print(embeddings.shape)\n",
        "        sentence_emb = torch.cat((sentence_emb, embeddings), axis=0)\n",
        "    return sentence_emb.view(N, 1, -1)\n",
        "\n",
        "\n",
        "def emb_pos_dep_tf_idf(seq, index, flag):\n",
        "    N = len(seq.split())\n",
        "    sentence_emb = torch.empty((0, 158), dtype=torch.float32)\n",
        "    parse = nlp(seq)\n",
        "    for token in parse:\n",
        "        word_emb = torch.FloatTensor(token.vector)\n",
        "        pos_emb = torch.FloatTensor(pos_onehot[pos_table[token.pos_]])\n",
        "        dep_emb = torch.FloatTensor(dep_onehot[dep_table[token.dep_]])\n",
        "        if flag == 'train':\n",
        "            tf_idf_emb = torch.FloatTensor([tf_idf_train[index, str(token)]])\n",
        "        elif flag == 'val':\n",
        "            tf_idf_emb = torch.FloatTensor([tf_idf_val[index, str(token)]])\n",
        "        elif flag == 'test':\n",
        "            tf_idf_emb = torch.FloatTensor([tf_idf_test[index, str(token)]])\n",
        "        embeddings = torch.cat((word_emb, pos_emb, dep_emb, tf_idf_emb), axis=-1).view(1, -1)\n",
        "        # print(embeddings.shape)\n",
        "        sentence_emb = torch.cat((sentence_emb, embeddings), axis=0)\n",
        "    return sentence_emb.view(N, 1, -1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAcbL-VNtLWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check if cuda is available, if so print the device name\n",
        "# using_cuda = torch.cuda.is_available()\n",
        "# device = torch.device('cuda' if using_cuda else 'cpu')\n",
        "# print('We are using ' + str(device) + '.')\n",
        "# if using_cuda:\n",
        "#     print(torch.cuda.get_device_properties(device))\n",
        "\n",
        "# MAX_LENGTH = 124\n",
        "# EMBEDDING_DIM = 158                      # word_emb 96 + pos_onehot 17 + dep_onehot 44 + td_idf 1\n",
        "# BATCH_SIZE = 256\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "\n",
        "# kwargs = {'num_workers': 1, 'pin_memory': True} if using_cuda else {}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}